# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import requests
import io
import re
import os




# ì²«ë²ˆì§¸ íƒ­: ë¶„ì„ê²°ê³¼ (tab7)
tab1, tab2, tab3, tab4, tab5, tab6, tab7= st.tabs([
    "ë¶„ì„ê²°ê³¼", 
    "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡", 
    "ë¶„ì„ê²°ê³¼(êµ°ìœ„)", 
    "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„)", 
    "ì ì—½ ì „í›„ ì²˜ë¦¬ ê²°ê³¼",
    "ê³¼ì‹¤ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼",  
    "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ / ì í•© í’ˆì¢… ì¶”ì²œ"
])


with tab1:
    st.title("ë¶„ì„ ê²°ê³¼")
    BASE_DIR = Path(__file__).parent / "mba" / "ë¶„ì„ê²°ê³¼" / "ê´€ê³„ì‹œê°í™”2"
    CULTIVAR_DIRS = {
        "í™ë¡œ": BASE_DIR / "í™ë¡œ",
        "í›„ì§€": BASE_DIR / "í›„ì§€",
    }
    cultivar = st.radio("í’ˆì¢… ì„ íƒ", list(CULTIVAR_DIRS.keys()), horizontal=True, key="radio_tab1")
    folder = CULTIVAR_DIRS[cultivar]
    if not folder.exists():
        st.error("í•´ë‹¹ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ ì˜¤íƒ€ ë˜ëŠ” ë“œë¼ì´ë¸Œ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    TAB_EXT = (".csv", ".xlsx")
    all_imgs = sorted([p for p in folder.rglob("*") if p.suffix.lower() in IMG_EXT])
    all_tabs = sorted([p for p in folder.rglob("*") if p.suffix.lower() in TAB_EXT])
    mode = st.segmented_control("í‘œì‹œ ìœ í˜•", options=["ì´ë¯¸ì§€", "í‘œ(ë°ì´í„°)"], key="seg_tab1")
    if mode == "ì´ë¯¸ì§€":
        if not all_imgs:
            st.warning("í‘œì‹œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            view = st.radio("ë°©ì‹ ì„ íƒ", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ íŒŒì¼"], horizontal=True, key="view_tab1")
            if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
                thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4)
                rows = (len(all_imgs) + thumbs - 1) // thumbs
                st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
                idx = 0
                for _ in range(rows):
                    cols = st.columns(thumbs, gap="small")
                    for c in cols:
                        if idx >= len(all_imgs):
                            break
                        p = all_imgs[idx]
                        with c:
                            st.image(str(p), caption=str(p.relative_to(folder)))
                        idx += 1
            else:
                sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [str(p.relative_to(folder)) for p in all_imgs])
                path = folder / sel
                st.image(str(path), caption=str(path))
    else:
        if not all_tabs:
            st.warning("í‘œì‹œí•  CSV/XLSX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            path = all_tabs[0]
            st.subheader("ì˜ˆì¸¡ ì •í™•ë„")
            try:
                if path.suffix.lower() == ".csv":
                    df = pd.read_csv(path)
                else:
                    df = pd.read_excel(path)
                st.dataframe(df)
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# ë‘ë²ˆì§¸ íƒ­: ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ (3. streamlit(í™ë¡œ,í›„ì§€4~)_ìˆ˜ì •3.py)
with tab2:
   # -*- coding: utf-8 -*-
# íŒŒì¼ëª…: ê¸°ìƒìë™ë¶ˆëŸ¬ì˜¤ê¸°3.py
    import streamlit as st
    import pandas as pd
    import numpy as np
    import requests
    from datetime import datetime
    import io
    import matplotlib.pyplot as plt
    from typing import Optional
    import re

# â–¶ í•œê¸€ í°íŠ¸ ìë™ ì„¤ì • (ê°œì„ íŒ: ê²½ë¡œ ì•ˆì •í™” + ì‹œìŠ¤í…œ í°íŠ¸ ìš°ì„ )
from pathlib import Path
import os
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import streamlit as st

plt.rcParams["font.size"] = 6

def _set_korean_font():
    # 1) ì•± í´ë” ê¸°ì¤€ìœ¼ë¡œ fonts/ë¥¼ ì •í™•íˆ ì°¾ë„ë¡ ì ˆëŒ€ê²½ë¡œí™”
    BASE = Path(__file__).parent
    bundled_candidates = [
        BASE / "fonts" / "NanumGothic.ttf",
        BASE / "fonts" / "NotoSansKR-Regular.otf",
    ]

    # 2) ë²ˆë“¤ í°íŠ¸(ì €ì¥ì†Œì— ë„£ì€ TTF/OTF)ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
    for p in bundled_candidates:
        if p.exists():
            try:
                fm.fontManager.addfont(str(p))
                family = fm.FontProperties(fname=str(p)).get_name()
                matplotlib.rcParams["font.family"] = family
                matplotlib.rcParams["axes.unicode_minus"] = False
                return
            except Exception:
                pass

    # 3) ì‹œìŠ¤í…œì— ê¹”ë ¤ ìˆì„ ë²•í•œ í•œê¸€ í°íŠ¸ í›„ë³´ (Streamlit CloudëŠ” ë³´í†µ Noto ê³„ì—´ ìˆìŒ)
    preferred = [
        "Noto Sans CJK KR", "Noto Sans KR",       # ë¦¬ëˆ…ìŠ¤/Cloudì—ì„œ ê¸°ëŒ€ë˜ëŠ” í°íŠ¸
        "NanumGothic", "Nanum Gothic",            # ë‚˜ëˆ”ê³ ë”•(ì‹œìŠ¤í…œ ì„¤ì¹˜ëœ ê²½ìš°)
        "Malgun Gothic",                          # ìœˆë„ìš°
        "AppleGothic",                            # ë§¥
    ]

    # í˜„ì¬ ì‹œìŠ¤í…œì— ë“±ë¡ëœ í°íŠ¸ ì´ë¦„ ì§‘í•©
    sys_fonts = {f.name for f in fm.fontManager.ttflist}
    for name in preferred:
        if name in sys_fonts:
            matplotlib.rcParams["font.family"] = name
            matplotlib.rcParams["axes.unicode_minus"] = False
            return

    # 4) ê·¸ë˜ë„ ëª» ì°¾ì•˜ìœ¼ë©´ ìµœì†Œí•œ ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ë§Œ ë°©ì§€ + ì•ˆë‚´
    matplotlib.rcParams["axes.unicode_minus"] = False
    st.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ /fonts ì— TTF/OTF(ì˜ˆ: NanumGothic.ttf)ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

_set_korean_font()

# ---------------------------
# ê³µí†µ ìœ í‹¸: ë¬¸ìì—´/í’ˆì§ˆí‘œ ì •ê·œí™”
# ---------------------------
def _clean_str(s: str) -> str:
    s = str(s)
    s = s.replace("\xa0", " ")                 # NBSP -> space
    s = s.replace("\n", " ").replace("\r", " ")
    s = re.sub(r"\s+", " ", s).strip()
    s = re.sub(r"\s*\(\s*", " (", s)          # "( " -> " ("
    s = re.sub(r"\s*\)\s*", ")", s)           # " )" -> ")"
    return s


def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í…Œì´ë¸”: ë©€í‹°í—¤ë”/ê³µë°±/ê¸°í˜¸ ì •ë¦¬ + ì§€ì—­/ìˆ˜í™•ì¼ì ì •ê·œí™”"""
    out = df.copy()

    # ë©€í‹°í—¤ë” â†’ ë‹¨ì¼ ë¬¸ìì—´
    if isinstance(out.columns, pd.MultiIndex):
        out.columns = [
            " ".join([str(x) for x in tup if str(x) != "nan"]).strip()
            for tup in out.columns.values
        ]

    # í—¤ë” í´ë¦°ì—…
    out.columns = [_clean_str(c) for c in out.columns]

    # í”í•œ ë³„ì¹­ í†µì¼
    alias = {
        "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
        "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
        "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
        "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
        "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
    }
    out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})

    # ì§€ì—­/ìˆ˜í™•ì¼ì ì •ë¦¬
    if "ì§€ì—­" in out.columns:
        out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
    if "ìˆ˜í™•ì¼ì" in out.columns:
        out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")

    return out


def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
    """ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ì»¬ëŸ¼ëª… 1ê°œ ì°¾ê¸°(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
    pat = re.compile(pattern, flags=re.IGNORECASE)
    for c in df.columns:
        if pat.search(str(c)):
            return c
    return None


    # -------------------------------------------------
    # ê¸°ë³¸ UI
    # -------------------------------------------------

    st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡", layout="wide")
    st.markdown("<h1 style='text-align: center;'>ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡</h1>", unsafe_allow_html=True)

    # -------------------------------------------------
    # ì§€ì—­ ì½”ë“œ
    # -------------------------------------------------
    AREA_CODE = {
        "ê²½ê¸°í™”ì„±": "324",
        "ê²½ë¶ì˜ì£¼": "331",
        "ê²½ë¶ì²­ì†¡": "332",
        "ëŒ€êµ¬êµ°ìœ„": "333",
        "ê²½ë‚¨ê±°ì°½": "334",
        "ì „ë¶ì¥ìˆ˜": "335",
        "ê²½ê¸°í¬ì²œ": "337",
        "ì¶©ë¶ì¶©ì£¼": "338",
    }

    # ê³¼ì‹¤í’ˆì§ˆ í˜ì´ì§€ì˜ ì§€ì—­ í‘œê¸° ë§¤í•‘
    REGION_NAME_MAP = {
        "ê²½ê¸°í™”ì„±": "í™”ì„±",
        "ê²½ë¶ì˜ì£¼": "ì˜ì£¼",
        "ê²½ë¶ì²­ì†¡": "ì²­ì†¡",
        "ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„",
        "ê²½ë‚¨ê±°ì°½": "ê±°ì°½",
        "ì „ë¶ì¥ìˆ˜": "ì¥ìˆ˜",
        "ê²½ê¸°í¬ì²œ": "í¬ì²œ",
        "ì¶©ë¶ì¶©ì£¼": "ì¶©ì£¼",
    }

    # -------------------------------------------------
    # íšŒê·€ì‹
    # -------------------------------------------------
    EQUATIONS_BY_CULTIVAR = {
        "í™ë¡œ": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 667.243 -0.597465Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.376337Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.0756442Â·ì¼ì‚¬ëŸ‰_sum_m08 +24.5342Â·í‰ê· í’ì†_mean_m06 +5.05212Â·ìµœì €ê¸°ì˜¨_mean_m06",
            "ì¢…ê²½": "ì¢…ê²½ = 124.046 -0.0439843Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.0673823Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.397906Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.559339Â·í‰ê· í’ì†_mean_m06 +7.43416Â·í‰ê· í’ì†_mean_m05 +0.00854761Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.15116Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.05474Â·ìµœì €ê¸°ì˜¨_mean_m05 -2.574Â·ìµœëŒ€í’ì†_mean_m04",
            "íš¡ê²½": "íš¡ê²½ = 141.358 -0.0531011Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.0459844Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.00297393Â·ì¼ì‚¬ëŸ‰_sum_m08",
            "L":   "L = -68.3528 +2.1686e-05Â·ê°•ìš°ëŸ‰_sum_m07 +0.653086Â·ìŠµë„_mean_m07 +2.72693Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.14857Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.00918464Â·ê°•ìš°ëŸ‰_sum_m06 -1.52125Â·ìµœì €ê¸°ì˜¨_mean_m05 -6.00147Â·í‰ê· í’ì†_mean_m06 +3.14509Â·ìµœëŒ€í’ì†_mean_m06 +4.16545Â·í‰ê· í’ì†_mean_m07",
            "a":   "a = 226.087 -1.71711Â·ìŠµë„_mean_m07 +0.00830904Â·ê°•ìš°ëŸ‰_sum_m07 -4.51272Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.51756Â·ìµœì €ê¸°ì˜¨_mean_m05 -1.94971Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.040713Â·ì¼ì‚¬ëŸ‰_sum_m07 -0.0185248Â·ê°•ìš°ëŸ‰_sum_m06 +0.00975096Â·ê°•ìš°ëŸ‰_sum_m08 +1.93026Â·ìµœê³ ê¸°ì˜¨_mean_m07 -0.192988Â·í‰ê· í’ì†_mean_m06",
            "b":   "b = -23.7933 +0.381237Â·ìŠµë„_mean_m07 +0.0052134Â·ê°•ìš°ëŸ‰_sum_m06 +0.0606139Â·ìŠµë„_mean_m05 +1.14817Â·ìµœì €ê¸°ì˜¨_mean_m06 +0.682908Â·í‰ê· í’ì†_mean_m07 -0.523353Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.350293Â·ìµœê³ ê¸°ì˜¨_mean_m05 -0.00264168Â·ê°•ìš°ëŸ‰_sum_m08 -1.23413Â·í‰ê· í’ì†_mean_m08 +0.652516Â·ìµœëŒ€í’ì†_mean_m06",
            "ê²½ë„": "ê²½ë„ = 54.6658 +0.2039Â·ìŠµë„_mean_m04 +0.0144323Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.194462Â·ìŠµë„_mean_m08 -0.0140798Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.00218425Â·ê²°ë¡œì‹œê°„_mean_m04 +0.364872Â·í‰ê· ê¸°ì˜¨_mean_m08",
            "ë‹¹ë„": "ë‹¹ë„ = 1.14467 -0.425354Â·ìµœëŒ€í’ì†_mean_m06 -1.03279Â·í‰ê· í’ì†_mean_m07 -0.0754722Â·í‰ê· í’ì†_mean_m08 +0.781233Â·í‰ê· í’ì†_mean_m04 -0.0277847Â·ìµœê³ ê¸°ì˜¨_mean_m08 -0.0127413Â·ìŠµë„_mean_m05 +0.0022906Â·ê²°ë¡œì‹œê°„_mean_m05 +0.259103Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.0923847Â·ìŠµë„_mean_m04 +0.410232Â·ìµœëŒ€í’ì†_mean_m04 -0.00215038Â·ê°•ìš°ëŸ‰_sum_m06",
            "ì‚°ë„": "ì‚°ë„ = 0.262689 +0.0555189Â·ìµœëŒ€í’ì†_mean_m06 +0.0451885Â·í‰ê· í’ì†_mean_m08 -0.0549304Â·í‰ê· í’ì†_mean_m04 -0.00534754Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.0236952Â·í‰ê· í’ì†_mean_m07 -0.00264247Â·ìŠµë„_mean_m04 +0.00413186Â·ìŠµë„_mean_m08 -0.00334177Â·í‰ê· ê¸°ì˜¨_mean_m07 +0.000124634Â·ê°•ìš°ëŸ‰_sum_m06 -0.001393Â·ìŠµë„_mean_m05",
        },
        "í›„ì§€": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 399.484 -0.229845Â·ì¼ì‚¬ëŸ‰_sum_m04 +6.76485Â·ìµœì €ê¸°ì˜¨_mean_m05 -17.8404Â·ìµœëŒ€í’ì†_mean_m07",
            "ì¢…ê²½": "ì¢…ê²½ = 183.553 -0.0439139Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.626045Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0145561Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.955631Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.0373121Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.656449Â·ìŠµë„_mean_m08 -0.0131851Â·ìŠµë„_mean_m06 +1.16239Â·í‰ê· ê¸°ì˜¨_mean_m07 -1.16892Â·ìµœì €ê¸°ì˜¨_mean_m09 -0.420997Â·ìŠµë„_mean_m09",
            "íš¡ê²½": "íš¡ê²½ = 79.6808 -1.82161Â·ìµœëŒ€í’ì†_mean_m07 +0.796471Â·í‰ê· ê¸°ì˜¨_mean_m05",
            "L":   "L = 75.7441 -0.134414Â·ìŠµë„_mean_m08 -0.400198Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0159958Â·ê°•ìš°ëŸ‰_sum_m10 +0.0240315Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.812706Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0812023Â·ìŠµë„_mean_m04 -0.206954Â·ìŠµë„_mean_m06 +0.116267Â·ìŠµë„_mean_m10 -0.0069829Â·ì¼ì‚¬ëŸ‰_sum_m04 -2.452Â·í‰ê· í’ì†_mean_m04 -0.0989298Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.384125Â·í‰ê· ê¸°ì˜¨_mean_m07",
            "a":   "a = 4.0922 -0.0203282Â·ê°•ìš°ëŸ‰_sum_m10 -2.85393Â·ìµœëŒ€í’ì†_mean_m05 -0.00910066Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0392451Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.307386Â·ìŠµë„_mean_m08 +0.000860505Â·ê°•ìš°ëŸ‰_sum_m08 -0.688696Â·ìµœëŒ€í’ì†_mean_m08 -0.00144964Â·ì¼ì‚¬ëŸ‰_sum_m05 +0.758309Â·ìµœëŒ€í’ì†_mean_m07",
            "b":   "b = 12.841 -0.0308293Â·ìŠµë„_mean_m08 +0.0145751Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.00322966Â·ê°•ìš°ëŸ‰_sum_m08 +0.035395Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0796701Â·ìŠµë„_mean_m10 -0.000543608Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00337387Â·ê°•ìš°ëŸ‰_sum_m10 -0.00372859Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.14243Â·ìŠµë„_mean_m06 +0.0641568Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.14721Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.53868Â·í‰ê· í’ì†_mean_m04",
            "ê²½ë„": "ê²½ë„ = 8.39888 +0.0529999Â·ì¼ì‚¬ëŸ‰_sum_m09 +6.94666Â·í‰ê· í’ì†_mean_m07 +3.98929Â·ìµœëŒ€í’ì†_mean_m08 -0.0451264Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.406065Â·ìŠµë„_mean_m04 -3.47701Â·í‰ê· í’ì†_mean_m06 -0.00806023Â·ê²°ë¡œì‹œê°„_mean_m10 +0.0392251Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00773583Â·ê²°ë¡œì‹œê°„_mean_m09 -2.0759Â·ìµœëŒ€í’ì†_mean_m10 +0.000289527Â·ê²°ë¡œì‹œê°„_mean_m06 -2.8229Â·ìµœëŒ€í’ì†_mean_m05 +0.000106158Â·ê²°ë¡œì‹œê°„_mean_m05 +0.270037Â·ìµœê³ ê¸°ì˜¨_mean_m09",
            "ë‹¹ë„": "ë‹¹ë„ = 10.492 +0.00486017Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00146432Â·ê²°ë¡œì‹œê°„_mean_m10 +0.00262004Â·ê²°ë¡œì‹œê°„_mean_m07 -0.00156465Â·ê²°ë¡œì‹œê°„_mean_m09 -1.20735Â·í‰ê· í’ì†_mean_m10 -0.000317261Â·ê²°ë¡œì‹œê°„_mean_m05",
            "ì‚°ë„": "ì‚°ë„ = 0.766184 -0.0175941Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.00379855Â·ìŠµë„_mean_m04 -0.00807644Â·ìµœê³ ê¸°ì˜¨_mean_m04 -4.6679e-05Â·ê°•ìš°ëŸ‰_sum_m08 +0.00318949Â·ìµœê³ ê¸°ì˜¨_mean_m08 -8.77968e-05Â·ê°•ìš°ëŸ‰_sum_m10 -0.00456198Â·í‰ê· í’ì†_mean_m04 +0.00411344Â·ìµœê³ ê¸°ì˜¨_mean_m07",
        },
    }

    # -------------------------------------------------
    # ìœ í‹¸
    # -------------------------------------------------
    def _ensure_numeric(df: pd.DataFrame, cols):
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    def cultivar_window(cultivar: str):
        if cultivar == "í™ë¡œ":
            return 4, 8
        return 4, 10  # í›„ì§€ ê¸°ë³¸

    def get_today_ym():
        now = datetime.now()
        return now.year, now.month

    # -------------------------------------------------
    # ì‚¬ì´íŠ¸ AJAX â†’ JSON (AWS í†µê³„)
    # -------------------------------------------------
    @st.cache_data(show_spinner=False, ttl=300)
    def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
        session = requests.Session()
        session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)

        form = {
            "pageIndex": "1",
            "searchNum": "0",
            "areaName": region_name,
            "areaCode": AREA_CODE.get(region_name, region_name),
            "statmethod": stat_gb_code,
        }
        if stat_gb_code == "A":
            form["wetherDtBgn"] = f"{s_ym}-01"
            form["wetherDtEnd"] = f"{e_ym}-30"
        elif stat_gb_code in ("B", "C"):
            form["wetherDtM"] = s_ym
        elif stat_gb_code == "D":
            form["wetherDtBgn2"] = s_ym
            form["wetherDtEnd2"] = e_ym
            form["wetherDtBgn"] = s_ym
            form["wetherDtEnd"] = e_ym

        resp = session.post(
            "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
            data=form, timeout=30,
            headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
        )
        resp.raise_for_status()
        try:
            return resp.json()
        except Exception:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

    # -------------------------------------------------
    # JSON â†’ í‘œ
    # -------------------------------------------------
    def json_to_dataframe(payload: dict) -> pd.DataFrame:
        if not payload or "result" not in payload:
            return pd.DataFrame()
        res = payload.get("result", [])
        if len(res) == 0:
            return pd.DataFrame()

        method = payload.get("mainAwsVO", {}).get("statmethod")
        raw = pd.DataFrame(res)

        with st.expander("ğŸ”§ API ì›ì‹œ ì»¬ëŸ¼ ë³´ê¸°", expanded=False):
            st.write(sorted(list(raw.columns)))

        rename_map = {
            "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
            "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
            "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
            "dalyWetherAvrgHd": "ìŠµë„",     "WetherAvgHd": "ìŠµë„",
            "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰",
            "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰",
            "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
            "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„",
            "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„",
            "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
            "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
            "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
        }
        raw = raw.rename(columns=rename_map)

        if method == "A":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "B":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "C":
            want = ["ìˆœ","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"] if "ìˆœ" in raw.columns \
                else ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        else:  # "D"
            want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
                if "ì›”" in raw.columns else \
                ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]

        use_cols = [c for c in want if c in raw.columns]
        if not use_cols:
            return pd.DataFrame()
        df = raw[use_cols].copy()

        numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        df = _ensure_numeric(df, [c for c in numcands if c in df.columns])

        if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
            df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
            if "ì—°ë„" not in df.columns:
                df["ì—°ë„"] = df["ì¼ì"].dt.year
            if "ì›”" not in df.columns:
                df["ì›”"] = df["ì¼ì"].dt.month
        elif "ì›”" in df.columns:
            df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
            df["ì›”"] = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")

        if {"ì—°ë„","ì›”"}.issubset(df.columns):
            df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        return df

    # -------------------------------------------------
    # ì¼/ìˆœ â†’ ì›”ë³„ ì§‘ê³„
    # -------------------------------------------------
    def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(df.columns):
            return df.copy()
        agg_map = {
            "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
            "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
            "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
        }
        use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
        out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
        return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

    # -------------------------------------------------
    # ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (_mean_mMM / _sum_mMM)
    # -------------------------------------------------
    def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
            raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
        sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
        wide_mean = None
        for m in range(1, 13):
            sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        wide_sum = None
        for m in range(1, 13):
            sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
        return wide

    # -------------------------------------------------
    # íšŒê·€ì‹ ì ìš©
    # -------------------------------------------------
    def apply_equation_row(row: pd.Series, eq_str: str) -> float:
        rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
        cols = sorted(row.index.tolist(), key=len, reverse=True)
        expr = rhs
        for c in cols:
            expr = expr.replace(c, f"row[{repr(c)}]")
        return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

    # -------------------------------------------------
    # ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°
    # -------------------------------------------------
    def fill_missing_or_future_with_climatology(env_m: pd.DataFrame, target_year: int, cultivar: str, mode: str = "last3") -> pd.DataFrame:
        need_cols = {"ì—°ë„","ì›”"}
        if not need_cols.issubset(env_m.columns):
            raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        s_mon, e_mon = cultivar_window(cultivar)
        cur_year, cur_mon = get_today_ym()

        cur = env_m[env_m["ì—°ë„"] == target_year].copy()
        hist = env_m[env_m["ì—°ë„"] < target_year].copy()
        if hist.empty:
            return cur
        if mode == "last3":
            last_years = sorted(hist["ì—°ë„"].unique())[-3:]
            hist = hist[hist["ì—°ë„"].isin(last_years)]

        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        climo = hist.groupby("ì›”", as_index=False)[num_cols].mean()

        months_window = list(range(s_mon, e_mon+1))
        have = set(cur["ì›”"].tolist())
        future_cut = cur_mon if target_year == cur_year else 12
        future_months = [m for m in months_window if (target_year == cur_year and m > future_cut) or (target_year > cur_year)]
        missing_months = [m for m in months_window if m not in have]

        to_fill = sorted(set(future_months) | set(missing_months))
        if to_fill:
            fill_rows = climo[climo["ì›”"].isin(to_fill)].copy()
            if fill_rows.empty:
                climo_all = env_m[env_m["ì—°ë„"] < target_year].groupby("ì›”", as_index=False)[num_cols].mean()
                fill_rows = climo_all[climo_all["ì›”"].isin(to_fill)].copy()
            fill_rows.insert(0, "ì—°ë„", target_year)
            cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)

        cur = cur[(cur["ì›”"] >= s_mon) & (cur["ì›”"] <= e_mon)]
        cur = cur.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        for c in num_cols:
            cur[c] = pd.to_numeric(cur[c], errors="coerce")
        return cur

    # -------------------------------------------------
    # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í…Œì´ë¸”
    # -------------------------------------------------
    @st.cache_data(show_spinner=False, ttl=3600)
    def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
        code = "apple01" if cultivar == "í›„ì§€" else "apple02"
        url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
        params = {
            "frtgrdCode": "apple",
            "selyear": str(selyear),
            "lastYear": str(lastyear),
            "searchGubun": code,
            "pageIndex": "1",
        }
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        try:
            import io as _io
            tables = pd.read_html(_io.StringIO(r.text))
        except Exception as e:
            st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\n"
                    "lxml/html5lib ì„¤ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”. (pip install lxml html5lib)")
            return {}

        cleaned = []
        for t in tables:
            t2 = normalize_quality_columns(t)
            if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(set(t2.columns)):
                cleaned.append(t2)

        result = {}
        if len(cleaned) >= 1:
            result["this"] = cleaned[0]
        if len(cleaned) >= 2:
            result["last"] = cleaned[1]
        return result

    def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
        if qdf is None or qdf.empty:
            return None
        region_disp_name = _clean_str(region_disp_name)
        if "ì§€ì—­" not in qdf.columns:
            return None
        tmp = qdf.copy()
        tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in tmp.columns and not np.issubdtype(tmp["ìˆ˜í™•ì¼ì"].dtype, np.datetime64):
            tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
        sub = tmp[tmp["ì§€ì—­"] == region_disp_name]
        if sub.empty:
            return None
        sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
        return sub.iloc[0]

    # -------------------------------------------------
    # ì‚¬ì´ë“œë°”
    # -------------------------------------------------
    # -------------------------------------------------
    # ì¡°íšŒ ì¡°ê±´ (ë©”ì¸ í™”ë©´ ìƒë‹¨ì— í‘œì‹œ)
    # -------------------------------------------------

    # í’ˆì¢… ì„ íƒ (ë¼ë””ì˜¤ ë²„íŠ¼)

    cultivar = st.radio(
    "í’ˆì¢… ì„ íƒ", ["í™ë¡œ", "í›„ì§€"], key="cultivar_radio"
)


    # ì§€ì—­ ì„ íƒ (ë“œë¡­ë‹¤ìš´)

    region = st.selectbox(
        "ì§€ì—­ ì„ íƒ",
        list(AREA_CODE.keys()),
        index=1
    )

    # ğŸ” ë²„íŠ¼
    run = st.button("ğŸ” ìë™ì¡°íšŒ & ì˜ˆì¸¡")

    # ì˜ˆìƒ ë‚ ì”¨ ë°©ë²•ì€ ì œê±°í•˜ê³ , í•­ìƒ 'all'(ì „ì²´ ê³¼ê±° í‰ê· )ìœ¼ë¡œ ê³ ì •
    mode = "all"


    # -------------------------------------------------
    # ì‹¤í–‰
    # -------------------------------------------------
    if run:
        try:
            cur_year, cur_month = get_today_ym()
            s_mon, e_mon = cultivar_window(cultivar)
            s_ym = f"{cur_year:04d}-{s_mon:02d}"
            e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

            with st.spinner("ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
                payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)

            if "error" in payload:
                st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.code(payload.get("raw","")[:1000])
                st.stop()

            df = json_to_dataframe(payload)
            st.subheader("ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡ ë°ì´í„°(ê¸°ìƒ)")
            if df.empty:
                st.warning("ì˜¬í•´ ê¸°ê°„ ë‚´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±° ê¸°í›„í‰ë…„ë§Œìœ¼ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            else:
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì˜ˆì™¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.exception(e)

        env_m = df.copy()
        if not env_m.empty and "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"] = env_m["ì›”"].astype(str).str[5:7].astype(int)

        past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
        past_df = json_to_dataframe(past_payload)
        env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m

        filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

        st.subheader("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì›”ë³„ ë°ì´í„°(ì˜¬í•´, ë¯¸ë˜ì›”ì€ ì˜ˆìƒ ë‚ ì”¨ë¡œ ëŒ€ì²´)")
        st.dataframe(filled_this_year, use_container_width=True)

        try:
            env_for_wide = pd.concat([env_all[env_all["ì—°ë„"] != cur_year], filled_this_year], ignore_index=True)
            wide = build_wide_month_feats(env_for_wide)
        except Exception as e:
            st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            st.stop()

        if cur_year not in set(wide["ì—°ë„"].astype(int).tolist()):
            st.error("ì˜ˆì¸¡ ì—°ë„ í–‰ì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        row = wide[wide["ì—°ë„"] == cur_year].iloc[0]

        EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
        preds = {}
        for tgt, formula in EQUATIONS.items():
            try:
                preds[tgt] = apply_equation_row(row, formula)
            except Exception as e:
                preds[tgt] = f"ì—ëŸ¬: {e}"

        st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  í’ˆì¢…: {cultivar}  ì—°ë„: {cur_year}")

        pred_df = pd.DataFrame([preds]).T.reset_index()
        pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]

        # í–‰/ì—´ ë°”ê¾¸ê¸°
        pred_df_t = pred_df.set_index("í•­ëª©").T.reset_index(drop=True)

        st.dataframe(pred_df_t, use_container_width=True)


        # -----------------------------
        # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ ë¶ˆëŸ¬ì™€ì„œ ì§€ì—­ í–‰ ì¶”ì¶œ
        # -----------------------------
        with st.spinner("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            qdict = fetch_quality_tables(cur_year, cur_year-1, cultivar)

        region_disp = REGION_NAME_MAP.get(region, region)
        last_row = None
        if qdict and "last" in qdict and qdict["last"] is not None and not qdict["last"].empty:
            q_last = normalize_quality_columns(qdict["last"])
            with st.expander("ì „ë…„ë„ í…Œì´ë¸” ì‹¤ì œ ì»¬ëŸ¼ëª…(ì •ê·œí™” í›„)"):
                st.write(list(q_last.columns))
            last_row = pick_region_row(q_last, region_disp)

        if last_row is not None:
            # 8ê°œ ì§€í‘œë§Œ íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘
            patterns = {
                "ê³¼ì¤‘": r"^ê³¼ì¤‘",
                "ì¢…ê²½": r"^ì¢…ê²½",
                "íš¡ê²½": r"^íš¡ê²½",
                # ê²½ë„í‰ê· (N/Ã¸11mm) ì£¼ë³€ í‘œê¸° ë³€í˜• í—ˆìš©
                "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
                # Â°Brix / ËšBrix ëª¨ë‘ í—ˆìš©
                "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
                "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
                "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
                "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
                "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
            }

            def to_float(x):
                try:
                    return float(str(x).replace(",", "").strip())
                except Exception:
                    return None

            rows = []
            # last_rowëŠ” Seriesë¼ì„œ ì»¬ëŸ¼ íƒìƒ‰ì„ ìœ„í•´ 1í–‰ DataFrameìœ¼ë¡œ ë³€í™˜
            last_df_for_match = last_row.to_frame().T
            for k, pat in patterns.items():
                col = get_first_col_by_pattern(last_df_for_match, pat)
                last_val = to_float(last_row[col]) if col else None
                pred_val = preds.get(k, None)
                rows.append([k, pred_val, last_val])

            compare_df = pd.DataFrame(rows, columns=["í•­ëª©","ì˜ˆì¸¡ê°’(ì˜¬í•´)","ì „ë…„ë„ ì‹¤ì œê°’"])
            st.subheader(f"ì˜¬í•´ ì˜ˆì¸¡ vs ì „ë…„ë„ ì‹¤ì œ  ë¹„êµ  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}")

            # í•­ëª©ì„ ì—´ë¡œ, ê°’ êµ¬ë¶„ì„ ì¸ë±ìŠ¤ë¡œ
            compare_df_t = compare_df.set_index("í•­ëª©").T
            compare_df_t.index.name = ""  # ì¸ë±ìŠ¤ ì œëª© ì œê±°
            st.dataframe(compare_df_t, use_container_width=True)


            # ====== ê·¸ë˜í”„ ì„¹ì…˜ (ë ˆì´ì•„ì›ƒ/ìƒ‰ìƒ/í¬ê¸° ë°˜ì˜) ======
            PRED_COLOR = "#87CEEB"   # ì˜ˆì¸¡(ì˜¬í•´): í•˜ëŠ˜ìƒ‰
            LAST_COLOR = "#800080"   # ì „ë…„ë„: ìì¤ë¹›

            def _pick(df, item):
                r = df[df["í•­ëª©"] == item]
                if r.empty: return np.nan, np.nan
                p = pd.to_numeric(r["ì˜ˆì¸¡ê°’(ì˜¬í•´)"].values[0], errors="coerce")
                l = pd.to_numeric(r["ì „ë…„ë„ ì‹¤ì œê°’"].values[0], errors="coerce")
                return p, l

            # â”€â”€ 1) ê³¼ì‹¤ í¬ê¸°(ê³¼ì¤‘Â·íš¡ê²½Â·ì¢…ê²½ í•œ ê·¸ë˜í”„ì—)
            size_items = ["ê³¼ì¤‘", "íš¡ê²½", "ì¢…ê²½"]
            x = np.arange(len(size_items))
            y_pred = []; y_last = []
            for it in size_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))

            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                w = 0.35
                if not all(pd.isna(y_pred)):
                    ax.bar(x - w/2, np.nan_to_num(y_pred, nan=0.0), width=w, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.bar(x + w/2, np.nan_to_num(y_last, nan=0.0), width=w, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(size_items)
                ax.set_title("ê³¼ì‹¤ í¬ê¸°")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                ax.legend()
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
            else:
                st.info("ê³¼ì‹¤ í¬ê¸°(ê³¼ì¤‘/íš¡ê²½/ì¢…ê²½) ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # ê³µí†µ: ë‹¨ì¼ í•­ëª© ë§‰ëŒ€ ê·¸ë˜í”„(ì‘ê²Œ)
            def _bar_single(item, title):
                p, l = _pick(compare_df, item)
                if pd.isna(p) and pd.isna(l): 
                    return
                xs, ys, cs = [], [], []
                if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                fig, ax = plt.subplots(figsize=(2.5, 1.8))
                ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                ax.set_title(title)
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)

            # â”€â”€ 2) ê²½ë„, 3) ë‹¹ë„, 4) ì‚°ë„ (ê°€ë¡œë¡œ ë‚˜ë€íˆ)
            c1, c2, c3 = st.columns(3)

            with c1:
                # ê²½ë„ ê·¸ë˜í”„ yì¶• ìµœëŒ€ê°’ 70ìœ¼ë¡œ ì„¤ì •
                p, l = _pick(compare_df, "ê²½ë„")
                if pd.isna(p) and pd.isna(l): 
                    pass
                else:
                    xs, ys, cs = [], [], []
                    if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                    if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                    fig, ax = plt.subplots(figsize=(2.5, 1.8))
                    ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                    ax.set_title("ê²½ë„")
                    ax.grid(axis="y", linestyle=":", alpha=0.35)
                    ax.set_ylim(top=70)
                    # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                    ax.spines["top"].set_visible(False)
                    ax.spines["right"].set_visible(False)
                    ax.spines["left"].set_linewidth(0.7)
                    ax.spines["bottom"].set_linewidth(0.7)
                    fig.tight_layout()
                    st.pyplot(fig, use_container_width=False)

            with c2:
                _bar_single("ë‹¹ë„", "ë‹¹ë„")
            with c3:
                _bar_single("ì‚°ë„", "ì‚°ë„")

            # â”€â”€ 5) ì°©ìƒ‰ë„ L/a/b (êº¾ì€ì„  ê·¸ë˜í”„, ì„¸ë¡œ ë§¨ ì•„ë˜)
            tone_items = ["L", "a", "b"]
            x = np.arange(len(tone_items))
            y_pred = []; y_last = []
            for it in tone_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))

            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                if not all(pd.isna(y_pred)):
                    ax.plot(x, y_pred, marker="o", linewidth=2, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.plot(x, y_last, marker="o", linewidth=2, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(tone_items)
                ax.set_title("ì°©ìƒ‰ë„")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                ax.legend()
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
            else:
                st.info("ì°©ìƒ‰ë„(L/a/b) ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            # ====== /ê·¸ë˜í”„ ì„¹ì…˜ ë ======



        else:
            st.warning("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆì—ì„œ í•´ë‹¹ ì§€ì—­ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í’ˆì¢…/ì§€ì—­ ì¡°í•©ì„ ë°”ê¿”ë³´ì„¸ìš”.")

        # ì›ìë£Œ ë‹¤ìš´ë¡œë“œ
        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì‹¤ì¸¡ ì›”ë³„ CSV",
                df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_monthly_measured.csv",
                mime="text/csv",
                disabled=df.empty
            )
        with c2:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì›”ë³„ CSV",
                filled_this_year.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_monthly_used.csv",
                mime="text/csv"
            )
        with c3:
            st.download_button(
                "â¬‡ï¸ íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ CSV",
                pred_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_predictions.csv",
                mime="text/csv"
            )
    else:
        st.info("ì¢Œì¸¡ì—ì„œ ì§€ì—­ê³¼ í’ˆì¢…ì„ ê³ ë¥¸ ë’¤ ìë™ì¡°íšŒ & ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ì˜¬í•´ ë‚¨ì€ ì›”ì€ â€˜ì˜ˆìƒ ë‚ ì”¨(ìµœê·¼ 3ë…„ ë˜ëŠ” ì „ì²´ ê³¼ê±° í‰ê· )â€™ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ==========================================================
# íƒ­1: ë¶„ì„ê²°ê³¼(êµ°ìœ„) - ì´ë¯¸ì§€/í‘œ ë·°ì–´ (í™ë¡œ/í›„ì§€)
# ==========================================================
with tab3:
    st.title("ë¶„ì„ê²°ê³¼(êµ°ìœ„)")
    BASE_DIR = Path(__file__).parent / "mba" / "ë¶„ì„ê²°ê³¼" / "êµ°ìœ„"
    CULTIVARS = ["í™ë¡œ", "í›„ì§€"]

    # ê²°ê³¼ ìì‚°(ì´ë¯¸ì§€/í‘œ) ìë™ ê²€ìƒ‰: í•˜ìœ„ì— 'í™ë¡œ','í›„ì§€' í´ë”ê°€ ìˆê±°ë‚˜, íŒŒì¼ëª…ì— í’ˆì¢…ëª…ì´ ë“¤ì–´ìˆëŠ” ê²½ìš° ëª¨ë‘ ì§€ì›
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    TAB_EXT = (".csv", ".xlsx")

    def get_assets_for_cultivar(cultivar: str):
        # 1) í´ë” ëª¨ë“œ: BASE_DIR/í™ë¡œ, BASE_DIR/í›„ì§€ ì¡´ì¬ ì‹œ
        folder1 = BASE_DIR / cultivar
        if folder1.exists():
            imgs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in IMG_EXT])
            tabs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in TAB_EXT])
            root = folder1
        else:
            # 2) íŒŒì¼ëª… í•„í„° ëª¨ë“œ: BASE_DIR ë‚´ íŒŒì¼ëª…ì— í’ˆì¢… í¬í•¨
            imgs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in IMG_EXT and cultivar in p.stem)])
            tabs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in TAB_EXT and cultivar in p.stem)])
            root = BASE_DIR
        return root, imgs, tabs

    cultivar = st.radio("í’ˆì¢… ì„ íƒ", CULTIVARS, horizontal=True, key="radio_tab2")

    folder, all_imgs, all_tabs = get_assets_for_cultivar(cultivar)
    if not BASE_DIR.exists():
        st.error(f"êµ°ìœ„ ê²°ê³¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {BASE_DIR}")
        st.stop()

    mode = st.segmented_control("í‘œì‹œ ìœ í˜•", options=["ì´ë¯¸ì§€", "í‘œ(ë°ì´í„°)"], key="seg_tab2")
    if mode == "ì´ë¯¸ì§€":
        if not all_imgs:
            st.warning("í‘œì‹œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ/íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”)")
        else:
            view = st.radio("ë°©ì‹ ì„ íƒ", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ íŒŒì¼"], horizontal=True, key="view_tab2")
            if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
                thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4, key="thumbs_slider_tab3")
                rows = (len(all_imgs) + thumbs - 1) // thumbs
                st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
                idx = 0
                for _ in range(rows):
                    cols = st.columns(thumbs, gap="small")
                    for c in cols:
                        if idx >= len(all_imgs):
                            break
                        p = all_imgs[idx]
                        with c:
                            st.image(str(p), caption=str(p.relative_to(folder)))
                        idx += 1
            else:
                sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [str(p.relative_to(folder)) for p in all_imgs])
                path = folder / sel
                st.image(str(path), caption=str(path))
    else:
        if not all_tabs:
            st.warning("í‘œì‹œí•  CSV/XLSX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sel = st.selectbox("í‘œ ì„ íƒ", [str(p.relative_to(folder)) for p in all_tabs])
            path = folder / sel
            st.subheader("í‘œì‹œ ì¤‘: " + str(path.name))
            try:
                if path.suffix.lower() == ".csv":
                    df = pd.read_csv(path, encoding="utf-8-sig")
                else:
                    df = pd.read_excel(path)
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# ==========================================================
# íƒ­2: ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„ ê³ ì •)
# ==========================================================
with tab4:
    st.markdown("ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„)")

    # ---------------------------
    # ì§€ì—­/ì½”ë“œ: êµ°ìœ„ ì „ìš©
    # ---------------------------
    AREA_CODE = {"ëŒ€êµ¬êµ°ìœ„": "333"}  # APIìš© í‚¤
    REGION_NAME_MAP = {"ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„"}  # í™”ë©´ í‘œì‹œëª…

    # ---------------------------
    # íšŒê·€ì‹ (êµ°ìœ„ìš©)
    # ---------------------------
    EQUATIONS_BY_CULTIVAR = {
    "í™ë¡œ": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 157.237 -137.847Â·í‰ê· í’ì†_mean_m08 +1.312Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.205849Â·ê°•ìš°ëŸ‰_sum_m05 +3.9929Â·ìµœì €ê¸°ì˜¨_mean_m07",
        "ì¢…ê²½": "ì¢…ê²½ = 36.9151 +0.613954Â·ìµœì €ê¸°ì˜¨_mean_m04 +0.244159Â·ìŠµë„_mean_m04 +0.577148Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.0405461Â·ê°•ìš°ëŸ‰_sum_m05",
        "íš¡ê²½": "íš¡ê²½ = 89.2207 -19.1684Â·í‰ê· í’ì†_mean_m08 +0.00285688Â·ê²°ë¡œì‹œê°„_mean_m04 +0.0137361Â·ê°•ìš°ëŸ‰_sum_m05",
        "L":   "L = -107.653 +4.02276Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.557626Â·ìµœê³ ê¸°ì˜¨_mean_m08 +0.357053Â·ìŠµë„_mean_m05 +1.23389Â·ìµœëŒ€í’ì†_mean_m08 +5.79158Â·í‰ê· í’ì†_mean_m07",
        "a":   "a = 28.916 +26.4391Â·ìµœëŒ€í’ì†_mean_m05 -2.04984Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.525233Â·í‰ê· ê¸°ì˜¨_mean_m08 -7.60126Â·ìµœëŒ€í’ì†_mean_m08 -0.0905347Â·ìŠµë„_mean_m05",
        "b":   "b = -44.3799 -0.0102677Â·ìµœëŒ€í’ì†_mean_m05 +1.63975Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.201082Â·ìŠµë„_mean_m05 +1.29407Â·ìµœëŒ€í’ì†_mean_m08",
        "ê²½ë„": "ê²½ë„ = 53.7403 +0.0406574Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0109639Â·ê²°ë¡œì‹œê°„_mean_m04 -5.99111Â·ìµœëŒ€í’ì†_mean_m05 +0.00101735Â·ê²°ë¡œì‹œê°„_mean_m05",
        "ë‹¹ë„": "ë‹¹ë„ = -3.77559 +0.845922Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.000435945Â·ê°•ìš°ëŸ‰_sum_m07 +0.00284123Â·ê²°ë¡œì‹œê°„_mean_m04 -0.343821Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.0040703Â·ê°•ìš°ëŸ‰_sum_m06",
        "ì‚°ë„": "ì‚°ë„ = 0.23201 -0.000127841Â·ê²°ë¡œì‹œê°„_mean_m05 -1.60354e-05Â·ê°•ìš°ëŸ‰_sum_m05 +0.0112801Â·í‰ê· í’ì†_mean_m06 +0.0202028Â·ìµœëŒ€í’ì†_mean_m05 -7.47002e-05Â·ê²°ë¡œì‹œê°„_mean_m04",
    },
    "í›„ì§€": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 280.193 -14.9938Â·ìµœëŒ€í’ì†_mean_m04 +7.01039Â·í‰ê· ê¸°ì˜¨_mean_m09 -0.216694Â·ì¼ì‚¬ëŸ‰_sum_m10",
        "ì¢…ê²½": "ì¢…ê²½ = 67.5821 +0.707095Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0488712Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.880706Â·ìµœê³ ê¸°ì˜¨_mean_m09",
        "íš¡ê²½": "íš¡ê²½ = 95.1048 +0.181127Â·ìŠµë„_mean_m04 -0.0132518Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.276929Â·ìŠµë„_mean_m08 +0.487867Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "L":   "L = -25.351 +0.317467Â·ìŠµë„_mean_m04 +0.063049Â·ìµœì €ê¸°ì˜¨_mean_m09 +0.310649Â·ìŠµë„_mean_m10 +1.19993Â·ìµœê³ ê¸°ì˜¨_mean_m10",
        "a":   "a = 24.306 -0.0581428Â·ê°•ìš°ëŸ‰_sum_m04 +7.83592Â·í‰ê· í’ì†_mean_m08 -0.515246Â·ìµœê³ ê¸°ì˜¨_mean_m10 +6.87267Â·í‰ê· í’ì†_mean_m05",
        "b":   "b = 18.3498 -0.0117526Â·ìŠµë„_mean_m10 -0.0255657Â·ì¼ì‚¬ëŸ‰_sum_m10 -5.44522Â·í‰ê· í’ì†_mean_m09 +0.493188Â·ìµœê³ ê¸°ì˜¨_mean_m04",
        "ê²½ë„": "ê²½ë„ = 44.1071 -0.0341814Â·ê°•ìš°ëŸ‰_sum_m10 +0.00537892Â·ê°•ìš°ëŸ‰_sum_m07 +4.75772Â·ìµœëŒ€í’ì†_mean_m08 +1.15897Â·ìµœì €ê¸°ì˜¨_mean_m04",
        "ë‹¹ë„": "ë‹¹ë„ = 7.35627 +2.56347Â·ìµœëŒ€í’ì†_mean_m08 -0.0270168Â·ìŠµë„_mean_m09 +0.0171314Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.525697Â·ìµœì €ê¸°ì˜¨_mean_m06 -0.231632Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "ì‚°ë„": "ì‚°ë„ = 1.14472 +0.169768Â·í‰ê· í’ì†_mean_m08 -0.0438612Â·ìµœê³ ê¸°ì˜¨_mean_m10 +5.80039e-05Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.103592Â·í‰ê· í’ì†_mean_m05 -0.000376686Â·ê°•ìš°ëŸ‰_sum_m04",
    },
}


    # ---------------------------
    # ìœ í‹¸/ì „ì²˜ë¦¬ í•¨ìˆ˜
    # ---------------------------
    def _clean_str(s: str) -> str:
        s = str(s).replace("\xa0", " ")
        s = s.replace("\n", " ").replace("\r", " ")
        s = re.sub(r"\s+", " ", s).strip()
        s = re.sub(r"\s*\(\s*", " (", s)
        s = re.sub(r"\s*\)\s*", ")", s)
        return s

    def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
        out = df.copy()
        if isinstance(out.columns, pd.MultiIndex):
            out.columns = [" ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                           for tup in out.columns.values]
        out.columns = [_clean_str(c) for c in out.columns]
        alias = {
            "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
            "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
            "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
        }
        out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})
        if "ì§€ì—­" in out.columns:
            out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in out.columns:
            out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")
        return out

    def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
        pat = re.compile(pattern, flags=re.IGNORECASE)
        for c in df.columns:
            if pat.search(str(c)):
                return c
        return None

    def _ensure_numeric(df: pd.DataFrame, cols):
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    def cultivar_window(cultivar: str):
        return (4, 8) if cultivar == "í™ë¡œ" else (4, 10)

    def get_today_ym():
        now = datetime.now()
        return now.year, now.month

    @st.cache_data(show_spinner=False, ttl=300)
    def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
        session = requests.Session()
        session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)
        form = {
            "pageIndex": "1",
            "searchNum": "0",
            "areaName": region_name,
            "areaCode": AREA_CODE.get(region_name, region_name),
            "statmethod": stat_gb_code,
        }
        if stat_gb_code == "A":
            form["wetherDtBgn"] = f"{s_ym}-01"; form["wetherDtEnd"] = f"{e_ym}-30"
        elif stat_gb_code in ("B", "C"):
            form["wetherDtM"] = s_ym
        else:  # "D"
            form["wetherDtBgn2"] = s_ym; form["wetherDtEnd2"] = e_ym
            form["wetherDtBgn"]  = s_ym; form["wetherDtEnd"]  = e_ym
        resp = session.post(
            "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
            data=form, timeout=30,
            headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
        )
        resp.raise_for_status()
        try:
            return resp.json()
        except Exception:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

    def json_to_dataframe(payload: dict) -> pd.DataFrame:
        if not payload or "result" not in payload:
            return pd.DataFrame()
        res = payload.get("result", [])
        if len(res) == 0:
            return pd.DataFrame()
        method = payload.get("mainAwsVO", {}).get("statmethod")
        raw = pd.DataFrame(res)
        with st.expander("ğŸ”§ API ì›ì‹œ ì»¬ëŸ¼ ë³´ê¸°", expanded=False):
            st.write(sorted(list(raw.columns)))
        rename_map = {
            "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
            "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
            "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
            "dalyWetherAvrgHd": "ìŠµë„", "WetherAvgHd": "ìŠµë„",
            "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰", "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰", "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
            "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„", "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„", "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
            "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
            "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
        }
        raw = raw.rename(columns=rename_map)
        if method == "A":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "B":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "C":
            want = ["ìˆœ","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"] if "ìˆœ" in raw.columns \
                else ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        else:
            want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
                if "ì›”" in raw.columns else \
                ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        use_cols = [c for c in want if c in raw.columns]
        if not use_cols:
            return pd.DataFrame()
        df = raw[use_cols].copy()
        numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        df = _ensure_numeric(df, [c for c in numcands if c in df.columns])
        if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
            df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
            if "ì—°ë„" not in df.columns: df["ì—°ë„"] = df["ì¼ì"].dt.year
            if "ì›”"   not in df.columns: df["ì›”"]   = df["ì¼ì"].dt.month
        elif "ì›”" in df.columns:
            df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
            df["ì›”"]   = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")
        if {"ì—°ë„","ì›”"}.issubset(df.columns):
            df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        return df

    def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(df.columns):
            return df.copy()
        agg_map = {
            "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
            "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
            "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
        }
        use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
        out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
        return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

    def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
            raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
        sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
        wide_mean = None
        for m in range(1, 12+1):
            sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        wide_sum = None
        for m in range(1, 12+1):
            sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
        return wide

    def apply_equation_row(row: pd.Series, eq_str: str) -> float:
        rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
        cols = sorted(row.index.tolist(), key=len, reverse=True)
        expr = rhs
        for c in cols:
            expr = expr.replace(c, f"row[{repr(c)}]")
        return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

    def fill_missing_or_future_with_climatology(env_m: pd.DataFrame, target_year: int, cultivar: str, mode: str = "all") -> pd.DataFrame:
        need_cols = {"ì—°ë„","ì›”"}
        if not need_cols.issubset(env_m.columns):
            raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        s_mon, e_mon = cultivar_window(cultivar)
        cur_year, cur_mon = get_today_ym()
        cur = env_m[env_m["ì—°ë„"] == target_year].copy()
        hist = env_m[env_m["ì—°ë„"] < target_year].copy()
        if hist.empty:
            return cur
        # 'all' == ì „ì²´ ê³¼ê±° í‰ê·  ì‚¬ìš©
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        climo_all = hist.groupby("ì›”", as_index=False)[num_cols].mean()
        months_window = list(range(s_mon, e_mon+1))
        have = set(cur["ì›”"].tolist())
        future_cut = cur_mon if target_year == cur_year else 12
        future_months = [m for m in months_window if (target_year == cur_year and m > future_cut) or (target_year > cur_year)]
        missing_months = [m for m in months_window if m not in have]
        to_fill = sorted(set(future_months) | set(missing_months))
        if to_fill:
            fill_rows = climo_all[climo_all["ì›”"].isin(to_fill)].copy()
            fill_rows.insert(0, "ì—°ë„", target_year)
            cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)
        cur = cur[(cur["ì›”"] >= s_mon) & (cur["ì›”"] <= e_mon)].sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        for c in num_cols:
            cur[c] = pd.to_numeric(cur[c], errors="coerce")
        return cur

    def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
        code = "apple01" if cultivar == "í›„ì§€" else "apple02"
        url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
        params = {
            "frtgrdCode": "apple",
            "selyear": str(selyear),
            "lastYear": str(lastyear),
            "searchGubun": code,
            "pageIndex": "1",
        }
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        try:
            tables = pd.read_html(io.StringIO(r.text))
        except Exception as e:
            st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹± ì‹¤íŒ¨: {e}\n(lxml/html5lib í•„ìš”)")
            return {}
        cleaned = []
        for t in tables:
            t2 = normalize_quality_columns(t)
            if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(set(t2.columns)):
                cleaned.append(t2)
        result = {}
        if len(cleaned) >= 1: result["this"] = cleaned[0]
        if len(cleaned) >= 2: result["last"] = cleaned[1]
        return result

    def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
        if qdf is None or qdf.empty: return None
        region_disp_name = _clean_str(region_disp_name)
        if "ì§€ì—­" not in qdf.columns: return None
        tmp = qdf.copy()
        tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in tmp.columns and not np.issubdtype(tmp["ìˆ˜í™•ì¼ì"].dtype, np.datetime64):
            tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
        sub = tmp[tmp["ì§€ì—­"] == region_disp_name]
        if sub.empty: return None
        sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
        return sub.iloc[0]

    # ---------------------------
    # ì¡°íšŒ/ì˜ˆì¸¡ UI (êµ°ìœ„ ê³ ì •)
    # ---------------------------
    c1, c2 = st.columns([1,1])
    with c1:
        cultivar = st.radio("í’ˆì¢… ì„ íƒ", ["í™ë¡œ", "í›„ì§€"], horizontal=True, key="radio_tab3")
    with c2:
        st.text("ì§€ì—­ ì„ íƒ")
        st.info("êµ°ìœ„(ëŒ€êµ¬êµ°ìœ„)ë¡œ ê³ ì •")
    region = "ëŒ€êµ¬êµ°ìœ„"  # ë‚´ë¶€ í‚¤
    region_disp = REGION_NAME_MAP[region]

    run = st.button("ğŸ” êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡")
    mode = "all"  # í•­ìƒ ì „ì²´ ê³¼ê±° í‰ê·  ê¸°ë°˜ìœ¼ë¡œ ë¯¸í™•ë³´ ì›” ì±„ì›€

    if run:
        try:
            cur_year, cur_month = get_today_ym()
            s_mon, e_mon = cultivar_window(cultivar)
            s_ym = f"{cur_year:04d}-{s_mon:02d}"
            e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

            with st.spinner("ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
                payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)

            if "error" in payload:
                st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.code(payload.get("raw","")[:1000])
                st.stop()

            df = json_to_dataframe(payload)
            st.subheader(f"ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡ ë°ì´í„°(ê¸°ìƒ) - {region_disp}")
            if df.empty:
                st.warning("ì˜¬í•´ ê¸°ê°„ ë‚´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±° í‰ê· ìœ¼ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            else:
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)

        env_m = df.copy()
        if not env_m.empty and "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"]   = env_m["ì›”"].astype(str).str[5:7].astype(int)

        past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
        past_df = json_to_dataframe(past_payload)
        env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m

        filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

        st.subheader("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì›”ë³„ ë°ì´í„°(ì˜¬í•´, ë¯¸ë˜ì›”ì€ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´)")
        st.dataframe(filled_this_year, use_container_width=True)

        try:
            env_for_wide = pd.concat([env_all[env_all["ì—°ë„"] != cur_year], filled_this_year], ignore_index=True)
            wide = build_wide_month_feats(env_for_wide)
        except Exception as e:
            st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            st.stop()

        if cur_year not in set(wide["ì—°ë„"].astype(int).tolist()):
            st.error("ì˜ˆì¸¡ ì—°ë„ í–‰ì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        row = wide[wide["ì—°ë„"] == cur_year].iloc[0]

        EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
        preds = {}
        for tgt, formula in EQUATIONS.items():
            try:
                preds[tgt] = apply_equation_row(row, formula)
            except Exception as e:
                preds[tgt] = f"ì—ëŸ¬: {e}"

        st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}  ì—°ë„: {cur_year}")
        pred_df = pd.DataFrame([preds]).T.reset_index()
        pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]
        st.dataframe(pred_df.set_index("í•­ëª©").T.reset_index(drop=True), use_container_width=True)

        # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë¹„êµ
        with st.spinner("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            qdict = fetch_quality_tables(cur_year, cur_year-1, cultivar)

        last_row = None
        if qdict and "last" in qdict and qdict["last"] is not None and not qdict["last"].empty:
            q_last = normalize_quality_columns(qdict["last"])
            with st.expander("ì „ë…„ë„ í…Œì´ë¸” ì‹¤ì œ ì»¬ëŸ¼ëª…(ì •ê·œí™” í›„)"):
                st.write(list(q_last.columns))
            last_row = pick_region_row(q_last, region_disp)

        if last_row is not None:
            patterns = {
                "ê³¼ì¤‘": r"^ê³¼ì¤‘",
                "ì¢…ê²½": r"^ì¢…ê²½",
                "íš¡ê²½": r"^íš¡ê²½",
                "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
                "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
                "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
                "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
                "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
                "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
            }
            def to_float(x):
                try:
                    return float(str(x).replace(",", "").strip())
                except Exception:
                    return None
            rows = []
            last_df_for_match = last_row.to_frame().T
            for k, pat in patterns.items():
                col = get_first_col_by_pattern(last_df_for_match, pat)
                last_val = to_float(last_row[col]) if col else None
                pred_val = preds.get(k, None)
                rows.append([k, pred_val, last_val])

            compare_df = pd.DataFrame(rows, columns=["í•­ëª©","ì˜ˆì¸¡ê°’(ì˜¬í•´)","ì „ë…„ë„ ì‹¤ì œê°’"])
            st.subheader(f"ì˜¬í•´ ì˜ˆì¸¡ vs ì „ë…„ë„ ì‹¤ì œ  ë¹„êµ  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}")
            compare_df_t = compare_df.set_index("í•­ëª©").T
            compare_df_t.index.name = ""
            st.dataframe(compare_df_t, use_container_width=True)

            # ì‘ì€ ì‹œê°í™”ë“¤
            PRED_COLOR = "#87CEEB"
            LAST_COLOR = "#800080"
            def _pick(df, item):
                r = df[df["í•­ëª©"] == item]
                if r.empty: return np.nan, np.nan
                p = pd.to_numeric(r["ì˜ˆì¸¡ê°’(ì˜¬í•´)"].values[0], errors="coerce")
                l = pd.to_numeric(r["ì „ë…„ë„ ì‹¤ì œê°’"].values[0], errors="coerce")
                return p, l

            size_items = ["ê³¼ì¤‘", "íš¡ê²½", "ì¢…ê²½"]
            x = np.arange(len(size_items))
            y_pred, y_last = [], []
            for it in size_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                w = 0.35
                if not all(pd.isna(y_pred)):
                    ax.bar(x - w/2, np.nan_to_num(y_pred, nan=0.0), width=w, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.bar(x + w/2, np.nan_to_num(y_last, nan=0.0), width=w, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(size_items)
                ax.set_title("ê³¼ì‹¤ í¬ê¸°")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)

            def _bar_single(item, title, ylim_top=None):
                p, l = _pick(compare_df, item)
                if pd.isna(p) and pd.isna(l): 
                    return
                xs, ys, cs = [], [], []
                if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                fig, ax = plt.subplots(figsize=(2.5, 1.8))
                ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                ax.set_title(title); ax.grid(axis="y", linestyle=":", alpha=0.35)
                if ylim_top: ax.set_ylim(top=ylim_top)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                fig.tight_layout(); st.pyplot(fig, use_container_width=False)

            c1, c2, c3 = st.columns(3)
            with c1: _bar_single("ê²½ë„", "ê²½ë„", ylim_top=70)
            with c2: _bar_single("ë‹¹ë„", "ë‹¹ë„")
            with c3: _bar_single("ì‚°ë„", "ì‚°ë„")

            tone_items = ["L", "a", "b"]
            x = np.arange(len(tone_items))
            y_pred, y_last = [], []
            for it in tone_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                if not all(pd.isna(y_pred)):
                    ax.plot(x, y_pred, marker="o", linewidth=2, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.plot(x, y_last, marker="o", linewidth=2, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(tone_items)
                ax.set_title("ì°©ìƒ‰ë„")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
        else:
            st.warning("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆì—ì„œ êµ°ìœ„ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")

        # ë‹¤ìš´ë¡œë“œë“¤
        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì‹¤ì¸¡ ì›”ë³„ CSV",
                df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_measured.csv",
                mime="text/csv",
                disabled=df.empty
            )
        with c2:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì›”ë³„ CSV",
                filled_this_year.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_used.csv",
                mime="text/csv"
            )
        with c3:
            st.download_button(
                "â¬‡ï¸ íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ CSV",
                pred_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_predictions.csv",
                mime="text/csv"
            )
    else:
        st.info("í’ˆì¢…ì„ ì„ íƒí•˜ê³  â€˜êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”.")

# ==========================================================
# íƒ­5: ì ì—½ ì „í›„ ì²˜ë¦¬ ê²°ê³¼
# ==========================================================

with tab5:
    st.title("ğŸƒ ì ì—½ ì „í›„ ì²˜ë¦¬ ê²°ê³¼")

    # ------------------------------
    # CSV ê²°ê³¼ í‘œì‹œ
    # ------------------------------
    csv_path = Path(__file__).parent / "mba" / "defoliation" / "_out" / "result.csv"
    if csv_path.exists():
        try:
            df = pd.read_csv(csv_path, encoding="utf-8-sig")
            st.subheader("ë¶„ì„ ë°ì´í„° (result.csv)")
            st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error(f"CSV ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    else:
        st.warning("result.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ------------------------------
    # Before / After Overlay ì´ë¯¸ì§€ í‘œì‹œ
    # ------------------------------
    st.subheader("Before / After Overlay ì´ë¯¸ì§€")

    img_folder = Path(__file__).parent / "mba" / "defoliation" / "_out" / "overlays"
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")

    all_imgs = sorted([p for p in img_folder.glob("*") if p.suffix.lower() in IMG_EXT])

    if not all_imgs:
        st.warning("í‘œì‹œí•  overlay ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        view = st.radio("ë³´ê¸° ë°©ì‹", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ìŒìœ¼ë¡œ ë³´ê¸°"], horizontal=True, key="view_tab5")

        if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
            thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4, key="thumbs_slider_tab5")
            rows = (len(all_imgs) + thumbs - 1) // thumbs
            st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
            idx = 0
            for _ in range(rows):
                cols = st.columns(thumbs, gap="small")
                for c in cols:
                    if idx >= len(all_imgs):
                        break
                    p = all_imgs[idx]
                    with c:
                        st.image(str(p), caption=p.name)
                    idx += 1

        else:  # ìŒìœ¼ë¡œ ë³´ê¸° (before/after ìë™ ë§¤ì¹­)
            names = sorted(set(p.name.replace("_before_overlay.jpg", "").replace("_after_overlay.jpg", "")
                               for p in all_imgs))
            sel = st.selectbox("ëŒ€ìƒ ì„ íƒ", names)
            before = img_folder / f"{sel}_before_overlay.jpg"
            after = img_folder / f"{sel}_after_overlay.jpg"

            cols = st.columns(2)
            if before.exists():
                cols[0].image(str(before), caption=f"{sel} - Before")
            else:
                cols[0].warning("Before ì´ë¯¸ì§€ ì—†ìŒ")

            if after.exists():
                cols[1].image(str(after), caption=f"{sel} - After")
            else:
                cols[1].warning("After ì´ë¯¸ì§€ ì—†ìŒ")

# ==========================================================
# íƒ­6: ê³¼ì‹¤ ì´ë¯¸ì§€ ëª¨ì–‘Â·ê¸¸ì´ ë¶„ì„ ê²°ê³¼
# ==========================================================

with tab6:
    st.title("ğŸ ê³¼ì‹¤ ì´ë¯¸ì§€ ëª¨ì–‘Â·ê¸¸ì´ ë¶„ì„ ê²°ê³¼")


    # ------------------------------
    # ê²°ê³¼ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì—‘ì…€/CSV)
    # ------------------------------
    csv_path = Path(__file__).parent / "python" / "goldenball" / "apple_pairs_results.csv"
    if csv_path.exists():
        try:
            if csv_path.suffix.lower() == ".csv":
                df = pd.read_csv(csv_path, encoding="utf-8-sig")
            else:
                df = pd.read_excel(csv_path)
            st.subheader("ğŸ“Š ê³¼ì‹¤ ë¶„ì„ ê²°ê³¼ ë°ì´í„°")
            st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error(f"CSV/XLSX ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    else:
        st.warning("apple_pairs_results íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ------------------------------
    # ì´ë¯¸ì§€ ë·°ì–´
    # ------------------------------
    st.subheader("ğŸ“· ë¶„ì„ëœ ê³¼ì‹¤ ì´ë¯¸ì§€ (Detection ê²°ê³¼)")

    img_folder = Path(__file__).parent / "python" / "goldenball" / "_debug_pairs"
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    all_imgs = sorted([p for p in img_folder.glob("*") if p.suffix.lower() in IMG_EXT])

    if not all_imgs:
        st.warning("í‘œì‹œí•  ê³¼ì‹¤ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        view = st.radio("ë³´ê¸° ë°©ì‹", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ ì„ íƒ"], horizontal=True, key="view_tab6")

        if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
            thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4, key="thumbs_slider_tab6")
            rows = (len(all_imgs) + thumbs - 1) // thumbs
            st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
            idx = 0
            for _ in range(rows):
                cols = st.columns(thumbs, gap="small")
                for c in cols:
                    if idx >= len(all_imgs):
                        break
                    p = all_imgs[idx]
                    with c:
                        st.image(str(p), caption=p.name)
                    idx += 1
        else:
            sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [p.name for p in all_imgs])
            path = img_folder / sel
            st.image(str(path), caption=str(path.name))

# ==========================================================
# íƒ­7: ì§€ì—­ ê¸°ë°˜ ì í•© í’ˆì¢… ì¶”ì²œ
# ==========================================================

with tab7:
    st.subheader("ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ / ì í•© í’ˆì¢… ì¶”ì²œ")

    # ì§€ì—­ ì„ íƒ (ë‹¨ìˆœ ì„ íƒì°½ë§Œ, ë°ì´í„° ì—†ìŒ)
    col_do, col_sigun, col_gueupmyeon = st.columns(3)
    sel_do = col_do.selectbox("ë„", ["ì„ íƒ", "ê²½ìƒë¶ë„", "ê°•ì›ë„"], key="demo_do")
    sel_sigun = col_sigun.selectbox("ì‹œ/êµ°", ["ì„ íƒ", "ì˜ì£¼ì‹œ", "êµ°ìœ„êµ°", "í‰ì°½êµ°"], key="demo_sigun")
    sel_gueupmyeon = col_gueupmyeon.selectbox("êµ¬/ì/ë©´", ["ì„ íƒ", "ë¬¸ì •ë™", "êµ°ìœ„ì", "ëŒ€ê´€ë ¹ë©´"], key="demo_gueupmyeon")

    st.divider()

    # í’ˆì¢… (ì‹¤ë°ì´í„° ì—†ìŒ, ê·¸ëƒ¥ ì˜ˆì‹œ ì„ íƒë§Œ)
    st.markdown("#### í’ˆì¢…")
    st.info("ì—¬ê¸°ì— í’ˆì¢…ì´ í‘œì‹œë©ë‹ˆë‹¤ (ë°ì´í„° ì—†ìŒ).")


    st.divider()

    # í’ˆì¢…íŠ¹ì§• / ì£¼ì˜ì‚¬í•­ (ë°ì´í„° ì—†ìŒ â†’ ì•ˆë‚´ ë¬¸êµ¬ë§Œ)
    st.markdown("#### í’ˆì¢…íŠ¹ì§•")
    st.info("ì—¬ê¸°ì— í’ˆì¢…íŠ¹ì§•ì´ í‘œì‹œë©ë‹ˆë‹¤ (ë°ì´í„° ì—†ìŒ).")

    st.markdown("#### ì£¼ì˜ì‚¬í•­")
    st.info("ì—¬ê¸°ì— ì£¼ì˜ì‚¬í•­ì´ í‘œì‹œë©ë‹ˆë‹¤ (ë°ì´í„° ì—†ìŒ).")

    st.caption("â€» í˜„ì¬ëŠ” ë‹¨ìˆœ UI ë°ëª¨ì´ë©°, ì‹¤ì œ ë°ì´í„°ëŠ” ì—°ë™ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
