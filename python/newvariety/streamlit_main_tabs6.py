# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import requests
import io
import re
import os
# ===== ê³µí†µ ìœ í‹¸ & ê²½ë¡œ (íƒ­5Â·6 ì „ìš©) =====
import statsmodels.api as sm

# ì‹¤ì œ êµ¬í˜„ ì „ê¹Œì§€ ì„ì‹œ ë”ë¯¸ â€” ì¼ë‹¨ í™”ë©´ë§Œ ë³´ì´ê²Œ
def gw_load_merged_dataset():
    import pandas as pd
    # ì‹¤ì œì—ì„  (merged_all, fruit_agg, env_mwide, bio_y, meta) ë°˜í™˜í•´ì•¼ í•¨
    # meta = (í’ˆì¢…ì»¬ëŸ¼ëª…, ê³¼ì‹¤ìˆ«ìíƒ€ê¹ƒë“¤, ê³µí†µì—°ë„ë¦¬ìŠ¤íŠ¸)
    return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), ("cultivar", [], [])

def gw_list_available_cultivars():
    return ["í™ë¡œ", "í›„ì§€"]

def gw_load_selected_vars(cv):
    import pandas as pd
    # targetë³„ ì„ íƒë³€ìˆ˜ (ë…¼ë¬¸ì‹)
    return pd.DataFrame({"target": ["ê³¼ì¤‘"], "vars_list": [["BIO1", "BIO2"]]})

def gw_fit_ols(g, tgt, xcols):
    import pandas as pd
    # ì‹¤ì œì—ì„  OLS ì í•©/í‰ê°€ ë¦¬í„´
    class DummyModel:
        @property
        def model(self):
            class M: 
                exog_names = ["const"] + xcols
            return M()
        @property
        def params(self):
            import pandas as pd
            return pd.Series([0.0] * (1 + len(xcols)), index=["const"] + xcols)
        def predict(self, X):
            return pd.Series([0.0] * len(X))
    sub = pd.DataFrame({"year":[2024], tgt:[0.0], **{c:[0.0] for c in xcols}})
    mets = {"R2": 0.0, "RMSE": 0.0}
    return DummyModel(), sub, pd.Series([0.0]), mets

# í’ˆì¢…ë³„ ì‚¬ìš©ì›” (íƒ­5/6ì—ì„œ í•„í„°ë§ì— ì‚¬ìš©)
GW_MONTH_RANGE = {"í™ë¡œ": list(range(4,9)), "í›„ì§€": list(range(4,11))}

# íƒ­5/6 ì‹œê°í™” ë„ì›€(í¬ê¸°/í†¤ì„ ê¸°ì¡´ íƒ­ê³¼ ë§ì¶¤: ì‘ê³  ë‹´ë°±)
def gw_plot_coefficients(model, title=None):
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots(figsize=(3.5, 2.6))
    ax.set_title(title or "Coefficients")
    ax.grid(axis="y", linestyle=":", alpha=0.35)
    ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
    fig.tight_layout()
    st.pyplot(fig, use_container_width=False)

def gw_plot_observed_vs_pred(sub, yhat, tgt, title=None):
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots(figsize=(3.5, 2.6))
    ax.plot(sub[tgt].values, label="Observed", marker="o")
    ax.plot(yhat.values, label="Pred", marker="o")
    ax.set_title(title or "Observed vs Predicted")
    ax.grid(axis="y", linestyle=":", alpha=0.35)
    ax.legend()
    ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
    fig.tight_layout()
    st.pyplot(fig, use_container_width=False)

def gw_plot_metric_bar(metric, value):
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots(figsize=(2.5, 1.8))
    ax.bar([metric], [value])
    ax.set_title(metric)
    ax.grid(axis="y", linestyle=":", alpha=0.35)
    ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
    fig.tight_layout()
    st.pyplot(fig, use_container_width=False)
# ===== /ê³µí†µ ìœ í‹¸ ë =====

# ì²«ë²ˆì§¸ íƒ­: ë¶„ì„ê²°ê³¼ (tab1~6)
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
    ["ë¶„ì„ê²°ê³¼", "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡", "ë¶„ì„ê²°ê³¼(êµ°ìœ„)", "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„)", "ë¶„ì„ê²°ê³¼(êµ°ìœ„Â·ë…¼ë¬¸ì‹)", "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„Â·ë…¼ë¬¸ì‹)"]
)


with tab1:
    st.title("ë¶„ì„ ê²°ê³¼")
    BASE_DIR = Path(r"C:\Users\User\Desktop\mba\ë¶„ì„ê²°ê³¼\ê´€ê³„ì‹œê°í™”2")
    CULTIVAR_DIRS = {
        "í™ë¡œ": BASE_DIR / "í™ë¡œ",
        "í›„ì§€": BASE_DIR / "í›„ì§€",
    }
    cultivar = st.radio("í’ˆì¢… ì„ íƒ", list(CULTIVAR_DIRS.keys()), horizontal=True, key="radio_tab1")
    folder = CULTIVAR_DIRS[cultivar]
    if not folder.exists():
        st.error("í•´ë‹¹ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ ì˜¤íƒ€ ë˜ëŠ” ë“œë¼ì´ë¸Œ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    TAB_EXT = (".csv", ".xlsx")
    all_imgs = sorted([p for p in folder.rglob("*") if p.suffix.lower() in IMG_EXT])
    all_tabs = sorted([p for p in folder.rglob("*") if p.suffix.lower() in TAB_EXT])
    mode = st.segmented_control("í‘œì‹œ ìœ í˜•", options=["ì´ë¯¸ì§€", "í‘œ(ë°ì´í„°)"], key="seg_tab1")
    if mode == "ì´ë¯¸ì§€":
        if not all_imgs:
            st.warning("í‘œì‹œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            view = st.radio("ë°©ì‹ ì„ íƒ", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ íŒŒì¼"], horizontal=True, key="view_tab1")
            if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
                thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4)
                rows = (len(all_imgs) + thumbs - 1) // thumbs
                st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
                idx = 0
                for _ in range(rows):
                    cols = st.columns(thumbs, gap="small")
                    for c in cols:
                        if idx >= len(all_imgs):
                            break
                        p = all_imgs[idx]
                        with c:
                            st.image(str(p), caption=str(p.relative_to(folder)))
                        idx += 1
            else:
                sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [str(p.relative_to(folder)) for p in all_imgs])
                path = folder / sel
                st.image(str(path), caption=str(path))
    else:
        if not all_tabs:
            st.warning("í‘œì‹œí•  CSV/XLSX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            path = all_tabs[0]
            st.subheader("ì˜ˆì¸¡ ì •í™•ë„")
            try:
                if path.suffix.lower() == ".csv":
                    df = pd.read_csv(path)
                else:
                    df = pd.read_excel(path)
                st.dataframe(df)
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# ë‘ë²ˆì§¸ íƒ­: ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ (3. streamlit(í™ë¡œ,í›„ì§€4~)_ìˆ˜ì •3.py)
with tab2:
   # -*- coding: utf-8 -*-
# íŒŒì¼ëª…: ê¸°ìƒìë™ë¶ˆëŸ¬ì˜¤ê¸°3.py
    import streamlit as st
    import pandas as pd
    import numpy as np
    import requests
    from datetime import datetime
    import io
    import matplotlib.pyplot as plt
    from typing import Optional
    import re

    # â–¶ í•œê¸€ í°íŠ¸ ìë™ ì„¤ì •
    import matplotlib
    import matplotlib.font_manager as fm
    import os

    plt.rcParams["font.size"] = 6

    def _set_korean_font():
        bundled_candidates = [
            "fonts/NanumGothic.ttf",
            "fonts/NotoSansKR-Regular.otf",
            "NanumGothic.ttf",
            "NotoSansKR-Regular.otf",
        ]
        for p in bundled_candidates:
            if os.path.exists(p):
                try:
                    fm.fontManager.addfont(p)
                    family = fm.FontProperties(fname=p).get_name()
                    matplotlib.rcParams["font.family"] = family
                    matplotlib.rcParams["axes.unicode_minus"] = False
                    return
                except Exception:
                    pass
        preferred = ["Malgun Gothic", "AppleGothic", "NanumGothic",
                    "Noto Sans CJK KR", "Noto Sans KR", "NanumBarunGothic"]
        sys_fonts = set(f.name for f in fm.fontManager.ttflist)
        for name in preferred:
            if name in sys_fonts:
                matplotlib.rcParams["font.family"] = name
                matplotlib.rcParams["axes.unicode_minus"] = False
                return
        matplotlib.rcParams["axes.unicode_minus"] = False
        st.warning("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. fonts/ í´ë”ì— ë‚˜ëˆ”ê³ ë”•(NanumGothic.ttf) ë“±ì„ ë„£ì–´ì£¼ì„¸ìš”.")

    _set_korean_font()

    # ---------------------------
    # ê³µí†µ ìœ í‹¸: ë¬¸ìì—´/í’ˆì§ˆí‘œ ì •ê·œí™”
    # ---------------------------
    def _clean_str(s: str) -> str:
        s = str(s)
        s = s.replace("\xa0", " ")                 # NBSP -> space
        s = s.replace("\n", " ").replace("\r", " ")
        s = re.sub(r"\s+", " ", s).strip()
        s = re.sub(r"\s*\(\s*", " (", s)          # "( " -> " ("
        s = re.sub(r"\s*\)\s*", ")", s)           # " )" -> ")"
        return s

    def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
        """ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í…Œì´ë¸”: ë©€í‹°í—¤ë”/ê³µë°±/ê¸°í˜¸ ì •ë¦¬ + ì§€ì—­/ìˆ˜í™•ì¼ì ì •ê·œí™”"""
        out = df.copy()

        # ë©€í‹°í—¤ë” â†’ ë‹¨ì¼ ë¬¸ìì—´
        if isinstance(out.columns, pd.MultiIndex):
            out.columns = [" ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                        for tup in out.columns.values]

        # í—¤ë” í´ë¦°ì—…
        out.columns = [_clean_str(c) for c in out.columns]

        # í”í•œ ë³„ì¹­ í†µì¼
        alias = {
            "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
            "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
            "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
        }
        out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})

        # ì§€ì—­/ìˆ˜í™•ì¼ì ì •ë¦¬
        if "ì§€ì—­" in out.columns:
            out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in out.columns:
            out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")

        return out

    def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
        """ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ì»¬ëŸ¼ëª… 1ê°œ ì°¾ê¸°(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)"""
        pat = re.compile(pattern, flags=re.IGNORECASE)
        for c in df.columns:
            if pat.search(str(c)):
                return c
        return None

    # -------------------------------------------------
    # ê¸°ë³¸ UI
    # -------------------------------------------------

    st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡", layout="wide")
    st.markdown("<h1 style='text-align: center;'>ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡</h1>", unsafe_allow_html=True)

    # -------------------------------------------------
    # ì§€ì—­ ì½”ë“œ
    # -------------------------------------------------
    AREA_CODE = {
        "ê²½ê¸°í™”ì„±": "324",
        "ê²½ë¶ì˜ì£¼": "331",
        "ê²½ë¶ì²­ì†¡": "332",
        "ëŒ€êµ¬êµ°ìœ„": "333",
        "ê²½ë‚¨ê±°ì°½": "334",
        "ì „ë¶ì¥ìˆ˜": "335",
        "ê²½ê¸°í¬ì²œ": "337",
        "ì¶©ë¶ì¶©ì£¼": "338",
    }

    # ê³¼ì‹¤í’ˆì§ˆ í˜ì´ì§€ì˜ ì§€ì—­ í‘œê¸° ë§¤í•‘
    REGION_NAME_MAP = {
        "ê²½ê¸°í™”ì„±": "í™”ì„±",
        "ê²½ë¶ì˜ì£¼": "ì˜ì£¼",
        "ê²½ë¶ì²­ì†¡": "ì²­ì†¡",
        "ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„",
        "ê²½ë‚¨ê±°ì°½": "ê±°ì°½",
        "ì „ë¶ì¥ìˆ˜": "ì¥ìˆ˜",
        "ê²½ê¸°í¬ì²œ": "í¬ì²œ",
        "ì¶©ë¶ì¶©ì£¼": "ì¶©ì£¼",
    }

    # -------------------------------------------------
    # íšŒê·€ì‹
    # -------------------------------------------------
    EQUATIONS_BY_CULTIVAR = {
        "í™ë¡œ": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 667.243 -0.597465Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.376337Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.0756442Â·ì¼ì‚¬ëŸ‰_sum_m08 +24.5342Â·í‰ê· í’ì†_mean_m06 +5.05212Â·ìµœì €ê¸°ì˜¨_mean_m06",
            "ì¢…ê²½": "ì¢…ê²½ = 124.046 -0.0439843Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.0673823Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.397906Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.559339Â·í‰ê· í’ì†_mean_m06 +7.43416Â·í‰ê· í’ì†_mean_m05 +0.00854761Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.15116Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.05474Â·ìµœì €ê¸°ì˜¨_mean_m05 -2.574Â·ìµœëŒ€í’ì†_mean_m04",
            "íš¡ê²½": "íš¡ê²½ = 141.358 -0.0531011Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.0459844Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.00297393Â·ì¼ì‚¬ëŸ‰_sum_m08",
            "L":   "L = -68.3528 +2.1686e-05Â·ê°•ìš°ëŸ‰_sum_m07 +0.653086Â·ìŠµë„_mean_m07 +2.72693Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.14857Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.00918464Â·ê°•ìš°ëŸ‰_sum_m06 -1.52125Â·ìµœì €ê¸°ì˜¨_mean_m05 -6.00147Â·í‰ê· í’ì†_mean_m06 +3.14509Â·ìµœëŒ€í’ì†_mean_m06 +4.16545Â·í‰ê· í’ì†_mean_m07",
            "a":   "a = 226.087 -1.71711Â·ìŠµë„_mean_m07 +0.00830904Â·ê°•ìš°ëŸ‰_sum_m07 -4.51272Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.51756Â·ìµœì €ê¸°ì˜¨_mean_m05 -1.94971Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.040713Â·ì¼ì‚¬ëŸ‰_sum_m07 -0.0185248Â·ê°•ìš°ëŸ‰_sum_m06 +0.00975096Â·ê°•ìš°ëŸ‰_sum_m08 +1.93026Â·ìµœê³ ê¸°ì˜¨_mean_m07 -0.192988Â·í‰ê· í’ì†_mean_m06",
            "b":   "b = -23.7933 +0.381237Â·ìŠµë„_mean_m07 +0.0052134Â·ê°•ìš°ëŸ‰_sum_m06 +0.0606139Â·ìŠµë„_mean_m05 +1.14817Â·ìµœì €ê¸°ì˜¨_mean_m06 +0.682908Â·í‰ê· í’ì†_mean_m07 -0.523353Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.350293Â·ìµœê³ ê¸°ì˜¨_mean_m05 -0.00264168Â·ê°•ìš°ëŸ‰_sum_m08 -1.23413Â·í‰ê· í’ì†_mean_m08 +0.652516Â·ìµœëŒ€í’ì†_mean_m06",
            "ê²½ë„": "ê²½ë„ = 54.6658 +0.2039Â·ìŠµë„_mean_m04 +0.0144323Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.194462Â·ìŠµë„_mean_m08 -0.0140798Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.00218425Â·ê²°ë¡œì‹œê°„_mean_m04 +0.364872Â·í‰ê· ê¸°ì˜¨_mean_m08",
            "ë‹¹ë„": "ë‹¹ë„ = 1.14467 -0.425354Â·ìµœëŒ€í’ì†_mean_m06 -1.03279Â·í‰ê· í’ì†_mean_m07 -0.0754722Â·í‰ê· í’ì†_mean_m08 +0.781233Â·í‰ê· í’ì†_mean_m04 -0.0277847Â·ìµœê³ ê¸°ì˜¨_mean_m08 -0.0127413Â·ìŠµë„_mean_m05 +0.0022906Â·ê²°ë¡œì‹œê°„_mean_m05 +0.259103Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.0923847Â·ìŠµë„_mean_m04 +0.410232Â·ìµœëŒ€í’ì†_mean_m04 -0.00215038Â·ê°•ìš°ëŸ‰_sum_m06",
            "ì‚°ë„": "ì‚°ë„ = 0.262689 +0.0555189Â·ìµœëŒ€í’ì†_mean_m06 +0.0451885Â·í‰ê· í’ì†_mean_m08 -0.0549304Â·í‰ê· í’ì†_mean_m04 -0.00534754Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.0236952Â·í‰ê· í’ì†_mean_m07 -0.00264247Â·ìŠµë„_mean_m04 +0.00413186Â·ìŠµë„_mean_m08 -0.00334177Â·í‰ê· ê¸°ì˜¨_mean_m07 +0.000124634Â·ê°•ìš°ëŸ‰_sum_m06 -0.001393Â·ìŠµë„_mean_m05",
        },
        "í›„ì§€": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 399.484 -0.229845Â·ì¼ì‚¬ëŸ‰_sum_m04 +6.76485Â·ìµœì €ê¸°ì˜¨_mean_m05 -17.8404Â·ìµœëŒ€í’ì†_mean_m07",
            "ì¢…ê²½": "ì¢…ê²½ = 183.553 -0.0439139Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.626045Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0145561Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.955631Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.0373121Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.656449Â·ìŠµë„_mean_m08 -0.0131851Â·ìŠµë„_mean_m06 +1.16239Â·í‰ê· ê¸°ì˜¨_mean_m07 -1.16892Â·ìµœì €ê¸°ì˜¨_mean_m09 -0.420997Â·ìŠµë„_mean_m09",
            "íš¡ê²½": "íš¡ê²½ = 79.6808 -1.82161Â·ìµœëŒ€í’ì†_mean_m07 +0.796471Â·í‰ê· ê¸°ì˜¨_mean_m05",
            "L":   "L = 75.7441 -0.134414Â·ìŠµë„_mean_m08 -0.400198Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0159958Â·ê°•ìš°ëŸ‰_sum_m10 +0.0240315Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.812706Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0812023Â·ìŠµë„_mean_m04 -0.206954Â·ìŠµë„_mean_m06 +0.116267Â·ìŠµë„_mean_m10 -0.0069829Â·ì¼ì‚¬ëŸ‰_sum_m04 -2.452Â·í‰ê· í’ì†_mean_m04 -0.0989298Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.384125Â·í‰ê· ê¸°ì˜¨_mean_m07",
            "a":   "a = 4.0922 -0.0203282Â·ê°•ìš°ëŸ‰_sum_m10 -2.85393Â·ìµœëŒ€í’ì†_mean_m05 -0.00910066Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0392451Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.307386Â·ìŠµë„_mean_m08 +0.000860505Â·ê°•ìš°ëŸ‰_sum_m08 -0.688696Â·ìµœëŒ€í’ì†_mean_m08 -0.00144964Â·ì¼ì‚¬ëŸ‰_sum_m05 +0.758309Â·ìµœëŒ€í’ì†_mean_m07",
            "b":   "b = 12.841 -0.0308293Â·ìŠµë„_mean_m08 +0.0145751Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.00322966Â·ê°•ìš°ëŸ‰_sum_m08 +0.035395Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0796701Â·ìŠµë„_mean_m10 -0.000543608Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00337387Â·ê°•ìš°ëŸ‰_sum_m10 -0.00372859Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.14243Â·ìŠµë„_mean_m06 +0.0641568Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.14721Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.53868Â·í‰ê· í’ì†_mean_m04",
            "ê²½ë„": "ê²½ë„ = 8.39888 +0.0529999Â·ì¼ì‚¬ëŸ‰_sum_m09 +6.94666Â·í‰ê· í’ì†_mean_m07 +3.98929Â·ìµœëŒ€í’ì†_mean_m08 -0.0451264Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.406065Â·ìŠµë„_mean_m04 -3.47701Â·í‰ê· í’ì†_mean_m06 -0.00806023Â·ê²°ë¡œì‹œê°„_mean_m10 +0.0392251Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00773583Â·ê²°ë¡œì‹œê°„_mean_m09 -2.0759Â·ìµœëŒ€í’ì†_mean_m10 +0.000289527Â·ê²°ë¡œì‹œê°„_mean_m06 -2.8229Â·ìµœëŒ€í’ì†_mean_m05 +0.000106158Â·ê²°ë¡œì‹œê°„_mean_m05 +0.270037Â·ìµœê³ ê¸°ì˜¨_mean_m09",
            "ë‹¹ë„": "ë‹¹ë„ = 10.492 +0.00486017Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00146432Â·ê²°ë¡œì‹œê°„_mean_m10 +0.00262004Â·ê²°ë¡œì‹œê°„_mean_m07 -0.00156465Â·ê²°ë¡œì‹œê°„_mean_m09 -1.20735Â·í‰ê· í’ì†_mean_m10 -0.000317261Â·ê²°ë¡œì‹œê°„_mean_m05",
            "ì‚°ë„": "ì‚°ë„ = 0.766184 -0.0175941Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.00379855Â·ìŠµë„_mean_m04 -0.00807644Â·ìµœê³ ê¸°ì˜¨_mean_m04 -4.6679e-05Â·ê°•ìš°ëŸ‰_sum_m08 +0.00318949Â·ìµœê³ ê¸°ì˜¨_mean_m08 -8.77968e-05Â·ê°•ìš°ëŸ‰_sum_m10 -0.00456198Â·í‰ê· í’ì†_mean_m04 +0.00411344Â·ìµœê³ ê¸°ì˜¨_mean_m07",
        },
    }

    # -------------------------------------------------
    # ìœ í‹¸
    # -------------------------------------------------
    def _ensure_numeric(df: pd.DataFrame, cols):
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    def cultivar_window(cultivar: str):
        if cultivar == "í™ë¡œ":
            return 4, 8
        return 4, 10  # í›„ì§€ ê¸°ë³¸

    def get_today_ym():
        now = datetime.now()
        return now.year, now.month

    # -------------------------------------------------
    # ì‚¬ì´íŠ¸ AJAX â†’ JSON (AWS í†µê³„)
    # -------------------------------------------------
    @st.cache_data(show_spinner=False, ttl=300)
    def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
        session = requests.Session()
        session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)

        form = {
            "pageIndex": "1",
            "searchNum": "0",
            "areaName": region_name,
            "areaCode": AREA_CODE.get(region_name, region_name),
            "statmethod": stat_gb_code,
        }
        if stat_gb_code == "A":
            form["wetherDtBgn"] = f"{s_ym}-01"
            form["wetherDtEnd"] = f"{e_ym}-30"
        elif stat_gb_code in ("B", "C"):
            form["wetherDtM"] = s_ym
        elif stat_gb_code == "D":
            form["wetherDtBgn2"] = s_ym
            form["wetherDtEnd2"] = e_ym
            form["wetherDtBgn"] = s_ym
            form["wetherDtEnd"] = e_ym

        resp = session.post(
            "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
            data=form, timeout=30,
            headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
        )
        resp.raise_for_status()
        try:
            return resp.json()
        except Exception:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

    # -------------------------------------------------
    # JSON â†’ í‘œ
    # -------------------------------------------------
    def json_to_dataframe(payload: dict) -> pd.DataFrame:
        if not payload or "result" not in payload:
            return pd.DataFrame()
        res = payload.get("result", [])
        if len(res) == 0:
            return pd.DataFrame()

        method = payload.get("mainAwsVO", {}).get("statmethod")
        raw = pd.DataFrame(res)

        with st.expander("ğŸ”§ API ì›ì‹œ ì»¬ëŸ¼ ë³´ê¸°", expanded=False):
            st.write(sorted(list(raw.columns)))

        rename_map = {
            "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
            "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
            "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
            "dalyWetherAvrgHd": "ìŠµë„",     "WetherAvgHd": "ìŠµë„",
            "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰",
            "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰",
            "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
            "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„",
            "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„",
            "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
            "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
            "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
        }
        raw = raw.rename(columns=rename_map)

        if method == "A":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "B":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "C":
            want = ["ìˆœ","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"] if "ìˆœ" in raw.columns \
                else ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        else:  # "D"
            want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
                if "ì›”" in raw.columns else \
                ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]

        use_cols = [c for c in want if c in raw.columns]
        if not use_cols:
            return pd.DataFrame()
        df = raw[use_cols].copy()

        numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        df = _ensure_numeric(df, [c for c in numcands if c in df.columns])

        if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
            df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
            if "ì—°ë„" not in df.columns:
                df["ì—°ë„"] = df["ì¼ì"].dt.year
            if "ì›”" not in df.columns:
                df["ì›”"] = df["ì¼ì"].dt.month
        elif "ì›”" in df.columns:
            df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
            df["ì›”"] = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")

        if {"ì—°ë„","ì›”"}.issubset(df.columns):
            df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        return df

    # -------------------------------------------------
    # ì¼/ìˆœ â†’ ì›”ë³„ ì§‘ê³„
    # -------------------------------------------------
    def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(df.columns):
            return df.copy()
        agg_map = {
            "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
            "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
            "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
        }
        use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
        out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
        return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

    # -------------------------------------------------
    # ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (_mean_mMM / _sum_mMM)
    # -------------------------------------------------
    def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
            raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
        sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
        wide_mean = None
        for m in range(1, 13):
            sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        wide_sum = None
        for m in range(1, 13):
            sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
        return wide

    # -------------------------------------------------
    # íšŒê·€ì‹ ì ìš©
    # -------------------------------------------------
    def apply_equation_row6(row: pd.Series, eq_str: str) -> float:
        # ì¢Œë³€ ì œê±° + ê³±ì (Â·)ì„ *ë¡œ
        rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")

        # ìˆ˜ì‹ì— ë“±ì¥í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ë³€ìˆ˜ëª…ì„ í™˜ê²½ìœ¼ë¡œ ì „ë‹¬
        # (rowì— ìˆëŠ” í‚¤ ì „ë¶€ë¥¼ ë„£ì–´ë„ ë¬¸ì œ ì—†ìŒ)
        env = {str(k): (float(row[k]) if pd.notna(row[k]) else float('nan')) for k in row.index}

        # í•„ìš”í•˜ë©´ numpyë„ ì „ë‹¬ ê°€ëŠ¥ (í˜„ì¬ ìˆ˜ì‹ì—” í•„ìš” ì—†ìŒ)
        env["np"] = np

        return float(eval(rhs, {"__builtins__": {}}, env))


    # -------------------------------------------------
    # ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°
    # -------------------------------------------------
    def fill_missing_or_future_with_climatology(env_m: pd.DataFrame, target_year: int, cultivar: str, mode: str = "last3") -> pd.DataFrame:
        need_cols = {"ì—°ë„","ì›”"}
        if not need_cols.issubset(env_m.columns):
            raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        s_mon, e_mon = cultivar_window(cultivar)
        cur_year, cur_mon = get_today_ym()

        cur = env_m[env_m["ì—°ë„"] == target_year].copy()
        hist = env_m[env_m["ì—°ë„"] < target_year].copy()
        if hist.empty:
            return cur
        if mode == "last3":
            last_years = sorted(hist["ì—°ë„"].unique())[-3:]
            hist = hist[hist["ì—°ë„"].isin(last_years)]

        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        climo = hist.groupby("ì›”", as_index=False)[num_cols].mean()

        months_window = list(range(s_mon, e_mon+1))
        have = set(cur["ì›”"].tolist())
        future_cut = cur_mon if target_year == cur_year else 12
        future_months = [m for m in months_window if (target_year == cur_year and m > future_cut) or (target_year > cur_year)]
        missing_months = [m for m in months_window if m not in have]

        to_fill = sorted(set(future_months) | set(missing_months))
        if to_fill:
            fill_rows = climo[climo["ì›”"].isin(to_fill)].copy()
            if fill_rows.empty:
                climo_all = env_m[env_m["ì—°ë„"] < target_year].groupby("ì›”", as_index=False)[num_cols].mean()
                fill_rows = climo_all[climo_all["ì›”"].isin(to_fill)].copy()
            fill_rows.insert(0, "ì—°ë„", target_year)
            cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)

        cur = cur[(cur["ì›”"] >= s_mon) & (cur["ì›”"] <= e_mon)]
        cur = cur.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        for c in num_cols:
            cur[c] = pd.to_numeric(cur[c], errors="coerce")
        return cur

    # -------------------------------------------------
    # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í…Œì´ë¸”
    # -------------------------------------------------
    @st.cache_data(show_spinner=False, ttl=3600)
    def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
        code = "apple01" if cultivar == "í›„ì§€" else "apple02"
        url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
        params = {
            "frtgrdCode": "apple",
            "selyear": str(selyear),
            "lastYear": str(lastyear),
            "searchGubun": code,
            "pageIndex": "1",
        }
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        try:
            import io as _io
            tables = pd.read_html(_io.StringIO(r.text))
        except Exception as e:
            st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\n"
                    "lxml/html5lib ì„¤ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”. (pip install lxml html5lib)")
            return {}

        cleaned = []
        for t in tables:
            t2 = normalize_quality_columns(t)
            if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(set(t2.columns)):
                cleaned.append(t2)

        result = {}
        if len(cleaned) >= 1:
            result["this"] = cleaned[0]
        if len(cleaned) >= 2:
            result["last"] = cleaned[1]
        return result

    def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
        if qdf is None or qdf.empty:
            return None
        region_disp_name = _clean_str(region_disp_name)
        if "ì§€ì—­" not in qdf.columns:
            return None
        tmp = qdf.copy()
        tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in tmp.columns and not np.issubdtype(tmp["ìˆ˜í™•ì¼ì"].dtype, np.datetime64):
            tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
        sub = tmp[tmp["ì§€ì—­"] == region_disp_name]
        if sub.empty:
            return None
        sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
        return sub.iloc[0]

    # -------------------------------------------------
    # ì‚¬ì´ë“œë°”
    # -------------------------------------------------
    # -------------------------------------------------
    # ì¡°íšŒ ì¡°ê±´ (ë©”ì¸ í™”ë©´ ìƒë‹¨ì— í‘œì‹œ)
    # -------------------------------------------------

    # í’ˆì¢… ì„ íƒ (ë¼ë””ì˜¤ ë²„íŠ¼)

    cultivar = st.radio(
    "í’ˆì¢… ì„ íƒ", ["í™ë¡œ", "í›„ì§€"], key="cultivar_radio"
)


    # ì§€ì—­ ì„ íƒ (ë“œë¡­ë‹¤ìš´)

    region = st.selectbox(
        "ì§€ì—­ ì„ íƒ",
        list(AREA_CODE.keys()),
        index=1
    )

    # ğŸ” ë²„íŠ¼
    run = st.button("ğŸ” ìë™ì¡°íšŒ & ì˜ˆì¸¡")

    # ì˜ˆìƒ ë‚ ì”¨ ë°©ë²•ì€ ì œê±°í•˜ê³ , í•­ìƒ 'all'(ì „ì²´ ê³¼ê±° í‰ê· )ìœ¼ë¡œ ê³ ì •
    mode = "all"


    # -------------------------------------------------
    # ì‹¤í–‰
    # -------------------------------------------------
    if run:
        try:
            cur_year, cur_month = get_today_ym()
            s_mon, e_mon = cultivar_window(cultivar)
            s_ym = f"{cur_year:04d}-{s_mon:02d}"
            e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

            with st.spinner("ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
                payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)

            if "error" in payload:
                st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.code(payload.get("raw","")[:1000])
                st.stop()

            df = json_to_dataframe(payload)
            st.subheader("ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡ ë°ì´í„°(ê¸°ìƒ)")
            if df.empty:
                st.warning("ì˜¬í•´ ê¸°ê°„ ë‚´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±° ê¸°í›„í‰ë…„ë§Œìœ¼ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            else:
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì˜ˆì™¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.exception(e)

        env_m = df.copy()
        if not env_m.empty and "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"] = env_m["ì›”"].astype(str).str[5:7].astype(int)

        past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
        past_df = json_to_dataframe(past_payload)
        env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m

        filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

        st.subheader("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì›”ë³„ ë°ì´í„°(ì˜¬í•´, ë¯¸ë˜ì›”ì€ ì˜ˆìƒ ë‚ ì”¨ë¡œ ëŒ€ì²´)")
        st.dataframe(filled_this_year, use_container_width=True)

        try:
            env_for_wide = pd.concat([env_all[env_all["ì—°ë„"] != cur_year], filled_this_year], ignore_index=True)
            wide = build_wide_month_feats(env_for_wide)
        except Exception as e:
            st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            st.stop()

        if cur_year not in set(wide["ì—°ë„"].astype(int).tolist()):
            st.error("ì˜ˆì¸¡ ì—°ë„ í–‰ì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        row = wide[wide["ì—°ë„"] == cur_year].iloc[0]

        EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
        preds = {}
        for tgt, formula in EQUATIONS.items():
            try:
                preds[tgt] = apply_equation_row(row, formula)
            except Exception as e:
                preds[tgt] = f"ì—ëŸ¬: {e}"

        st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  í’ˆì¢…: {cultivar}  ì—°ë„: {cur_year}")

        pred_df = pd.DataFrame([preds]).T.reset_index()
        pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]

        # í–‰/ì—´ ë°”ê¾¸ê¸°
        pred_df_t = pred_df.set_index("í•­ëª©").T.reset_index(drop=True)

        st.dataframe(pred_df_t, use_container_width=True)


        # -----------------------------
        # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ ë¶ˆëŸ¬ì™€ì„œ ì§€ì—­ í–‰ ì¶”ì¶œ
        # -----------------------------
        with st.spinner("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            qdict = fetch_quality_tables(cur_year, cur_year-1, cultivar)

        region_disp = REGION_NAME_MAP.get(region, region)
        last_row = None
        if qdict and "last" in qdict and qdict["last"] is not None and not qdict["last"].empty:
            q_last = normalize_quality_columns(qdict["last"])
            with st.expander("ì „ë…„ë„ í…Œì´ë¸” ì‹¤ì œ ì»¬ëŸ¼ëª…(ì •ê·œí™” í›„)"):
                st.write(list(q_last.columns))
            last_row = pick_region_row(q_last, region_disp)

        if last_row is not None:
            # 8ê°œ ì§€í‘œë§Œ íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘
            patterns = {
                "ê³¼ì¤‘": r"^ê³¼ì¤‘",
                "ì¢…ê²½": r"^ì¢…ê²½",
                "íš¡ê²½": r"^íš¡ê²½",
                # ê²½ë„í‰ê· (N/Ã¸11mm) ì£¼ë³€ í‘œê¸° ë³€í˜• í—ˆìš©
                "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
                # Â°Brix / ËšBrix ëª¨ë‘ í—ˆìš©
                "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
                "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
                "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
                "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
                "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
            }

            def to_float(x):
                try:
                    return float(str(x).replace(",", "").strip())
                except Exception:
                    return None

            rows = []
            # last_rowëŠ” Seriesë¼ì„œ ì»¬ëŸ¼ íƒìƒ‰ì„ ìœ„í•´ 1í–‰ DataFrameìœ¼ë¡œ ë³€í™˜
            last_df_for_match = last_row.to_frame().T
            for k, pat in patterns.items():
                col = get_first_col_by_pattern(last_df_for_match, pat)
                last_val = to_float(last_row[col]) if col else None
                pred_val = preds.get(k, None)
                rows.append([k, pred_val, last_val])

            compare_df = pd.DataFrame(rows, columns=["í•­ëª©","ì˜ˆì¸¡ê°’(ì˜¬í•´)","ì „ë…„ë„ ì‹¤ì œê°’"])
            st.subheader(f"ì˜¬í•´ ì˜ˆì¸¡ vs ì „ë…„ë„ ì‹¤ì œ  ë¹„êµ  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}")

            # í•­ëª©ì„ ì—´ë¡œ, ê°’ êµ¬ë¶„ì„ ì¸ë±ìŠ¤ë¡œ
            compare_df_t = compare_df.set_index("í•­ëª©").T
            compare_df_t.index.name = ""  # ì¸ë±ìŠ¤ ì œëª© ì œê±°
            st.dataframe(compare_df_t, use_container_width=True)


            # ====== ê·¸ë˜í”„ ì„¹ì…˜ (ë ˆì´ì•„ì›ƒ/ìƒ‰ìƒ/í¬ê¸° ë°˜ì˜) ======
            PRED_COLOR = "#87CEEB"   # ì˜ˆì¸¡(ì˜¬í•´): í•˜ëŠ˜ìƒ‰
            LAST_COLOR = "#800080"   # ì „ë…„ë„: ìì¤ë¹›

            def _pick(df, item):
                r = df[df["í•­ëª©"] == item]
                if r.empty: return np.nan, np.nan
                p = pd.to_numeric(r["ì˜ˆì¸¡ê°’(ì˜¬í•´)"].values[0], errors="coerce")
                l = pd.to_numeric(r["ì „ë…„ë„ ì‹¤ì œê°’"].values[0], errors="coerce")
                return p, l

            # â”€â”€ 1) ê³¼ì‹¤ í¬ê¸°(ê³¼ì¤‘Â·íš¡ê²½Â·ì¢…ê²½ í•œ ê·¸ë˜í”„ì—)
            size_items = ["ê³¼ì¤‘", "íš¡ê²½", "ì¢…ê²½"]
            x = np.arange(len(size_items))
            y_pred = []; y_last = []
            for it in size_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))

            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                w = 0.35
                if not all(pd.isna(y_pred)):
                    ax.bar(x - w/2, np.nan_to_num(y_pred, nan=0.0), width=w, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.bar(x + w/2, np.nan_to_num(y_last, nan=0.0), width=w, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(size_items)
                ax.set_title("ê³¼ì‹¤ í¬ê¸°")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                ax.legend()
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
            else:
                st.info("ê³¼ì‹¤ í¬ê¸°(ê³¼ì¤‘/íš¡ê²½/ì¢…ê²½) ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

            # ê³µí†µ: ë‹¨ì¼ í•­ëª© ë§‰ëŒ€ ê·¸ë˜í”„(ì‘ê²Œ)
            def _bar_single(item, title):
                p, l = _pick(compare_df, item)
                if pd.isna(p) and pd.isna(l): 
                    return
                xs, ys, cs = [], [], []
                if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                fig, ax = plt.subplots(figsize=(2.5, 1.8))
                ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                ax.set_title(title)
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)

            # â”€â”€ 2) ê²½ë„, 3) ë‹¹ë„, 4) ì‚°ë„ (ê°€ë¡œë¡œ ë‚˜ë€íˆ)
            c1, c2, c3 = st.columns(3)

            with c1:
                # ê²½ë„ ê·¸ë˜í”„ yì¶• ìµœëŒ€ê°’ 70ìœ¼ë¡œ ì„¤ì •
                p, l = _pick(compare_df, "ê²½ë„")
                if pd.isna(p) and pd.isna(l): 
                    pass
                else:
                    xs, ys, cs = [], [], []
                    if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                    if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                    fig, ax = plt.subplots(figsize=(2.5, 1.8))
                    ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                    ax.set_title("ê²½ë„")
                    ax.grid(axis="y", linestyle=":", alpha=0.35)
                    ax.set_ylim(top=70)
                    # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                    ax.spines["top"].set_visible(False)
                    ax.spines["right"].set_visible(False)
                    ax.spines["left"].set_linewidth(0.7)
                    ax.spines["bottom"].set_linewidth(0.7)
                    fig.tight_layout()
                    st.pyplot(fig, use_container_width=False)

            with c2:
                _bar_single("ë‹¹ë„", "ë‹¹ë„")
            with c3:
                _bar_single("ì‚°ë„", "ì‚°ë„")

            # â”€â”€ 5) ì°©ìƒ‰ë„ L/a/b (êº¾ì€ì„  ê·¸ë˜í”„, ì„¸ë¡œ ë§¨ ì•„ë˜)
            tone_items = ["L", "a", "b"]
            x = np.arange(len(tone_items))
            y_pred = []; y_last = []
            for it in tone_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))

            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                if not all(pd.isna(y_pred)):
                    ax.plot(x, y_pred, marker="o", linewidth=2, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.plot(x, y_last, marker="o", linewidth=2, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(tone_items)
                ax.set_title("ì°©ìƒ‰ë„")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                # í…Œë‘ë¦¬ì„  ì–‡ê²Œ, ìœ„/ì˜¤ë¥¸ìª½ ì œê±°
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7)
                ax.spines["bottom"].set_linewidth(0.7)
                ax.legend()
                fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
            else:
                st.info("ì°©ìƒ‰ë„(L/a/b) ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            # ====== /ê·¸ë˜í”„ ì„¹ì…˜ ë ======



        else:
            st.warning("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆì—ì„œ í•´ë‹¹ ì§€ì—­ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í’ˆì¢…/ì§€ì—­ ì¡°í•©ì„ ë°”ê¿”ë³´ì„¸ìš”.")

        # ì›ìë£Œ ë‹¤ìš´ë¡œë“œ
        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì‹¤ì¸¡ ì›”ë³„ CSV",
                df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_monthly_measured.csv",
                mime="text/csv",
                disabled=df.empty
            )
        with c2:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì›”ë³„ CSV",
                filled_this_year.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_monthly_used.csv",
                mime="text/csv"
            )
        with c3:
            st.download_button(
                "â¬‡ï¸ íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ CSV",
                pred_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region}_{cultivar}_{cur_year}_predictions.csv",
                mime="text/csv"
            )
    else:
        st.info("ì¢Œì¸¡ì—ì„œ ì§€ì—­ê³¼ í’ˆì¢…ì„ ê³ ë¥¸ ë’¤ ìë™ì¡°íšŒ & ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. ì˜¬í•´ ë‚¨ì€ ì›”ì€ â€˜ì˜ˆìƒ ë‚ ì”¨(ìµœê·¼ 3ë…„ ë˜ëŠ” ì „ì²´ ê³¼ê±° í‰ê· )â€™ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ==========================================================
# íƒ­1: ë¶„ì„ê²°ê³¼(êµ°ìœ„) - ì´ë¯¸ì§€/í‘œ ë·°ì–´ (í™ë¡œ/í›„ì§€)
# ==========================================================
with tab3:
    st.title("ë¶„ì„ê²°ê³¼(êµ°ìœ„)")
    BASE_DIR = Path(r"C:\Users\User\Desktop\mba\ë¶„ì„ê²°ê³¼\êµ°ìœ„")
    CULTIVARS = ["í™ë¡œ", "í›„ì§€"]

    # ê²°ê³¼ ìì‚°(ì´ë¯¸ì§€/í‘œ) ìë™ ê²€ìƒ‰: í•˜ìœ„ì— 'í™ë¡œ','í›„ì§€' í´ë”ê°€ ìˆê±°ë‚˜, íŒŒì¼ëª…ì— í’ˆì¢…ëª…ì´ ë“¤ì–´ìˆëŠ” ê²½ìš° ëª¨ë‘ ì§€ì›
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    TAB_EXT = (".csv", ".xlsx")

    def get_assets_for_cultivar(cultivar: str):
        # 1) í´ë” ëª¨ë“œ: BASE_DIR/í™ë¡œ, BASE_DIR/í›„ì§€ ì¡´ì¬ ì‹œ
        folder1 = BASE_DIR / cultivar
        if folder1.exists():
            imgs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in IMG_EXT])
            tabs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in TAB_EXT])
            root = folder1
        else:
            # 2) íŒŒì¼ëª… í•„í„° ëª¨ë“œ: BASE_DIR ë‚´ íŒŒì¼ëª…ì— í’ˆì¢… í¬í•¨
            imgs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in IMG_EXT and cultivar in p.stem)])
            tabs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in TAB_EXT and cultivar in p.stem)])
            root = BASE_DIR
        return root, imgs, tabs

    cultivar = st.radio("í’ˆì¢… ì„ íƒ", CULTIVARS, horizontal=True, key="radio_tab2")

    folder, all_imgs, all_tabs = get_assets_for_cultivar(cultivar)
    if not BASE_DIR.exists():
        st.error(f"êµ°ìœ„ ê²°ê³¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {BASE_DIR}")
        st.stop()

    mode = st.segmented_control("í‘œì‹œ ìœ í˜•", options=["ì´ë¯¸ì§€", "í‘œ(ë°ì´í„°)"], key="seg_tab2")
    if mode == "ì´ë¯¸ì§€":
        if not all_imgs:
            st.warning("í‘œì‹œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ/íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”)")
        else:
            view = st.radio("ë°©ì‹ ì„ íƒ", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ íŒŒì¼"], horizontal=True, key="view_tab2")
            if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
                thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4)
                rows = (len(all_imgs) + thumbs - 1) // thumbs
                st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
                idx = 0
                for _ in range(rows):
                    cols = st.columns(thumbs, gap="small")
                    for c in cols:
                        if idx >= len(all_imgs):
                            break
                        p = all_imgs[idx]
                        with c:
                            st.image(str(p), caption=str(p.relative_to(folder)))
                        idx += 1
            else:
                sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [str(p.relative_to(folder)) for p in all_imgs])
                path = folder / sel
                st.image(str(path), caption=str(path))
    else:
        if not all_tabs:
            st.warning("í‘œì‹œí•  CSV/XLSX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sel = st.selectbox("í‘œ ì„ íƒ", [str(p.relative_to(folder)) for p in all_tabs])
            path = folder / sel
            st.subheader("í‘œì‹œ ì¤‘: " + str(path.name))
            try:
                if path.suffix.lower() == ".csv":
                    df = pd.read_csv(path, encoding="utf-8-sig")
                else:
                    df = pd.read_excel(path)
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# ==========================================================
# íƒ­2: ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„ ê³ ì •)
# ==========================================================
with tab4:
    st.markdown("ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„)")

    # ---------------------------
    # ì§€ì—­/ì½”ë“œ: êµ°ìœ„ ì „ìš©
    # ---------------------------
    AREA_CODE = {"ëŒ€êµ¬êµ°ìœ„": "333"}  # APIìš© í‚¤
    REGION_NAME_MAP = {"ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„"}  # í™”ë©´ í‘œì‹œëª…

    # ---------------------------
    # íšŒê·€ì‹ (êµ°ìœ„ìš©)
    # ---------------------------
    EQUATIONS_BY_CULTIVAR = {
    "í™ë¡œ": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 157.237 -137.847Â·í‰ê· í’ì†_mean_m08 +1.312Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.205849Â·ê°•ìš°ëŸ‰_sum_m05 +3.9929Â·ìµœì €ê¸°ì˜¨_mean_m07",
        "ì¢…ê²½": "ì¢…ê²½ = 36.9151 +0.613954Â·ìµœì €ê¸°ì˜¨_mean_m04 +0.244159Â·ìŠµë„_mean_m04 +0.577148Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.0405461Â·ê°•ìš°ëŸ‰_sum_m05",
        "íš¡ê²½": "íš¡ê²½ = 89.2207 -19.1684Â·í‰ê· í’ì†_mean_m08 +0.00285688Â·ê²°ë¡œì‹œê°„_mean_m04 +0.0137361Â·ê°•ìš°ëŸ‰_sum_m05",
        "L":   "L = -107.653 +4.02276Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.557626Â·ìµœê³ ê¸°ì˜¨_mean_m08 +0.357053Â·ìŠµë„_mean_m05 +1.23389Â·ìµœëŒ€í’ì†_mean_m08 +5.79158Â·í‰ê· í’ì†_mean_m07",
        "a":   "a = 28.916 +26.4391Â·ìµœëŒ€í’ì†_mean_m05 -2.04984Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.525233Â·í‰ê· ê¸°ì˜¨_mean_m08 -7.60126Â·ìµœëŒ€í’ì†_mean_m08 -0.0905347Â·ìŠµë„_mean_m05",
        "b":   "b = -44.3799 -0.0102677Â·ìµœëŒ€í’ì†_mean_m05 +1.63975Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.201082Â·ìŠµë„_mean_m05 +1.29407Â·ìµœëŒ€í’ì†_mean_m08",
        "ê²½ë„": "ê²½ë„ = 53.7403 +0.0406574Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0109639Â·ê²°ë¡œì‹œê°„_mean_m04 -5.99111Â·ìµœëŒ€í’ì†_mean_m05 +0.00101735Â·ê²°ë¡œì‹œê°„_mean_m05",
        "ë‹¹ë„": "ë‹¹ë„ = -3.77559 +0.845922Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.000435945Â·ê°•ìš°ëŸ‰_sum_m07 +0.00284123Â·ê²°ë¡œì‹œê°„_mean_m04 -0.343821Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.0040703Â·ê°•ìš°ëŸ‰_sum_m06",
        "ì‚°ë„": "ì‚°ë„ = 0.23201 -0.000127841Â·ê²°ë¡œì‹œê°„_mean_m05 -1.60354e-05Â·ê°•ìš°ëŸ‰_sum_m05 +0.0112801Â·í‰ê· í’ì†_mean_m06 +0.0202028Â·ìµœëŒ€í’ì†_mean_m05 -7.47002e-05Â·ê²°ë¡œì‹œê°„_mean_m04",
    },
    "í›„ì§€": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 280.193 -14.9938Â·ìµœëŒ€í’ì†_mean_m04 +7.01039Â·í‰ê· ê¸°ì˜¨_mean_m09 -0.216694Â·ì¼ì‚¬ëŸ‰_sum_m10",
        "ì¢…ê²½": "ì¢…ê²½ = 67.5821 +0.707095Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0488712Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.880706Â·ìµœê³ ê¸°ì˜¨_mean_m09",
        "íš¡ê²½": "íš¡ê²½ = 95.1048 +0.181127Â·ìŠµë„_mean_m04 -0.0132518Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.276929Â·ìŠµë„_mean_m08 +0.487867Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "L":   "L = -25.351 +0.317467Â·ìŠµë„_mean_m04 +0.063049Â·ìµœì €ê¸°ì˜¨_mean_m09 +0.310649Â·ìŠµë„_mean_m10 +1.19993Â·ìµœê³ ê¸°ì˜¨_mean_m10",
        "a":   "a = 24.306 -0.0581428Â·ê°•ìš°ëŸ‰_sum_m04 +7.83592Â·í‰ê· í’ì†_mean_m08 -0.515246Â·ìµœê³ ê¸°ì˜¨_mean_m10 +6.87267Â·í‰ê· í’ì†_mean_m05",
        "b":   "b = 18.3498 -0.0117526Â·ìŠµë„_mean_m10 -0.0255657Â·ì¼ì‚¬ëŸ‰_sum_m10 -5.44522Â·í‰ê· í’ì†_mean_m09 +0.493188Â·ìµœê³ ê¸°ì˜¨_mean_m04",
        "ê²½ë„": "ê²½ë„ = 44.1071 -0.0341814Â·ê°•ìš°ëŸ‰_sum_m10 +0.00537892Â·ê°•ìš°ëŸ‰_sum_m07 +4.75772Â·ìµœëŒ€í’ì†_mean_m08 +1.15897Â·ìµœì €ê¸°ì˜¨_mean_m04",
        "ë‹¹ë„": "ë‹¹ë„ = 7.35627 +2.56347Â·ìµœëŒ€í’ì†_mean_m08 -0.0270168Â·ìŠµë„_mean_m09 +0.0171314Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.525697Â·ìµœì €ê¸°ì˜¨_mean_m06 -0.231632Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "ì‚°ë„": "ì‚°ë„ = 1.14472 +0.169768Â·í‰ê· í’ì†_mean_m08 -0.0438612Â·ìµœê³ ê¸°ì˜¨_mean_m10 +5.80039e-05Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.103592Â·í‰ê· í’ì†_mean_m05 -0.000376686Â·ê°•ìš°ëŸ‰_sum_m04",
    },
}


    # ---------------------------
    # ìœ í‹¸/ì „ì²˜ë¦¬ í•¨ìˆ˜
    # ---------------------------
    def _clean_str(s: str) -> str:
        s = str(s).replace("\xa0", " ")
        s = s.replace("\n", " ").replace("\r", " ")
        s = re.sub(r"\s+", " ", s).strip()
        s = re.sub(r"\s*\(\s*", " (", s)
        s = re.sub(r"\s*\)\s*", ")", s)
        return s

    def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
        out = df.copy()
        if isinstance(out.columns, pd.MultiIndex):
            out.columns = [" ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                           for tup in out.columns.values]
        out.columns = [_clean_str(c) for c in out.columns]
        alias = {
            "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
            "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
            "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
        }
        out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})
        if "ì§€ì—­" in out.columns:
            out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in out.columns:
            out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")
        return out

    def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
        pat = re.compile(pattern, flags=re.IGNORECASE)
        for c in df.columns:
            if pat.search(str(c)):
                return c
        return None

    def _ensure_numeric(df: pd.DataFrame, cols):
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    def cultivar_window(cultivar: str):
        return (4, 8) if cultivar == "í™ë¡œ" else (4, 10)

    def get_today_ym():
        now = datetime.now()
        return now.year, now.month

    @st.cache_data(show_spinner=False, ttl=300)
    def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
        session = requests.Session()
        session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)
        form = {
            "pageIndex": "1",
            "searchNum": "0",
            "areaName": region_name,
            "areaCode": AREA_CODE.get(region_name, region_name),
            "statmethod": stat_gb_code,
        }
        if stat_gb_code == "A":
            form["wetherDtBgn"] = f"{s_ym}-01"; form["wetherDtEnd"] = f"{e_ym}-30"
        elif stat_gb_code in ("B", "C"):
            form["wetherDtM"] = s_ym
        else:  # "D"
            form["wetherDtBgn2"] = s_ym; form["wetherDtEnd2"] = e_ym
            form["wetherDtBgn"]  = s_ym; form["wetherDtEnd"]  = e_ym
        resp = session.post(
            "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
            data=form, timeout=30,
            headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
        )
        resp.raise_for_status()
        try:
            return resp.json()
        except Exception:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

    def json_to_dataframe(payload: dict) -> pd.DataFrame:
        if not payload or "result" not in payload:
            return pd.DataFrame()
        res = payload.get("result", [])
        if len(res) == 0:
            return pd.DataFrame()
        method = payload.get("mainAwsVO", {}).get("statmethod")
        raw = pd.DataFrame(res)
        with st.expander("ğŸ”§ API ì›ì‹œ ì»¬ëŸ¼ ë³´ê¸°", expanded=False):
            st.write(sorted(list(raw.columns)))
        rename_map = {
            "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
            "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
            "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
            "dalyWetherAvrgHd": "ìŠµë„", "WetherAvgHd": "ìŠµë„",
            "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰", "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰", "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
            "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„", "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„", "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
            "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
            "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
        }
        raw = raw.rename(columns=rename_map)
        if method == "A":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "B":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "C":
            want = ["ìˆœ","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"] if "ìˆœ" in raw.columns \
                else ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        else:
            want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
                if "ì›”" in raw.columns else \
                ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        use_cols = [c for c in want if c in raw.columns]
        if not use_cols:
            return pd.DataFrame()
        df = raw[use_cols].copy()
        numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        df = _ensure_numeric(df, [c for c in numcands if c in df.columns])
        if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
            df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
            if "ì—°ë„" not in df.columns: df["ì—°ë„"] = df["ì¼ì"].dt.year
            if "ì›”"   not in df.columns: df["ì›”"]   = df["ì¼ì"].dt.month
        elif "ì›”" in df.columns:
            df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
            df["ì›”"]   = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")
        if {"ì—°ë„","ì›”"}.issubset(df.columns):
            df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        return df

    def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(df.columns):
            return df.copy()
        agg_map = {
            "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
            "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
            "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
        }
        use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
        out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
        return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

    def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
            raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
        sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
        wide_mean = None
        for m in range(1, 12+1):
            sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        wide_sum = None
        for m in range(1, 12+1):
            sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
        return wide

    def apply_equation_row(row: pd.Series, eq_str: str) -> float:
        rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
        lhs = eq_str.split("=", 1)[0].strip()
        cols = [c for c in sorted(row.index.tolist(), key=len, reverse=True) if c != lhs]
        expr = rhs
        for c in cols:
            expr = expr.replace(c, f"row[{repr(c)}]")
        return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

    def fill_missing_or_future_with_climatology(env_m: pd.DataFrame, target_year: int, cultivar: str, mode: str = "all") -> pd.DataFrame:
        need_cols = {"ì—°ë„","ì›”"}
        if not need_cols.issubset(env_m.columns):
            raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        s_mon, e_mon = cultivar_window(cultivar)
        cur_year, cur_mon = get_today_ym()
        cur = env_m[env_m["ì—°ë„"] == target_year].copy()
        hist = env_m[env_m["ì—°ë„"] < target_year].copy()
        if hist.empty:
            return cur
        # 'all' == ì „ì²´ ê³¼ê±° í‰ê·  ì‚¬ìš©
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        climo_all = hist.groupby("ì›”", as_index=False)[num_cols].mean()
        months_window = list(range(s_mon, e_mon+1))
        have = set(cur["ì›”"].tolist())
        future_cut = cur_mon if target_year == cur_year else 12
        future_months = [m for m in months_window if (target_year == cur_year and m > future_cut) or (target_year > cur_year)]
        missing_months = [m for m in months_window if m not in have]
        to_fill = sorted(set(future_months) | set(missing_months))
        if to_fill:
            fill_rows = climo_all[climo_all["ì›”"].isin(to_fill)].copy()
            fill_rows.insert(0, "ì—°ë„", target_year)
            cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)
        cur = cur[(cur["ì›”"] >= s_mon) & (cur["ì›”"] <= e_mon)].sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        for c in num_cols:
            cur[c] = pd.to_numeric(cur[c], errors="coerce")
        return cur

    def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
        code = "apple01" if cultivar == "í›„ì§€" else "apple02"
        url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
        params = {
            "frtgrdCode": "apple",
            "selyear": str(selyear),
            "lastYear": str(lastyear),
            "searchGubun": code,
            "pageIndex": "1",
        }
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        try:
            tables = pd.read_html(io.StringIO(r.text))
        except Exception as e:
            st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹± ì‹¤íŒ¨: {e}\n(lxml/html5lib í•„ìš”)")
            return {}
        cleaned = []
        for t in tables:
            t2 = normalize_quality_columns(t)
            if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(set(t2.columns)):
                cleaned.append(t2)
        result = {}
        if len(cleaned) >= 1: result["this"] = cleaned[0]
        if len(cleaned) >= 2: result["last"] = cleaned[1]
        return result

    def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
        if qdf is None or qdf.empty: return None
        region_disp_name = _clean_str(region_disp_name)
        if "ì§€ì—­" not in qdf.columns: return None
        tmp = qdf.copy()
        tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in tmp.columns and not np.issubdtype(tmp["ìˆ˜í™•ì¼ì"].dtype, np.datetime64):
            tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
        sub = tmp[tmp["ì§€ì—­"] == region_disp_name]
        if sub.empty: return None
        sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
        return sub.iloc[0]

    # ---------------------------
    # ì¡°íšŒ/ì˜ˆì¸¡ UI (êµ°ìœ„ ê³ ì •)
    # ---------------------------
    c1, c2 = st.columns([1,1])
    with c1:
        cultivar = st.radio("í’ˆì¢… ì„ íƒ", ["í™ë¡œ", "í›„ì§€"], horizontal=True, key="radio_tab3")
    with c2:
        st.text("ì§€ì—­ ì„ íƒ")
        st.info("êµ°ìœ„(ëŒ€êµ¬êµ°ìœ„)ë¡œ ê³ ì •")
    region = "ëŒ€êµ¬êµ°ìœ„"  # ë‚´ë¶€ í‚¤
    region_disp = REGION_NAME_MAP[region]

    run = st.button("ğŸ” êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡")
    mode = "all"  # í•­ìƒ ì „ì²´ ê³¼ê±° í‰ê·  ê¸°ë°˜ìœ¼ë¡œ ë¯¸í™•ë³´ ì›” ì±„ì›€

    if run:
        try:
            cur_year, cur_month = get_today_ym()
            s_mon, e_mon = cultivar_window(cultivar)
            s_ym = f"{cur_year:04d}-{s_mon:02d}"
            e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

            with st.spinner("ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
                payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)

            if "error" in payload:
                st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.code(payload.get("raw","")[:1000])
                st.stop()

            df = json_to_dataframe(payload)
            st.subheader(f"ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡ ë°ì´í„°(ê¸°ìƒ) - {region_disp}")
            if df.empty:
                st.warning("ì˜¬í•´ ê¸°ê°„ ë‚´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±° í‰ê· ìœ¼ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            else:
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)

        env_m = df.copy()
        if not env_m.empty and "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"]   = env_m["ì›”"].astype(str).str[5:7].astype(int)

        past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
        past_df = json_to_dataframe(past_payload)
        env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m

        filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

        st.subheader("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì›”ë³„ ë°ì´í„°(ì˜¬í•´, ë¯¸ë˜ì›”ì€ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´)")
        st.dataframe(filled_this_year, use_container_width=True)

        try:
            env_for_wide = pd.concat([env_all[env_all["ì—°ë„"] != cur_year], filled_this_year], ignore_index=True)
            wide = build_wide_month_feats(env_for_wide)
        except Exception as e:
            st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            st.stop()

        if cur_year not in set(wide["ì—°ë„"].astype(int).tolist()):
            st.error("ì˜ˆì¸¡ ì—°ë„ í–‰ì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        row = wide[wide["ì—°ë„"] == cur_year].iloc[0]

        EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
        preds = {}
        for tgt, formula in EQUATIONS.items():
            try:
                preds[tgt] = apply_equation_row(row, formula)
            except Exception as e:
                preds[tgt] = f"ì—ëŸ¬: {e}"

        st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}  ì—°ë„: {cur_year}")
        pred_df = pd.DataFrame([preds]).T.reset_index()
        pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]
        st.dataframe(pred_df.set_index("í•­ëª©").T.reset_index(drop=True), use_container_width=True)

        # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë¹„êµ
        with st.spinner("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            qdict = fetch_quality_tables(cur_year, cur_year-1, cultivar)

        last_row = None
        if qdict and "last" in qdict and qdict["last"] is not None and not qdict["last"].empty:
            q_last = normalize_quality_columns(qdict["last"])
            with st.expander("ì „ë…„ë„ í…Œì´ë¸” ì‹¤ì œ ì»¬ëŸ¼ëª…(ì •ê·œí™” í›„)"):
                st.write(list(q_last.columns))
            last_row = pick_region_row(q_last, region_disp)

        if last_row is not None:
            patterns = {
                "ê³¼ì¤‘": r"^ê³¼ì¤‘",
                "ì¢…ê²½": r"^ì¢…ê²½",
                "íš¡ê²½": r"^íš¡ê²½",
                "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
                "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
                "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
                "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
                "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
                "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
            }
            def to_float(x):
                try:
                    return float(str(x).replace(",", "").strip())
                except Exception:
                    return None
            rows = []
            last_df_for_match = last_row.to_frame().T
            for k, pat in patterns.items():
                col = get_first_col_by_pattern(last_df_for_match, pat)
                last_val = to_float(last_row[col]) if col else None
                pred_val = preds.get(k, None)
                rows.append([k, pred_val, last_val])

            compare_df = pd.DataFrame(rows, columns=["í•­ëª©","ì˜ˆì¸¡ê°’(ì˜¬í•´)","ì „ë…„ë„ ì‹¤ì œê°’"])
            st.subheader(f"ì˜¬í•´ ì˜ˆì¸¡ vs ì „ë…„ë„ ì‹¤ì œ  ë¹„êµ  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}")
            compare_df_t = compare_df.set_index("í•­ëª©").T
            compare_df_t.index.name = ""
            st.dataframe(compare_df_t, use_container_width=True)

            # ì‘ì€ ì‹œê°í™”ë“¤
            PRED_COLOR = "#87CEEB"
            LAST_COLOR = "#800080"
            def _pick(df, item):
                r = df[df["í•­ëª©"] == item]
                if r.empty: return np.nan, np.nan
                p = pd.to_numeric(r["ì˜ˆì¸¡ê°’(ì˜¬í•´)"].values[0], errors="coerce")
                l = pd.to_numeric(r["ì „ë…„ë„ ì‹¤ì œê°’"].values[0], errors="coerce")
                return p, l

            size_items = ["ê³¼ì¤‘", "íš¡ê²½", "ì¢…ê²½"]
            x = np.arange(len(size_items))
            y_pred, y_last = [], []
            for it in size_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                w = 0.35
                if not all(pd.isna(y_pred)):
                    ax.bar(x - w/2, np.nan_to_num(y_pred, nan=0.0), width=w, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.bar(x + w/2, np.nan_to_num(y_last, nan=0.0), width=w, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(size_items)
                ax.set_title("ê³¼ì‹¤ í¬ê¸°")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)

            def _bar_single(item, title, ylim_top=None):
                p, l = _pick(compare_df, item)
                if pd.isna(p) and pd.isna(l): 
                    return
                xs, ys, cs = [], [], []
                if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                fig, ax = plt.subplots(figsize=(2.5, 1.8))
                ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                ax.set_title(title); ax.grid(axis="y", linestyle=":", alpha=0.35)
                if ylim_top: ax.set_ylim(top=ylim_top)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                fig.tight_layout(); st.pyplot(fig, use_container_width=False)

            c1, c2, c3 = st.columns(3)
            with c1: _bar_single("ê²½ë„", "ê²½ë„", ylim_top=70)
            with c2: _bar_single("ë‹¹ë„", "ë‹¹ë„")
            with c3: _bar_single("ì‚°ë„", "ì‚°ë„")

            tone_items = ["L", "a", "b"]
            x = np.arange(len(tone_items))
            y_pred, y_last = [], []
            for it in tone_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                if not all(pd.isna(y_pred)):
                    ax.plot(x, y_pred, marker="o", linewidth=2, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.plot(x, y_last, marker="o", linewidth=2, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(tone_items)
                ax.set_title("ì°©ìƒ‰ë„")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
        else:
            st.warning("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆì—ì„œ êµ°ìœ„ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")

        # ë‹¤ìš´ë¡œë“œë“¤
        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì‹¤ì¸¡ ì›”ë³„ CSV",
                df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_measured.csv",
                mime="text/csv",
                disabled=df.empty
            )
        with c2:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì›”ë³„ CSV",
                filled_this_year.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_used.csv",
                mime="text/csv"
            )
        with c3:
            st.download_button(
                "â¬‡ï¸ íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ CSV",
                pred_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_predictions.csv",
                mime="text/csv"
            )
    else:
        st.info("í’ˆì¢…ì„ ì„ íƒí•˜ê³  â€˜êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”.")
# ==== [íƒ­5Â·6ìš© ê³µí†µ ìœ í‹¸ - êµ°ìœ„ ë…¼ë¬¸ì‹] ====
import statsmodels.api as sm
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st

# ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë² ì´ìŠ¤ ê²½ë¡œ (í•„ìš”ì‹œ í•œ ë²ˆë§Œ ìˆ˜ì •)
GW_BASE = Path(r"C:\Users\User\Desktop\mba\í™˜ê²½ë°ì´í„°")
GW_BIO_FILE   = GW_BASE / "_OUT" / "bioclim_19_variables_Gunwi.csv"
GW_ENV_FILE   = GW_BASE / "ê¸°ìƒë°ì´í„°_í†µí•©.xlsx"
GW_FRUIT_FILE = GW_BASE / "ê³¼ì‹¤ë°ì´í„°_í†µí•©.xlsx"
GW_OUTDIR     = GW_BASE / "_ANALYSIS_OUT"
GW_BYC_DIR    = GW_OUTDIR / "_BY_CULTIVAR"

# í’ˆì¢…ë³„ í—ˆìš© ì›”(ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼)
GW_MONTH_RANGE = {
    "í™ë¡œ": list(range(5, 10)),   # 5~9ì›”
    "í›„ì§€": list(range(5, 11)),   # 5~10ì›”
}

def gw_to_year_series(s: pd.Series) -> pd.Series:
    import re as _re
    s2 = s.copy()
    m_year = s2.astype(str).str.fullmatch(r"\s*(19|20)\d{2}\s*")
    if m_year.fillna(False).all():
        return pd.to_numeric(s2, errors="coerce")
    def _looks_like_yyyymmdd(x):
        try: xs = str(int(float(x))).strip()
        except Exception: xs = str(x)
        return bool(_re.fullmatch(r"(19|20)\d{6}", xs))
    mask_ymd = s2.apply(_looks_like_yyyymmdd)
    if mask_ymd.any():
        tmp = s2[mask_ymd].apply(lambda x: str(int(float(x))).strip())
        y = pd.to_datetime(tmp, format="%Y%m%d", errors="coerce").dt.year
        s2.loc[mask_ymd] = y
    def _looks_like_excel_serial(x):
        try:
            v = float(x); return 10000 <= v <= 60000
        except Exception:
            return False
    mask_serial = s2.apply(_looks_like_excel_serial)
    if mask_serial.any():
        y = pd.to_datetime(s2[mask_serial].astype(float), unit="D", origin="1899-12-30", errors="coerce").dt.year
        s2.loc[mask_serial] = y
    s2 = pd.to_datetime(s2, errors="coerce").dt.year
    return pd.to_numeric(s2, errors="coerce").astype("Int64")

def gw_extract_gunwi(df: pd.DataFrame):
    if "ì§€ì—­ëª…" not in df.columns: return None
    m = df["ì§€ì—­ëª…"].astype(str).str.contains("êµ°ìœ„", na=False)
    out = df.loc[m].copy()
    return out if not out.empty else None

def gw_find_cultivar_col(df: pd.DataFrame):
    cands = [c for c in df.columns if any(k in str(c) for k in ["í’ˆì¢…","í’ˆì¢…ëª…","í’ˆì¢…ì½”ë“œ","í’ˆì¢…êµ¬ë¶„"])]
    return cands[0] if cands else None

def gw_wide_month(df_sub: pd.DataFrame, cols=("tmean","tmax","tmin","prcp","rad","humid")):
    cols = [c for c in cols if c in df_sub.columns]
    if not cols: return pd.DataFrame()
    w = df_sub.pivot_table(index="year", columns="month", values=cols)
    w.columns = [f"{v}_m{m:02d}" for v, m in w.columns.to_flat_index()]
    return w.reset_index()

@st.cache_data(show_spinner=False)
def gw_load_merged_dataset():
    # 1) ë¡œë”©
    bio = pd.read_csv(GW_BIO_FILE)
    env_all   = pd.read_excel(GW_ENV_FILE,   sheet_name=None)
    fruit_all = pd.read_excel(GW_FRUIT_FILE, sheet_name=None)
    env_frames   = [x for x in (gw_extract_gunwi(df) for df in env_all.values())   if x is not None]
    fruit_frames = [x for x in (gw_extract_gunwi(df) for df in fruit_all.values()) if x is not None]
    if not env_frames or not fruit_frames:
        return None, None, None, None, None
    env_raw   = pd.concat(env_frames, ignore_index=True)
    fruit_raw = pd.concat(fruit_frames, ignore_index=True)
    # 2) ì›”ë³„ ì§‘ê³„ â†’ wide
    if "ì¼ì" not in env_raw.columns: return None, None, None, None, None
    env_raw["date"]  = pd.to_datetime(env_raw["ì¼ì"], errors="coerce")
    env_raw["year"]  = env_raw["date"].dt.year
    env_raw["month"] = env_raw["date"].dt.month
    for col in ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ìŠµë„"]:
        if col in env_raw.columns:
            env_raw[col] = pd.to_numeric(env_raw[col], errors="coerce")
    agg_map = {"í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ê°•ìš°ëŸ‰":"sum"}
    if "ì¼ì‚¬ëŸ‰" in env_raw.columns: agg_map["ì¼ì‚¬ëŸ‰"] = "mean"
    if "ìŠµë„"  in env_raw.columns: agg_map["ìŠµë„"]  = "mean"
    env_monthly = (env_raw.dropna(subset=["year","month"])
                          .groupby(["year","month"], as_index=False)
                          .agg(agg_map)
                          .rename(columns={"í‰ê· ê¸°ì˜¨":"tmean","ìµœê³ ê¸°ì˜¨":"tmax","ìµœì €ê¸°ì˜¨":"tmin",
                                           "ê°•ìš°ëŸ‰":"prcp","ì¼ì‚¬ëŸ‰":"rad","ìŠµë„":"humid"}))
    env_mwide = gw_wide_month(env_monthly)
    # 3) BIO (êµ°ìœ„ë§Œ, ì—°ë„ í‰ê· )
    bio_gw = bio[bio["region"].astype(str).str.contains("êµ°ìœ„", na=False)].copy()
    bio_gw["year"] = pd.to_numeric(bio_gw["year"], errors="coerce").astype("Int64")
    bio_y = bio_gw.groupby("year", as_index=False).mean(numeric_only=True)
    # 4) ê³¼ì‹¤ (ì—°ë„Ã—í’ˆì¢…)
    if "year" in fruit_raw.columns: fruit_raw["year"] = gw_to_year_series(fruit_raw["year"])
    elif "ì—°ë„" in fruit_raw.columns: fruit_raw["year"] = gw_to_year_series(fruit_raw["ì—°ë„"])
    elif "ì¼ì" in fruit_raw.columns: fruit_raw["year"] = gw_to_year_series(fruit_raw["ì¼ì"])
    else: return None, None, None, None, None
    cultivar_col = gw_find_cultivar_col(fruit_raw)
    if cultivar_col is None:
        fruit_raw["_í’ˆì¢…ì„ì‹œ"] = "ALL"; cultivar_col = "_í’ˆì¢…ì„ì‹œ"
    drop_keys = {"ì§€ì—­ëª…","ì¼ì","ì—°ë„","year",cultivar_col}
    fruit_conv = fruit_raw.copy()
    for c in fruit_conv.columns:
        if c not in drop_keys:
            fruit_conv[c] = pd.to_numeric(fruit_conv[c], errors="coerce")
    num_cols = [c for c in fruit_conv.columns if c not in drop_keys and pd.api.types.is_numeric_dtype(fruit_conv[c])]
    fruit_agg = (fruit_conv.dropna(subset=["year"])
                            .groupby([cultivar_col,"year"], as_index=False)[num_cols].mean())
    # 5) ë³‘í•© + êµì§‘í•© ì—°ë„
    merged_all = (fruit_agg.merge(bio_y, on="year", how="inner").merge(env_mwide, on="year", how="left"))
    bio_years   = sorted(map(int, pd.Series(bio_y["year"]).dropna().unique()))
    env_years   = sorted(map(int, pd.Series(env_mwide["year"]).dropna().unique()))
    fruit_years = sorted(map(int, pd.Series(fruit_agg["year"]).dropna().unique()))
    common_years = sorted(set(bio_years) & set(env_years) & set(fruit_years))
    return merged_all, fruit_agg, env_mwide, bio_y, (cultivar_col, num_cols, common_years)

def gw_list_available_cultivars():
    if not GW_BYC_DIR.exists(): return []
    return [p.name for p in GW_BYC_DIR.iterdir() if p.is_dir()]

def gw_load_selected_vars(cultivar: str):
    f = GW_BYC_DIR / cultivar / "ì„ íƒë³€ìˆ˜_ìš”ì•½.csv"
    if not f.exists():
        return pd.DataFrame(columns=["target","selected_vars","vars_list"])
    df = pd.read_csv(f, encoding="utf-8-sig")
    if "selected_vars" in df.columns:
        df["vars_list"] = df["selected_vars"].fillna("").apply(lambda s: [v.strip() for v in str(s).split(",") if v.strip()])
    else:
        df["vars_list"] = [[] for _ in range(len(df))]
    return df

def gw_fit_ols(df: pd.DataFrame, y_col: str, x_cols: list):
    from math import sqrt as _sqrt
    sub = df[["year", y_col] + x_cols].dropna()
    if len(sub) < 5:
        return None, None, None, None
    X = sm.add_constant(sub[x_cols]); y = sub[y_col]
    model = sm.OLS(y, X).fit()
    yhat = model.predict(X)
    r2 = model.rsquared
    rmse = _sqrt(np.mean((y - yhat)**2))
    return model, sub, yhat, {"R2": r2, "RMSE": rmse}

def gw_plot_coefficients(model, title="Coefficients"):
    betas = model.params.drop(labels=["const"], errors="ignore")
    fig, ax = plt.subplots(figsize=(5,3))
    betas.plot(kind="bar", ax=ax)
    ax.set_title(title); ax.set_ylabel("Coefficient"); ax.grid(True, axis="y", linestyle="--", alpha=0.4)
    st.pyplot(fig)

def gw_plot_observed_vs_pred(sub, yhat, y_col, title="Observed vs Predicted"):
    fig, ax = plt.subplots(figsize=(4,4))
    ax.scatter(sub[y_col], yhat, s=30)
    lims = [min(sub[y_col].min(), yhat.min()), max(sub[y_col].max(), yhat.max())]
    ax.plot(lims, lims, linestyle="--")
    ax.set_xlabel("Observed"); ax.set_ylabel("Predicted")
    ax.set_title(title); ax.grid(True, linestyle="--", alpha=0.4)
    st.pyplot(fig)

def gw_plot_metric_bar(name: str, value: float):
    fig, ax = plt.subplots(figsize=(3.5,2.2))
    ax.bar([name], [value])
    ax.set_ylim(0, max(value*1.2, 1e-9))
    for i, v in enumerate([value]): ax.text(i, v, f"{v:.3f}", ha="center", va="bottom")
    ax.set_title(name); ax.grid(True, axis="y", linestyle="--", alpha=0.4)
    st.pyplot(fig)

# -------------------------
# TAB 5: ë¶„ì„ê²°ê³¼ ìš”ì•½ (êµ°ìœ„Â·ë…¼ë¬¸ì‹)
# -------------------------
with tab5:
    st.subheader("í’ˆì¢…Ã—íƒ€ê¹ƒë³„ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ (RÂ², RMSE) â€” êµ°ìœ„Â·ë…¼ë¬¸ì‹")

    merged_all, fruit_agg, env_mwide, bio_y, meta = gw_load_merged_dataset()
    if merged_all is None:
        st.error("êµ°ìœ„ ë°ì´í„° ë³‘í•©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ìë£Œ ê²½ë¡œ/í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    cultivar_col, fruit_num_cols, common_years = meta

    cultivars_avail = gw_list_available_cultivars()
    if not cultivars_avail:
        st.warning("ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”.")
        st.stop()

    rows = []
    for cv in cultivars_avail:
        sel_df = gw_load_selected_vars(cv)
        if sel_df.empty:
            continue
        valid_months = GW_MONTH_RANGE.get(cv, list(range(5,10)))
        month_suffix = tuple(f"m{m:02d}" for m in valid_months)
        if merged_all.empty:
            continue
        g = merged_all.copy() if cultivar_col not in merged_all.columns else \
            merged_all[(merged_all[cultivar_col] == cv)]
        if "year" in g.columns and common_years:
            g = g[g["year"].isin(common_years)]

        for _, r in sel_df.iterrows():
            tgt = r["target"]
            xcols_raw = r["vars_list"] if isinstance(r["vars_list"], (list, tuple)) else []
            xcols = [x for x in xcols_raw if (x in g.columns)]
            if tgt not in g.columns or not xcols:
                continue
            model, sub, yhat, mets = gw_fit_ols(g, tgt, xcols)
            if model is None:
                continue
            rows.append({
                "í’ˆì¢…": cv, "íƒ€ê¹ƒ": tgt, "ë³€ìˆ˜": ", ".join(xcols),
                "í‘œë³¸ìˆ˜": len(sub), "RÂ²": mets.get("R2", np.nan), "RMSE": mets.get("RMSE", np.nan),
            })

    if not rows:
        st.warning("ìš”ì•½í‘œë¥¼ ë§Œë“¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    perf_df = pd.DataFrame(rows).sort_values(["í’ˆì¢…","íƒ€ê¹ƒ"]).reset_index(drop=True)
    st.dataframe(perf_df, use_container_width=True)
    st.download_button("â¬‡ï¸ ìš”ì•½í‘œ CSV ë‹¤ìš´ë¡œë“œ",
                       perf_df.to_csv(index=False).encode("utf-8-sig"),
                       file_name="ë¶„ì„ê²°ê³¼_ìš”ì•½í‘œ(êµ°ìœ„_ë…¼ë¬¸ì‹).csv")

    st.markdown("---")
    st.subheader("ê°œë³„ ëª¨ë¸ ì‹œê°í™”")
    cv_sel = st.selectbox("í’ˆì¢… ì„ íƒ", options=sorted(perf_df["í’ˆì¢…"].unique().tolist()), index=0, key="gw_viz_cv")
    tgt_opts = perf_df.loc[perf_df["í’ˆì¢…"]==cv_sel, "íƒ€ê¹ƒ"].unique().tolist()
    tgt_sel = st.selectbox("íƒ€ê¹ƒ ì„ íƒ", options=tgt_opts, index=0, key="gw_viz_tgt")
    row = perf_df[(perf_df["í’ˆì¢…"]==cv_sel) & (perf_df["íƒ€ê¹ƒ"]==tgt_sel)].iloc[0]
    xcols = [c.strip() for c in str(row["ë³€ìˆ˜"]).split(",") if c.strip()]

    g = merged_all.copy() if cultivar_col not in merged_all.columns else \
        merged_all[(merged_all[cultivar_col] == cv_sel)]
    if "year" in g.columns and common_years:
        g = g[g["year"].isin(common_years)]

    model, sub, yhat, mets = gw_fit_ols(g, tgt_sel, xcols)
    if model is None:
        st.info("í‘œë³¸ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ì…ë ¥ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        colA, colB = st.columns(2)
        with colA:
            gw_plot_coefficients(model, title=f"[{cv_sel} - {tgt_sel}] Coefficients")
        with colB:
            gw_plot_observed_vs_pred(sub, yhat, tgt_sel, title=f"[{cv_sel} - {tgt_sel}] Observed vs Predicted")
        colC, colD = st.columns(2)
        with colC:
            gw_plot_metric_bar("RÂ²", mets.get("R2", np.nan))
        with colD:
            gw_plot_metric_bar("RMSE", mets.get("RMSE", np.nan))

# -------------------------
# TAB 6: 2024 ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ (ë…¼ë¬¸ì‹ íšŒê·€ì‹ ì‚¬ìš©, ë¡œì»¬ íŒŒì¼ë§Œ)
# -------------------------
with tab6:
    st.subheader("ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡ â€” 2024 ì˜ˆì¸¡ vs 2023 ì‹¤ì œ (ë…¼ë¬¸ì‹ íšŒê·€ì‹)")

    # --- íšŒê·€ì‹(ì‚¬ìš©ì ì œê³µ) ---
    EQUATIONS_BY_CULTIVAR = {
        "í™ë¡œ": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 667.243 -0.597465Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.376337Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.0756442Â·ì¼ì‚¬ëŸ‰_sum_m08 +24.5342Â·í‰ê· í’ì†_mean_m06 +5.05212Â·ìµœì €ê¸°ì˜¨_mean_m06",
            "ì¢…ê²½": "ì¢…ê²½ = 124.046 -0.0439843Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.0673823Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.397906Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.559339Â·í‰ê· í’ì†_mean_m06 +7.43416Â·í‰ê· í’ì†_mean_m05 +0.00854761Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.15116Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.05474Â·ìµœì €ê¸°ì˜¨_mean_m05 -2.574Â·ìµœëŒ€í’ì†_mean_m04",
            "íš¡ê²½": "íš¡ê²½ = 141.358 -0.0531011Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.0459844Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.00297393Â·ì¼ì‚¬ëŸ‰_sum_m08",
            "L":   "L = -68.3528 +2.1686e-05Â·ê°•ìš°ëŸ‰_sum_m07 +0.653086Â·ìŠµë„_mean_m07 +2.72693Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.14857Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.00918464Â·ê°•ìš°ëŸ‰_sum_m06 -1.52125Â·ìµœì €ê¸°ì˜¨_mean_m05 -6.00147Â·í‰ê· í’ì†_mean_m06 +3.14509Â·ìµœëŒ€í’ì†_mean_m06 +4.16545Â·í‰ê· í’ì†_mean_m07",
            "a":   "a = 226.087 -1.71711Â·ìŠµë„_mean_m07 +0.00830904Â·ê°•ìš°ëŸ‰_sum_m07 -4.51272Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.51756Â·ìµœì €ê¸°ì˜¨_mean_m05 -1.94971Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.040713Â·ì¼ì‚¬ëŸ‰_sum_m07 -0.0185248Â·ê°•ìš°ëŸ‰_sum_m06 +0.00975096Â·ê°•ìš°ëŸ‰_sum_m08 +1.93026Â·ìµœê³ ê¸°ì˜¨_mean_m07 -0.192988Â·í‰ê· í’ì†_mean_m06",
            "b":   "b = -23.7933 +0.381237Â·ìŠµë„_mean_m07 +0.0052134Â·ê°•ìš°ëŸ‰_sum_m06 +0.0606139Â·ìŠµë„_mean_m05 +1.14817Â·ìµœì €ê¸°ì˜¨_mean_m06 +0.682908Â·í‰ê· í’ì†_mean_m07 -0.523353Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.350293Â·ìµœê³ ê¸°ì˜¨_mean_m05 -0.00264168Â·ê°•ìš°ëŸ‰_sum_m08 -1.23413Â·í‰ê· í’ì†_mean_m08 +0.652516Â·ìµœëŒ€í’ì†_mean_m06",
            "ê²½ë„": "ê²½ë„ = 54.6658 +0.2039Â·ìŠµë„_mean_m04 +0.0144323Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.194462Â·ìŠµë„_mean_m08 -0.0140798Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.00218425Â·ê²°ë¡œì‹œê°„_mean_m04 +0.364872Â·í‰ê· ê¸°ì˜¨_mean_m08",
            "ë‹¹ë„": "ë‹¹ë„ = 1.14467 -0.425354Â·ìµœëŒ€í’ì†_mean_m06 -1.03279Â·í‰ê· í’ì†_mean_m07 -0.0754722Â·í‰ê· í’ì†_mean_m08 +0.781233Â·í‰ê· í’ì†_mean_m04 -0.0277847Â·ìµœê³ ê¸°ì˜¨_mean_m08 -0.0127413Â·ìŠµë„_mean_m05 +0.0022906Â·ê²°ë¡œì‹œê°„_mean_m05 +0.259103Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.0923847Â·ìŠµë„_mean_m04 +0.410232Â·ìµœëŒ€í’ì†_mean_m04 -0.00215038Â·ê°•ìš°ëŸ‰_sum_m06",
            "ì‚°ë„": "ì‚°ë„ = 0.262689 +0.0555189Â·ìµœëŒ€í’ì†_mean_m06 +0.0451885Â·í‰ê· í’ì†_mean_m08 -0.0549304Â·í‰ê· í’ì†_mean_m04 -0.00534754Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.0236952Â·í‰ê· í’ì†_mean_m07 -0.00264247Â·ìŠµë„_mean_m04 +0.00413186Â·ìŠµë„_mean_m08 -0.00334177Â·í‰ê· ê¸°ì˜¨_mean_m07 +0.000124634Â·ê°•ìš°ëŸ‰_sum_m06 -0.001393Â·ìŠµë„_mean_m05",
        },
        "í›„ì§€": {
            "ê³¼ì¤‘": "ê³¼ì¤‘ = 399.484 -0.229845Â·ì¼ì‚¬ëŸ‰_sum_m04 +6.76485Â·ìµœì €ê¸°ì˜¨_mean_m05 -17.8404Â·ìµœëŒ€í’ì†_mean_m07",
            "ì¢…ê²½": "ì¢…ê²½ = 183.553 -0.0439139Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.626045Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0145561Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.955631Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.0373121Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.656449Â·ìŠµë„_mean_m08 -0.0131851Â·ìŠµë„_mean_m06 +1.16239Â·í‰ê· ê¸°ì˜¨_mean_m07 -1.16892Â·ìµœì €ê¸°ì˜¨_mean_m09 -0.420997Â·ìŠµë„_mean_m09",
            "íš¡ê²½": "íš¡ê²½ = 79.6808 -1.82161Â·ìµœëŒ€í’ì†_mean_m07 +0.796471Â·í‰ê· ê¸°ì˜¨_mean_m05",
            "L":   "L = 75.7441 -0.134414Â·ìŠµë„_mean_m08 -0.400198Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0159958Â·ê°•ìš°ëŸ‰_sum_m10 +0.0240315Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.812706Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0812023Â·ìŠµë„_mean_m04 -0.206954Â·ìŠµë„_mean_m06 +0.116267Â·ìŠµë„_mean_m10 -0.0069829Â·ì¼ì‚¬ëŸ‰_sum_m04 -2.452Â·í‰ê· í’ì†_mean_m04 -0.0989298Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.384125Â·í‰ê· ê¸°ì˜¨_mean_m07",
            "a":   "a = 4.0922 -0.0203282Â·ê°•ìš°ëŸ‰_sum_m10 -2.85393Â·ìµœëŒ€í’ì†_mean_m05 -0.00910066Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0392451Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.307386Â·ìŠµë„_mean_m08 +0.000860505Â·ê°•ìš°ëŸ‰_sum_m08 -0.688696Â·ìµœëŒ€í’ì†_mean_m08 -0.00144964Â·ì¼ì‚¬ëŸ‰_sum_m05 +0.758309Â·ìµœëŒ€í’ì†_mean_m07",
            "b":   "b = 12.841 -0.0308293Â·ìŠµë„_mean_m08 +0.0145751Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.00322966Â·ê°•ìš°ëŸ‰_sum_m08 +0.035395Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0796701Â·ìŠµë„_mean_m10 -0.000543608Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00337387Â·ê°•ìš°ëŸ‰_sum_m10 -0.00372859Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.14243Â·ìŠµë„_mean_m06 +0.0641568Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.14721Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.53868Â·í‰ê· í’ì†_mean_m04",
            "ê²½ë„": "ê²½ë„ = 8.39888 +0.0529999Â·ì¼ì‚¬ëŸ‰_sum_m09 +6.94666Â·í‰ê· í’ì†_mean_m07 +3.98929Â·ìµœëŒ€í’ì†_mean_m08 -0.0451264Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.406065Â·ìŠµë„_mean_m04 -3.47701Â·í‰ê· í’ì†_mean_m06 -0.00806023Â·ê²°ë¡œì‹œê°„_mean_m10 +0.0392251Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00773583Â·ê²°ë¡œì‹œê°„_mean_m09 -2.0759Â·ìµœëŒ€í’ì†_mean_m10 +0.000289527Â·ê²°ë¡œì‹œê°„_mean_m06 -2.8229Â·ìµœëŒ€í’ì†_mean_m05 +0.000106158Â·ê²°ë¡œì‹œê°„_mean_m05 +0.270037Â·ìµœê³ ê¸°ì˜¨_mean_m09",
            "ë‹¹ë„": "ë‹¹ë„ = 10.492 +0.00486017Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00146432Â·ê²°ë¡œì‹œê°„_mean_m10 +0.00262004Â·ê²°ë¡œì‹œê°„_mean_m07 -0.00156465Â·ê²°ë¡œì‹œê°„_mean_m09 -1.20735Â·í‰ê· í’ì†_mean_m10 -0.000317261Â·ê²°ë¡œì‹œê°„_mean_m05",
            "ì‚°ë„": "ì‚°ë„ = 0.766184 -0.0175941Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.00379855Â·ìŠµë„_mean_m04 -0.00807644Â·ìµœê³ ê¸°ì˜¨_mean_m04 -4.6679e-05Â·ê°•ìš°ëŸ‰_sum_m08 +0.00318949Â·ìµœê³ ê¸°ì˜¨_mean_m08 -8.77968e-05Â·ê°•ìš°ëŸ‰_sum_m10 -0.00456198Â·í‰ê· í’ì†_mean_m04 +0.00411344Â·ìµœê³ ê¸°ì˜¨_mean_m07",
        },
    }

    # --- ì„¤ì •/ê²½ë¡œ í™•ì¸ ---
    if not GW_ENV_FILE.exists() or not GW_FRUIT_FILE.exists():
        st.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\ní™˜ê²½: {GW_ENV_FILE}\nê³¼ì‹¤: {GW_FRUIT_FILE}")
        st.stop()

    # --- ìœ í‹¸: ì›”ë²”ìœ„(í™ë¡œ 4~8, í›„ì§€ 4~10) ---
    def _month_window(cv: str):
        return (4, 8) if cv == "í™ë¡œ" else (4, 10)

    # --- ìœ í‹¸: íŒ¨í„´ìœ¼ë¡œ ì‹¤ì œ ê³¼ì‹¤ ì»¬ëŸ¼ ì°¾ê¸°(2023 ë¹„êµìš©) ---
    def _first_col_by_pattern(df: pd.DataFrame, pattern: str):
        pat = re.compile(pattern, flags=re.IGNORECASE)
        for c in df.columns:
            if pat.search(str(c)): return c
        return None

    # ê³¼ì‹¤ ì§€í‘œ ì •ê·œí™”ìš© íŒ¨í„´(ê°€ëŠ¥í•œ ë³„ì¹­ í¬í•¨)
    TARGET_PATTERNS = {
        "ê³¼ì¤‘": r"^ê³¼ì¤‘",
        "ì¢…ê²½": r"^ì¢…ê²½",
        "íš¡ê²½": r"^íš¡ê²½",
        "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
        "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
        "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
        "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
        "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
        "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
    }

    # --- ë°ì´í„° ë¡œë“œ ---
    env_all   = pd.read_excel(GW_ENV_FILE,   sheet_name=None)
    fruit_all = pd.read_excel(GW_FRUIT_FILE, sheet_name=None)

    # ì§€ì—­ ëª©ë¡(ìˆìœ¼ë©´ ì„ íƒ)
    def _collect_regions(dfs):
        regs = []
        for df in dfs.values():
            if "ì§€ì—­ëª…" in df.columns:
                regs += df["ì§€ì—­ëª…"].dropna().astype(str).unique().tolist()
        return sorted(list(dict.fromkeys(regs)))  # unique + keep order

    region_opts = _collect_regions(env_all) or ["(ì „ì²´)"]
    col1, col2 = st.columns([1,1])
    with col1:
        cultivar = st.radio("í’ˆì¢… ì„ íƒ", ["í™ë¡œ","í›„ì§€"], horizontal=True, key="tab6_cv")
    with col2:
        region = st.selectbox("ì§€ì—­ ì„ íƒ(í™˜ê²½/ê³¼ì‹¤ì—ì„œ ê³µí†µìœ¼ë¡œ í•„í„°ë§)", options=region_opts, index=(region_opts.index("ëŒ€êµ¬êµ°ìœ„") if "ëŒ€êµ¬êµ°ìœ„" in region_opts else 0))

    # ì§€ì—­ í•„í„° í•¨ìˆ˜(ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì „ì²´)
    def _filter_region(df: pd.DataFrame) -> pd.DataFrame:
        if "ì§€ì—­ëª…" in df.columns and region in region_opts and region != "(ì „ì²´)":
            m = df["ì§€ì—­ëª…"].astype(str) == str(region)
            return df.loc[m].copy()
        return df.copy()

    # --- í™˜ê²½: ì¼â†’ì—°/ì›”, ì›”ë³„ ì§‘ê³„ (PATCH) ---
    env_frames = [_filter_region(df) for df in env_all.values()]
    env_raw = pd.concat(env_frames, ignore_index=True)

    if "ì¼ì" not in env_raw.columns:
        st.error("í™˜ê²½ë°ì´í„°ì— 'ì¼ì' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    env_raw["date"]  = pd.to_datetime(env_raw["ì¼ì"], errors="coerce")
    env_raw["ì—°ë„"]  = env_raw["date"].dt.year
    env_raw["ì›”"]   = env_raw["date"].dt.month

    # íšŒê·€ì‹ì— ë“±ì¥ ê°€ëŠ¥í•œ ì›ì‹œ ë³€ìˆ˜ë“¤
    base_mean_vars = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","í‰ê· í’ì†","ìµœëŒ€í’ì†","ê²°ë¡œì‹œê°„"]
    base_sum_vars  = ["ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„"]  # sumì´ í•„ìš”í•œ ì• ë“¤(ê²°ë¡œì‹œê°„ì€ mean/sum ë‘˜ ë‹¤ ìˆ˜ì‹ì— ìˆì„ ìˆ˜ ìˆìŒ)

    # ì‹¤ì œë¡œ ìˆëŠ” ì»¬ëŸ¼ë§Œ ì“°ë˜, ë‚˜ì¤‘ì— ì—†ëŠ” ê²ƒì€ 0/NaN ìœ¼ë¡œ ë³´ì •
    present_mean = [c for c in base_mean_vars if c in env_raw.columns]
    present_sum  = [c for c in base_sum_vars  if c in env_raw.columns]

    for c in present_mean + present_sum:
        env_raw[c] = pd.to_numeric(env_raw[c], errors="coerce")

    # ì›”ë³„ mean
    env_mean = (env_raw.dropna(subset=["ì—°ë„","ì›”"])
                    .groupby(["ì—°ë„","ì›”"], as_index=False)[present_mean].mean()
                    .rename(columns={c: f"{c}_mean" for c in present_mean}))

    # ì›”ë³„ sum
    env_sum  = (env_raw.dropna(subset=["ì—°ë„","ì›”"])
                    .groupby(["ì—°ë„","ì›”"], as_index=False)[present_sum].sum()
                    .rename(columns={c: f"{c}_sum" for c in present_sum}))

    # í•©ì¹˜ê¸°
    env_month = pd.merge(env_mean, env_sum, on=["ì—°ë„","ì›”"], how="outer").sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

   # mean/sum ì»¬ëŸ¼ëª… ë¶„ë¦¬ ì •ë¦¬
    for c in num_cols_env:
        if c in env_month.columns and (c, "mean") in env_month.columns.to_flat_index() if isinstance(env_month.columns, pd.MultiIndex) else False:
            pass  # (ë©€í‹°ì¸ë±ìŠ¤ì¼ ê°€ëŠ¥ì„± ë°©ì§€ìš©)
    # ë©€í‹°ì¸ë±ìŠ¤ ëŒ€ë¹„
    if isinstance(env_month.columns, pd.MultiIndex):
        env_month.columns = ["ì—°ë„","ì›”"] + [f"{v}_{agg}" for v, agg in env_month.columns.tolist()[2:]]

    # wide: _mean_mMM / _sum_mMM ëª¨ë‘ ìƒì„±
    def _wide_mean_sum(env_m: pd.DataFrame) -> pd.DataFrame:
        # mean ê³„ì—´
        wide_mean = None
        for m in range(1, 13):
            sub = env_m[env_m["ì›”"] == m][["ì—°ë„"] + [f"{c}_mean" for c in num_cols_env if f"{c}_mean" in env_m.columns]].copy()
            sub = sub.rename(columns={f"{c}_mean": f"{c}_mean_m{m:02d}" for c in num_cols_env if f"{c}_mean" in env_m.columns})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        # sum ê³„ì—´
        wide_sum = None
        for m in range(1, 13):
            sub = env_m[env_m["ì›”"] == m][["ì—°ë„"] + [f"{c}_sum" for c in num_cols_env if f"{c}_sum" in env_m.columns]].copy()
            sub = sub.rename(columns={f"{c}_sum": f"{c}_sum_m{m:02d}" for c in num_cols_env if f"{c}_sum" in env_m.columns})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        out = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer")
        return out

    # 2024 ì±„ì›€: ì›”ë²”ìœ„(í’ˆì¢…ë³„) ë‚´ì—ì„œ í˜„ì¬ ë°ì´í„° ì—†ìœ¼ë©´ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´
    def _fill_year_climo(env_m: pd.DataFrame, year_val: int, cv: str) -> pd.DataFrame:
        s_mon, e_mon = _month_window(cv)
        base = pd.DataFrame({"ì—°ë„":[year_val]*12, "ì›”":list(range(1,13))})
        cur  = env_m[env_m["ì—°ë„"] == year_val]
        hist = env_m[env_m["ì—°ë„"] <  year_val]
        out = base.merge(cur, on=["ì—°ë„","ì›”"], how="left")
        if not hist.empty:
            # ê³¼ê±° ì „ì²´ í‰ê·  ì‚¬ìš©
            cl_mean = hist.groupby("ì›”", as_index=False)[[f"{c}_mean" for c in num_cols_env if f"{c}_mean" in env_m.columns]].mean()
            cl_sum  = hist.groupby("ì›”", as_index=False)[[f"{c}_sum"  for c in num_cols_env if f"{c}_sum"  in env_m.columns]].mean()
            out = out.merge(cl_mean, on="ì›”", how="left", suffixes=("","_clmo"))
            out = out.merge(cl_sum,  on="ì›”", how="left", suffixes=("","_clmo2"))
            # ë¹„ì–´ìˆìœ¼ë©´ ê¸°í›„í‰ë…„ìœ¼ë¡œ ì±„ì›€
            for c in [f"{v}_mean" for v in num_cols_env if f"{v}_mean" in env_m.columns]:
                out[c] = np.where(out[c].notna(), out[c], out.get(f"{c}_clmo"))
            for c in [f"{v}_sum" for v in num_cols_env if f"{v}_sum in env_m.columns"]:
                pass  # ì•ˆì „
            for v in num_cols_env:
                if f"{v}_sum" in env_m.columns and f"{v}_sum_clmo2" in out.columns:
                    c = f"{v}_sum"
                    out[c] = np.where(out[c].notna(), out[c], out[f"{c}_clmo2"])
            # ë¶ˆí•„ìš”í•œ *_clmo, *_clmo2 ì œê±°
            out = out[[col for col in out.columns if not (str(col).endswith("_clmo") or str(col).endswith("_clmo2"))]]
        # í’ˆì¢… ì›”ë²”ìœ„ ìë¥´ê¸°(ì‹œê°í™”/ì•ˆì „)
        out = out[(out["ì›”"] >= s_mon) & (out["ì›”"] <= e_mon)].copy()
        # ë‹¤ì‹œ 12ê°œì›” í˜•íƒœë¡œ ë§Œë“¤ê¸° ìœ„í•´ ëˆ„ë½ì›”ì€ climoë¡œ ì±„ìš´ full 12ê°œì›” ë²„ì „ë„ ìƒì„±
        full = base.merge(out, on=["ì—°ë„","ì›”"], how="left")
        if not hist.empty:
            # ë‚¨ì€ ì›”ë„ ê¸°í›„í‰ë…„ìœ¼ë¡œ
            for v in num_cols_env:
                if f"{v}_mean" in env_m.columns:
                    c = f"{v}_mean"
                    cl = hist.groupby("ì›”", as_index=False)[c].mean().rename(columns={c:"_cl"})
                    full = full.merge(cl, on="ì›”", how="left")
                    full[c] = np.where(full[c].notna(), full[c], full["_cl"]); full = full.drop(columns=["_cl"])
                if f"{v}_sum" in env_m.columns:
                    c = f"{v}_sum"
                    cl = hist.groupby("ì›”", as_index=False)[c].mean().rename(columns={c:"_cl"})
                    full = full.merge(cl, on="ì›”", how="left")
                    full[c] = np.where(full[c].notna(), full[c], full["_cl"]); full = full.drop(columns=["_cl"])
        return full

    # ì§‘ê³„ í…Œì´ë¸” ì»¬ëŸ¼ ì •ë¦¬: ë©€í‹°ì¸ë±ìŠ¤ ë°©ì§€ + mean/sum ì ‘ë¯¸ì‚¬ ë¶€ì—¬
    # (ì´ë¯¸ ìœ„ì—ì„œ mean/sum í˜•íƒœë¡œ ë‚˜ì™”ì„ ê°€ëŠ¥ì„± ê³ ë ¤í•˜ì—¬ ë³´ì •)
    if not any(k.endswith("_mean") or k.endswith("_sum") for k in env_month.columns if k not in ["ì—°ë„","ì›”"]):
        # env_monthê°€ 'í‰ê· ê¸°ì˜¨','í‰ê· ê¸°ì˜¨1'(sum) ê°™ì´ ì•ˆ ë“¤ì–´ì™”ë‹¤ë©´ ë‹¤ì‹œ ë¶„ë¦¬
        cols_keep = ["ì—°ë„","ì›”"]
        # ì›ë³¸ì—ì„œ ë‹¤ì‹œ mean/sum ë‚˜ëˆ  ìƒì„±
        tmp = env_raw.groupby(["ì—°ë„","ì›”"], as_index=False).agg({**{c:"mean" for c in num_cols_env}, **{c:"sum" for c in num_cols_env}})
        if isinstance(tmp.columns, pd.MultiIndex):
            tmp.columns = ["ì—°ë„","ì›”"] + [f"{v}_{agg}" for v, agg in tmp.columns.tolist()[2:]]
        env_month = tmp

    # 2024ìš© ì›”ë³„(í´ë¦¬ëª¨ ì±„ì›€) â†’ wide ìƒì„±
    env2024_m = _fill_year_climo(env_month, 2024, cultivar)
    st.caption("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ 2024 ì›”ë³„ ì§‘ê³„(ì—†ëŠ” ì›”ì€ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´)")
    st.dataframe(env2024_m, use_container_width=True)

    # wide ìƒì„±(ì—°ë„ 2024 í•˜ë‚˜)
    env2024_m["ì—°ë„"] = 2024
    wide_all = _wide_mean_sum(env2024_m)
    row2024 = wide_all[wide_all["ì—°ë„"] == 2024].iloc[0]

    # --- íšŒê·€ì‹ ì ìš© ---
    def apply_equation_row(row: pd.Series, eq_str: str) -> float:
        rhs = eq_str.split("=",1)[1].strip().replace("Â·","*")
        # ê¸´ ì´ë¦„ë¶€í„° ì¹˜í™˜(ë¶€ë¶„ ë¬¸ìì—´ ì¶©ëŒ ë°©ì§€)
        for c in sorted(row.index.tolist(), key=len, reverse=True):
            rhs = rhs.replace(c, f"row[{repr(c)}]")
        return float(eval(rhs, {"__builtins__": {}}, {"row": row, "np": np}))

    EQU = EQUATIONS_BY_CULTIVAR[cultivar]
    preds = {}
    for tgt, formula in EQU.items():
        try:
            preds[tgt] = apply_equation_row(row2024, formula)
        except Exception as e:
            preds[tgt] = np.nan
            st.warning(f"[{tgt}] ìˆ˜ì‹ ì ìš© ì˜¤ë¥˜: {e}")

    pred_df = pd.DataFrame([preds]).T.reset_index()
    pred_df.columns = ["í•­ëª©","2024 ì˜ˆì¸¡"]

    # --- 2023 ì‹¤ì œê°’(ë™ì¼ ì§€ì—­Â·í’ˆì¢… í‰ê· ) ---
    fruit_frames = [_filter_region(df) for df in fruit_all.values()]
    fruit_raw = pd.concat(fruit_frames, ignore_index=True)

    # ì—°ë„ íŒŒì‹±
    if "year" in fruit_raw.columns:
        fruit_raw["year"] = gw_to_year_series(fruit_raw["year"])
    elif "ì—°ë„" in fruit_raw.columns:
        fruit_raw["year"] = gw_to_year_series(fruit_raw["ì—°ë„"])
    elif "ì¼ì" in fruit_raw.columns:
        fruit_raw["year"] = gw_to_year_series(fruit_raw["ì¼ì"])
    else:
        fruit_raw["year"] = pd.NA

    cult_col = gw_find_cultivar_col(fruit_raw) or "_í’ˆì¢…ì„ì‹œ"
    if cult_col not in fruit_raw.columns:
        fruit_raw[cult_col] = "ALL"

    # 2023 í–‰ë§Œ, ì„ íƒ í’ˆì¢… í•„í„°
    f23 = fruit_raw[(fruit_raw["year"] == 2023) & (fruit_raw[cult_col] == cultivar)].copy()

    actual_rows = []
    for tgt, pat in TARGET_PATTERNS.items():
        col = _first_col_by_pattern(f23, pat)
        if col is not None:
            val = pd.to_numeric(f23[col], errors="coerce").mean()
        else:
            val = np.nan
        actual_rows.append([tgt, val])
    actual_df = pd.DataFrame(actual_rows, columns=["í•­ëª©","2023 ì‹¤ì œ"])

    # --- í•©ì¹˜ê¸° & í‘œì‹œ ---
    out = pred_df.merge(actual_df, on="í•­ëª©", how="left")
    st.subheader(f"{region} Â· {cultivar} â€” 2024 ì˜ˆì¸¡ vs 2023 ì‹¤ì œ")
    st.dataframe(out.set_index("í•­ëª©").T, use_container_width=True)

    # --- ì†Œí˜• ê·¸ë˜í”„(ê°™ì€ ìŠ¤íƒ€ì¼) ---
    def _pick(df, item):
        r = df[df["í•­ëª©"] == item]
        if r.empty: return np.nan, np.nan
        return pd.to_numeric(r["2024 ì˜ˆì¸¡"], errors="coerce").iloc[0], pd.to_numeric(r["2023 ì‹¤ì œ"], errors="coerce").iloc[0]

    PRED_COLOR = "#87CEEB"
    LAST_COLOR = "#800080"

    # 1) ê³¼ì¤‘/íš¡ê²½/ì¢…ê²½
    size_items = [i for i in ["ê³¼ì¤‘","íš¡ê²½","ì¢…ê²½"] if i in out["í•­ëª©"].values]
    if size_items:
        x = np.arange(len(size_items)); y_pred=[]; y_last=[]
        for it in size_items:
            p,l=_pick(out,it); y_pred.append(p); y_last.append(l)
        fig, ax = plt.subplots(figsize=(3.5, 2.6))
        w=0.35
        ax.bar(x-w/2, np.nan_to_num(y_pred,nan=0.0), width=w, label="2024 ì˜ˆì¸¡", color=PRED_COLOR)
        ax.bar(x+w/2, np.nan_to_num(y_last,nan=0.0), width=w, label="2023 ì‹¤ì œ", color=LAST_COLOR)
        ax.set_xticks(x); ax.set_xticklabels(size_items); ax.set_title("ê³¼ì‹¤ í¬ê¸°")
        ax.grid(axis="y", linestyle=":", alpha=0.35)
        ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
        ax.legend(); fig.tight_layout(); st.pyplot(fig, use_container_width=False)

    # 2) ê²½ë„/ë‹¹ë„/ì‚°ë„
    def _bar_single(item, ylim_top=None):
        p,l = _pick(out,item)
        if pd.isna(p) and pd.isna(l): return
        xs=[]; ys=[]; cs=[]
        if not pd.isna(p): xs.append("2024 ì˜ˆì¸¡"); ys.append(float(p)); cs.append(PRED_COLOR)
        if not pd.isna(l): xs.append("2023 ì‹¤ì œ"); ys.append(float(l)); cs.append(LAST_COLOR)
        fig, ax = plt.subplots(figsize=(2.5,1.8))
        ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
        ax.set_title(item); ax.grid(axis="y", linestyle=":", alpha=0.35)
        if ylim_top: ax.set_ylim(top=ylim_top)
        ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
        fig.tight_layout(); st.pyplot(fig, use_container_width=False)

    c1, c2, c3 = st.columns(3)
    with c1: _bar_single("ê²½ë„", ylim_top=70)
    with c2: _bar_single("ë‹¹ë„")
    with c3: _bar_single("ì‚°ë„")

    # 3) L/a/b
    tone_items = [i for i in ["L","a","b"] if i in out["í•­ëª©"].values]
    if tone_items:
        x = np.arange(len(tone_items)); yp=[]; yl=[]
        for it in tone_items:
            p,l=_pick(out,it); yp.append(p); yl.append(l)
        fig, ax = plt.subplots(figsize=(3.5,2.6))
        if any(pd.notna(yp)): ax.plot(x, yp, marker="o", linewidth=2, label="2024 ì˜ˆì¸¡", color=PRED_COLOR)
        if any(pd.notna(yl)): ax.plot(x, yl, marker="o", linewidth=2, label="2023 ì‹¤ì œ", color=LAST_COLOR)
        ax.set_xticks(x); ax.set_xticklabels(tone_items); ax.set_title("ì°©ìƒ‰ë„")
        ax.grid(axis="y", linestyle=":", alpha=0.35)
        ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
        ax.legend(); fig.tight_layout(); st.pyplot(fig, use_container_width=False)

    # --- ë‹¤ìš´ë¡œë“œ ---
    cA, cB = st.columns(2)
    with cA:
        st.download_button("â¬‡ï¸ ì˜ˆì¸¡/ì‹¤ì œ ë¹„êµí‘œ CSV",
            out.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{cultivar}_2024_pred_vs_2023_actual(eq).csv",
            mime="text/csv")
    with cB:
        # 2024 ì˜ˆì¸¡ì— ì‚¬ìš©ëœ wide ë³€ìˆ˜ ì „ì²´ ë‚´ë³´ë‚´ê¸°
        vars_df = pd.DataFrame([row2024]).T.reset_index()
        vars_df.columns = ["ë³€ìˆ˜","ê°’"]
        st.download_button("â¬‡ï¸ 2024 ì…ë ¥ë³€ìˆ˜(BUILT) CSV",
            vars_df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{cultivar}_2024_env_wide_mean_sum.csv",
            mime="text/csv")

