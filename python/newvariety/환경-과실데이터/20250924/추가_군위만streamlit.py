# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import requests
import io
import re
import os
from datetime import datetime
from typing import Optional
import matplotlib
import matplotlib.font_manager as fm

# í˜ì´ì§€ ì„¤ì • (ìµœìƒë‹¨ 1íšŒ)
st.set_page_config(page_title="ğŸ êµ°ìœ„ ë¶„ì„ & ì˜ˆì¸¡", layout="wide")

# ê³µí†µ í°íŠ¸ ì„¤ì •
def _set_korean_font():
    bundled_candidates = [
        "fonts/NanumGothic.ttf",
        "fonts/NotoSansKR-Regular.otf",
        "NanumGothic.ttf",
        "NotoSansKR-Regular.otf",
    ]
    for p in bundled_candidates:
        if os.path.exists(p):
            try:
                fm.fontManager.addfont(p)
                family = fm.FontProperties(fname=p).get_name()
                matplotlib.rcParams["font.family"] = family
                matplotlib.rcParams["axes.unicode_minus"] = False
                return
            except Exception:
                pass
    preferred = ["Malgun Gothic", "AppleGothic", "NanumGothic",
                 "Noto Sans CJK KR", "Noto Sans KR", "NanumBarunGothic"]
    sys_fonts = set(f.name for f in fm.fontManager.ttflist)
    for name in preferred:
        if name in sys_fonts:
            matplotlib.rcParams["font.family"] = name
            matplotlib.rcParams["axes.unicode_minus"] = False
            return
    matplotlib.rcParams["axes.unicode_minus"] = False
_set_korean_font()
plt.rcParams["font.size"] = 6

# =========================
# íƒ­ êµ¬ì„±
# =========================
tab1, tab2 = st.tabs(["ë¶„ì„ê²°ê³¼(êµ°ìœ„)", "ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„)"])

# ==========================================================
# íƒ­1: ë¶„ì„ê²°ê³¼(êµ°ìœ„) - ì´ë¯¸ì§€/í‘œ ë·°ì–´ (í™ë¡œ/í›„ì§€)
# ==========================================================
with tab1:
    st.title("êµ°ìœ„ - ë¶„ì„ ê²°ê³¼")
    BASE_DIR = Path(r"C:\Users\User\Desktop\mba\ë¶„ì„ê²°ê³¼\êµ°ìœ„")
    CULTIVARS = ["í™ë¡œ", "í›„ì§€"]

    # ê²°ê³¼ ìì‚°(ì´ë¯¸ì§€/í‘œ) ìë™ ê²€ìƒ‰: í•˜ìœ„ì— 'í™ë¡œ','í›„ì§€' í´ë”ê°€ ìˆê±°ë‚˜, íŒŒì¼ëª…ì— í’ˆì¢…ëª…ì´ ë“¤ì–´ìˆëŠ” ê²½ìš° ëª¨ë‘ ì§€ì›
    IMG_EXT = (".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp")
    TAB_EXT = (".csv", ".xlsx")

    def get_assets_for_cultivar(cultivar: str):
        # 1) í´ë” ëª¨ë“œ: BASE_DIR/í™ë¡œ, BASE_DIR/í›„ì§€ ì¡´ì¬ ì‹œ
        folder1 = BASE_DIR / cultivar
        if folder1.exists():
            imgs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in IMG_EXT])
            tabs = sorted([p for p in folder1.rglob("*") if p.suffix.lower() in TAB_EXT])
            root = folder1
        else:
            # 2) íŒŒì¼ëª… í•„í„° ëª¨ë“œ: BASE_DIR ë‚´ íŒŒì¼ëª…ì— í’ˆì¢… í¬í•¨
            imgs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in IMG_EXT and cultivar in p.stem)])
            tabs = sorted([p for p in BASE_DIR.glob("*") if (p.suffix.lower() in TAB_EXT and cultivar in p.stem)])
            root = BASE_DIR
        return root, imgs, tabs

    cultivar = st.radio("í’ˆì¢… ì„ íƒ", CULTIVARS, horizontal=True)

    folder, all_imgs, all_tabs = get_assets_for_cultivar(cultivar)
    if not BASE_DIR.exists():
        st.error(f"êµ°ìœ„ ê²°ê³¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {BASE_DIR}")
        st.stop()

    mode = st.segmented_control("í‘œì‹œ ìœ í˜•", options=["ì´ë¯¸ì§€", "í‘œ(ë°ì´í„°)"])
    if mode == "ì´ë¯¸ì§€":
        if not all_imgs:
            st.warning("í‘œì‹œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ/íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”)")
        else:
            view = st.radio("ë°©ì‹ ì„ íƒ", ["ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)", "ë‹¨ì¼ íŒŒì¼"], horizontal=True)
            if view == "ê°¤ëŸ¬ë¦¬(ì¸ë„¤ì¼)":
                thumbs = st.slider("í•œ ì¤„ì— ëª‡ ì¥", min_value=2, max_value=6, value=4)
                rows = (len(all_imgs) + thumbs - 1) // thumbs
                st.caption(f"ì´ {len(all_imgs)}ê°œ ì´ë¯¸ì§€")
                idx = 0
                for _ in range(rows):
                    cols = st.columns(thumbs, gap="small")
                    for c in cols:
                        if idx >= len(all_imgs):
                            break
                        p = all_imgs[idx]
                        with c:
                            st.image(str(p), caption=str(p.relative_to(folder)))
                        idx += 1
            else:
                sel = st.selectbox("ì´ë¯¸ì§€ ì„ íƒ", [str(p.relative_to(folder)) for p in all_imgs])
                path = folder / sel
                st.image(str(path), caption=str(path))
    else:
        if not all_tabs:
            st.warning("í‘œì‹œí•  CSV/XLSX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sel = st.selectbox("í‘œ ì„ íƒ", [str(p.relative_to(folder)) for p in all_tabs])
            path = folder / sel
            st.subheader("í‘œì‹œ ì¤‘: " + str(path.name))
            try:
                if path.suffix.lower() == ".csv":
                    df = pd.read_csv(path, encoding="utf-8-sig")
                else:
                    df = pd.read_excel(path)
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.error(f"ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

# ==========================================================
# íƒ­2: ê³¼ì‹¤í’ˆì§ˆ ì˜ˆì¸¡(êµ°ìœ„ ê³ ì •)
# ==========================================================
with tab2:
    st.markdown("<h1 style='text-align: center;'>ğŸ êµ°ìœ„ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡</h1>", unsafe_allow_html=True)

    # ---------------------------
    # ì§€ì—­/ì½”ë“œ: êµ°ìœ„ ì „ìš©
    # ---------------------------
    AREA_CODE = {"ëŒ€êµ¬êµ°ìœ„": "333"}  # APIìš© í‚¤
    REGION_NAME_MAP = {"ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„"}  # í™”ë©´ í‘œì‹œëª…

    # ---------------------------
    # íšŒê·€ì‹ (êµ°ìœ„ìš©)
    # ---------------------------
    EQUATIONS_BY_CULTIVAR = {
    "í™ë¡œ": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 157.237 -137.847Â·í‰ê· í’ì†_mean_m08 +1.312Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.205849Â·ê°•ìš°ëŸ‰_sum_m05 +3.9929Â·ìµœì €ê¸°ì˜¨_mean_m07",
        "ì¢…ê²½": "ì¢…ê²½ = 36.9151 +0.613954Â·ìµœì €ê¸°ì˜¨_mean_m04 +0.244159Â·ìŠµë„_mean_m04 +0.577148Â·ìµœê³ ê¸°ì˜¨_mean_m07 +0.0405461Â·ê°•ìš°ëŸ‰_sum_m05",
        "íš¡ê²½": "íš¡ê²½ = 89.2207 -19.1684Â·í‰ê· í’ì†_mean_m08 +0.00285688Â·ê²°ë¡œì‹œê°„_mean_m04 +0.0137361Â·ê°•ìš°ëŸ‰_sum_m05",
        "L":   "L = -107.653 +4.02276Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.557626Â·ìµœê³ ê¸°ì˜¨_mean_m08 +0.357053Â·ìŠµë„_mean_m05 +1.23389Â·ìµœëŒ€í’ì†_mean_m08 +5.79158Â·í‰ê· í’ì†_mean_m07",
        "a":   "a = 28.916 +26.4391Â·ìµœëŒ€í’ì†_mean_m05 -2.04984Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.525233Â·í‰ê· ê¸°ì˜¨_mean_m08 -7.60126Â·ìµœëŒ€í’ì†_mean_m08 -0.0905347Â·ìŠµë„_mean_m05",
        "b":   "b = -44.3799 -0.0102677Â·ìµœëŒ€í’ì†_mean_m05 +1.63975Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.201082Â·ìŠµë„_mean_m05 +1.29407Â·ìµœëŒ€í’ì†_mean_m08",
        "ê²½ë„": "ê²½ë„ = 53.7403 +0.0406574Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0109639Â·ê²°ë¡œì‹œê°„_mean_m04 -5.99111Â·ìµœëŒ€í’ì†_mean_m05 +0.00101735Â·ê²°ë¡œì‹œê°„_mean_m05",
        "ë‹¹ë„": "ë‹¹ë„ = -3.77559 +0.845922Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.000435945Â·ê°•ìš°ëŸ‰_sum_m07 +0.00284123Â·ê²°ë¡œì‹œê°„_mean_m04 -0.343821Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.0040703Â·ê°•ìš°ëŸ‰_sum_m06",
        "ì‚°ë„": "ì‚°ë„ = 0.23201 -0.000127841Â·ê²°ë¡œì‹œê°„_mean_m05 -1.60354e-05Â·ê°•ìš°ëŸ‰_sum_m05 +0.0112801Â·í‰ê· í’ì†_mean_m06 +0.0202028Â·ìµœëŒ€í’ì†_mean_m05 -7.47002e-05Â·ê²°ë¡œì‹œê°„_mean_m04",
    },
    "í›„ì§€": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 280.193 -14.9938Â·ìµœëŒ€í’ì†_mean_m04 +7.01039Â·í‰ê· ê¸°ì˜¨_mean_m09 -0.216694Â·ì¼ì‚¬ëŸ‰_sum_m10",
        "ì¢…ê²½": "ì¢…ê²½ = 67.5821 +0.707095Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0488712Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.880706Â·ìµœê³ ê¸°ì˜¨_mean_m09",
        "íš¡ê²½": "íš¡ê²½ = 95.1048 +0.181127Â·ìŠµë„_mean_m04 -0.0132518Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.276929Â·ìŠµë„_mean_m08 +0.487867Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "L":   "L = -25.351 +0.317467Â·ìŠµë„_mean_m04 +0.063049Â·ìµœì €ê¸°ì˜¨_mean_m09 +0.310649Â·ìŠµë„_mean_m10 +1.19993Â·ìµœê³ ê¸°ì˜¨_mean_m10",
        "a":   "a = 24.306 -0.0581428Â·ê°•ìš°ëŸ‰_sum_m04 +7.83592Â·í‰ê· í’ì†_mean_m08 -0.515246Â·ìµœê³ ê¸°ì˜¨_mean_m10 +6.87267Â·í‰ê· í’ì†_mean_m05",
        "b":   "b = 18.3498 -0.0117526Â·ìŠµë„_mean_m10 -0.0255657Â·ì¼ì‚¬ëŸ‰_sum_m10 -5.44522Â·í‰ê· í’ì†_mean_m09 +0.493188Â·ìµœê³ ê¸°ì˜¨_mean_m04",
        "ê²½ë„": "ê²½ë„ = 44.1071 -0.0341814Â·ê°•ìš°ëŸ‰_sum_m10 +0.00537892Â·ê°•ìš°ëŸ‰_sum_m07 +4.75772Â·ìµœëŒ€í’ì†_mean_m08 +1.15897Â·ìµœì €ê¸°ì˜¨_mean_m04",
        "ë‹¹ë„": "ë‹¹ë„ = 7.35627 +2.56347Â·ìµœëŒ€í’ì†_mean_m08 -0.0270168Â·ìŠµë„_mean_m09 +0.0171314Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.525697Â·ìµœì €ê¸°ì˜¨_mean_m06 -0.231632Â·ìµœê³ ê¸°ì˜¨_mean_m05",
        "ì‚°ë„": "ì‚°ë„ = 1.14472 +0.169768Â·í‰ê· í’ì†_mean_m08 -0.0438612Â·ìµœê³ ê¸°ì˜¨_mean_m10 +5.80039e-05Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.103592Â·í‰ê· í’ì†_mean_m05 -0.000376686Â·ê°•ìš°ëŸ‰_sum_m04",
    },
}


    # ---------------------------
    # ìœ í‹¸/ì „ì²˜ë¦¬ í•¨ìˆ˜
    # ---------------------------
    def _clean_str(s: str) -> str:
        s = str(s).replace("\xa0", " ")
        s = s.replace("\n", " ").replace("\r", " ")
        s = re.sub(r"\s+", " ", s).strip()
        s = re.sub(r"\s*\(\s*", " (", s)
        s = re.sub(r"\s*\)\s*", ")", s)
        return s

    def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
        out = df.copy()
        if isinstance(out.columns, pd.MultiIndex):
            out.columns = [" ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                           for tup in out.columns.values]
        out.columns = [_clean_str(c) for c in out.columns]
        alias = {
            "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
            "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
            "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
            "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
        }
        out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})
        if "ì§€ì—­" in out.columns:
            out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in out.columns:
            out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")
        return out

    def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
        pat = re.compile(pattern, flags=re.IGNORECASE)
        for c in df.columns:
            if pat.search(str(c)):
                return c
        return None

    def _ensure_numeric(df: pd.DataFrame, cols):
        for c in cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce")
        return df

    def cultivar_window(cultivar: str):
        return (4, 8) if cultivar == "í™ë¡œ" else (4, 10)

    def get_today_ym():
        now = datetime.now()
        return now.year, now.month

    @st.cache_data(show_spinner=False, ttl=300)
    def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
        session = requests.Session()
        session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)
        form = {
            "pageIndex": "1",
            "searchNum": "0",
            "areaName": region_name,
            "areaCode": AREA_CODE.get(region_name, region_name),
            "statmethod": stat_gb_code,
        }
        if stat_gb_code == "A":
            form["wetherDtBgn"] = f"{s_ym}-01"; form["wetherDtEnd"] = f"{e_ym}-30"
        elif stat_gb_code in ("B", "C"):
            form["wetherDtM"] = s_ym
        else:  # "D"
            form["wetherDtBgn2"] = s_ym; form["wetherDtEnd2"] = e_ym
            form["wetherDtBgn"]  = s_ym; form["wetherDtEnd"]  = e_ym
        resp = session.post(
            "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
            data=form, timeout=30,
            headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
        )
        resp.raise_for_status()
        try:
            return resp.json()
        except Exception:
            return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

    def json_to_dataframe(payload: dict) -> pd.DataFrame:
        if not payload or "result" not in payload:
            return pd.DataFrame()
        res = payload.get("result", [])
        if len(res) == 0:
            return pd.DataFrame()
        method = payload.get("mainAwsVO", {}).get("statmethod")
        raw = pd.DataFrame(res)
        with st.expander("ğŸ”§ API ì›ì‹œ ì»¬ëŸ¼ ë³´ê¸°", expanded=False):
            st.write(sorted(list(raw.columns)))
        rename_map = {
            "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
            "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
            "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
            "dalyWetherAvrgHd": "ìŠµë„", "WetherAvgHd": "ìŠµë„",
            "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰", "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰", "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
            "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„", "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„", "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
            "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
            "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
        }
        raw = raw.rename(columns=rename_map)
        if method == "A":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "B":
            want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        elif method == "C":
            want = ["ìˆœ","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"] if "ìˆœ" in raw.columns \
                else ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        else:
            want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
                if "ì›”" in raw.columns else \
                ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        use_cols = [c for c in want if c in raw.columns]
        if not use_cols:
            return pd.DataFrame()
        df = raw[use_cols].copy()
        numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
        df = _ensure_numeric(df, [c for c in numcands if c in df.columns])
        if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
            df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
            if "ì—°ë„" not in df.columns: df["ì—°ë„"] = df["ì¼ì"].dt.year
            if "ì›”"   not in df.columns: df["ì›”"]   = df["ì¼ì"].dt.month
        elif "ì›”" in df.columns:
            df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
            df["ì›”"]   = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")
        if {"ì—°ë„","ì›”"}.issubset(df.columns):
            df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        return df

    def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(df.columns):
            return df.copy()
        agg_map = {
            "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
            "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
            "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
        }
        use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
        out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
        return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

    def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
        if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
            raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
        sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
        wide_mean = None
        for m in range(1, 12+1):
            sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
            wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
        wide_sum = None
        for m in range(1, 12+1):
            sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
            sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
            wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
        wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
        return wide

    def apply_equation_row(row: pd.Series, eq_str: str) -> float:
        rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
        cols = sorted(row.index.tolist(), key=len, reverse=True)
        expr = rhs
        for c in cols:
            expr = expr.replace(c, f"row[{repr(c)}]")
        return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

    def fill_missing_or_future_with_climatology(env_m: pd.DataFrame, target_year: int, cultivar: str, mode: str = "all") -> pd.DataFrame:
        need_cols = {"ì—°ë„","ì›”"}
        if not need_cols.issubset(env_m.columns):
            raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        s_mon, e_mon = cultivar_window(cultivar)
        cur_year, cur_mon = get_today_ym()
        cur = env_m[env_m["ì—°ë„"] == target_year].copy()
        hist = env_m[env_m["ì—°ë„"] < target_year].copy()
        if hist.empty:
            return cur
        # 'all' == ì „ì²´ ê³¼ê±° í‰ê·  ì‚¬ìš©
        num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
        climo_all = hist.groupby("ì›”", as_index=False)[num_cols].mean()
        months_window = list(range(s_mon, e_mon+1))
        have = set(cur["ì›”"].tolist())
        future_cut = cur_mon if target_year == cur_year else 12
        future_months = [m for m in months_window if (target_year == cur_year and m > future_cut) or (target_year > cur_year)]
        missing_months = [m for m in months_window if m not in have]
        to_fill = sorted(set(future_months) | set(missing_months))
        if to_fill:
            fill_rows = climo_all[climo_all["ì›”"].isin(to_fill)].copy()
            fill_rows.insert(0, "ì—°ë„", target_year)
            cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)
        cur = cur[(cur["ì›”"] >= s_mon) & (cur["ì›”"] <= e_mon)].sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
        for c in num_cols:
            cur[c] = pd.to_numeric(cur[c], errors="coerce")
        return cur

    def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
        code = "apple01" if cultivar == "í›„ì§€" else "apple02"
        url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
        params = {
            "frtgrdCode": "apple",
            "selyear": str(selyear),
            "lastYear": str(lastyear),
            "searchGubun": code,
            "pageIndex": "1",
        }
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        try:
            tables = pd.read_html(io.StringIO(r.text))
        except Exception as e:
            st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹± ì‹¤íŒ¨: {e}\n(lxml/html5lib í•„ìš”)")
            return {}
        cleaned = []
        for t in tables:
            t2 = normalize_quality_columns(t)
            if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(set(t2.columns)):
                cleaned.append(t2)
        result = {}
        if len(cleaned) >= 1: result["this"] = cleaned[0]
        if len(cleaned) >= 2: result["last"] = cleaned[1]
        return result

    def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
        if qdf is None or qdf.empty: return None
        region_disp_name = _clean_str(region_disp_name)
        if "ì§€ì—­" not in qdf.columns: return None
        tmp = qdf.copy()
        tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
        if "ìˆ˜í™•ì¼ì" in tmp.columns and not np.issubdtype(tmp["ìˆ˜í™•ì¼ì"].dtype, np.datetime64):
            tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
        sub = tmp[tmp["ì§€ì—­"] == region_disp_name]
        if sub.empty: return None
        sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
        return sub.iloc[0]

    # ---------------------------
    # ì¡°íšŒ/ì˜ˆì¸¡ UI (êµ°ìœ„ ê³ ì •)
    # ---------------------------
    c1, c2 = st.columns([1,1])
    with c1:
        cultivar = st.radio("í’ˆì¢… ì„ íƒ", ["í™ë¡œ", "í›„ì§€"], horizontal=True, key="cv_radio")
    with c2:
        st.text("ì§€ì—­ ì„ íƒ")
        st.info("êµ°ìœ„(ëŒ€êµ¬êµ°ìœ„)ë¡œ ê³ ì •")
    region = "ëŒ€êµ¬êµ°ìœ„"  # ë‚´ë¶€ í‚¤
    region_disp = REGION_NAME_MAP[region]

    run = st.button("ğŸ” êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡")
    mode = "all"  # í•­ìƒ ì „ì²´ ê³¼ê±° í‰ê·  ê¸°ë°˜ìœ¼ë¡œ ë¯¸í™•ë³´ ì›” ì±„ì›€

    if run:
        try:
            cur_year, cur_month = get_today_ym()
            s_mon, e_mon = cultivar_window(cultivar)
            s_ym = f"{cur_year:04d}-{s_mon:02d}"
            e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

            with st.spinner("ê¸°ìƒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
                payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)

            if "error" in payload:
                st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                st.code(payload.get("raw","")[:1000])
                st.stop()

            df = json_to_dataframe(payload)
            st.subheader(f"ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡ ë°ì´í„°(ê¸°ìƒ) - {region_disp}")
            if df.empty:
                st.warning("ì˜¬í•´ ê¸°ê°„ ë‚´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê³¼ê±° í‰ê· ìœ¼ë¡œ ì±„ì›Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")
            else:
                st.dataframe(df, use_container_width=True)
        except Exception as e:
            st.error("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.exception(e)

        env_m = df.copy()
        if not env_m.empty and "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"]   = env_m["ì›”"].astype(str).str[5:7].astype(int)

        past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
        past_df = json_to_dataframe(past_payload)
        env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m

        filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

        st.subheader("ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ì›”ë³„ ë°ì´í„°(ì˜¬í•´, ë¯¸ë˜ì›”ì€ ê³¼ê±° í‰ê· ìœ¼ë¡œ ëŒ€ì²´)")
        st.dataframe(filled_this_year, use_container_width=True)

        try:
            env_for_wide = pd.concat([env_all[env_all["ì—°ë„"] != cur_year], filled_this_year], ignore_index=True)
            wide = build_wide_month_feats(env_for_wide)
        except Exception as e:
            st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            st.stop()

        if cur_year not in set(wide["ì—°ë„"].astype(int).tolist()):
            st.error("ì˜ˆì¸¡ ì—°ë„ í–‰ì„ êµ¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        row = wide[wide["ì—°ë„"] == cur_year].iloc[0]

        EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
        preds = {}
        for tgt, formula in EQUATIONS.items():
            try:
                preds[tgt] = apply_equation_row(row, formula)
            except Exception as e:
                preds[tgt] = f"ì—ëŸ¬: {e}"

        st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}  ì—°ë„: {cur_year}")
        pred_df = pd.DataFrame([preds]).T.reset_index()
        pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]
        st.dataframe(pred_df.set_index("í•­ëª©").T.reset_index(drop=True), use_container_width=True)

        # ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë¹„êµ
        with st.spinner("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            qdict = fetch_quality_tables(cur_year, cur_year-1, cultivar)

        last_row = None
        if qdict and "last" in qdict and qdict["last"] is not None and not qdict["last"].empty:
            q_last = normalize_quality_columns(qdict["last"])
            with st.expander("ì „ë…„ë„ í…Œì´ë¸” ì‹¤ì œ ì»¬ëŸ¼ëª…(ì •ê·œí™” í›„)"):
                st.write(list(q_last.columns))
            last_row = pick_region_row(q_last, region_disp)

        if last_row is not None:
            patterns = {
                "ê³¼ì¤‘": r"^ê³¼ì¤‘",
                "ì¢…ê²½": r"^ì¢…ê²½",
                "íš¡ê²½": r"^íš¡ê²½",
                "ê²½ë„": r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)",
                "ë‹¹ë„": r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?",
                "ì‚°ë„": r"^ì‚°ë„(\s*\(%\))?",
                "L":   r"ì°©ìƒ‰.*Hunter\s*L\b",
                "a":   r"ì°©ìƒ‰.*Hunter\s*a\b",
                "b":   r"ì°©ìƒ‰.*Hunter\s*b\b",
            }
            def to_float(x):
                try:
                    return float(str(x).replace(",", "").strip())
                except Exception:
                    return None
            rows = []
            last_df_for_match = last_row.to_frame().T
            for k, pat in patterns.items():
                col = get_first_col_by_pattern(last_df_for_match, pat)
                last_val = to_float(last_row[col]) if col else None
                pred_val = preds.get(k, None)
                rows.append([k, pred_val, last_val])

            compare_df = pd.DataFrame(rows, columns=["í•­ëª©","ì˜ˆì¸¡ê°’(ì˜¬í•´)","ì „ë…„ë„ ì‹¤ì œê°’"])
            st.subheader(f"ì˜¬í•´ ì˜ˆì¸¡ vs ì „ë…„ë„ ì‹¤ì œ  ë¹„êµ  ì§€ì—­: {region_disp}  í’ˆì¢…: {cultivar}")
            compare_df_t = compare_df.set_index("í•­ëª©").T
            compare_df_t.index.name = ""
            st.dataframe(compare_df_t, use_container_width=True)

            # ì‘ì€ ì‹œê°í™”ë“¤
            PRED_COLOR = "#87CEEB"
            LAST_COLOR = "#800080"
            def _pick(df, item):
                r = df[df["í•­ëª©"] == item]
                if r.empty: return np.nan, np.nan
                p = pd.to_numeric(r["ì˜ˆì¸¡ê°’(ì˜¬í•´)"].values[0], errors="coerce")
                l = pd.to_numeric(r["ì „ë…„ë„ ì‹¤ì œê°’"].values[0], errors="coerce")
                return p, l

            size_items = ["ê³¼ì¤‘", "íš¡ê²½", "ì¢…ê²½"]
            x = np.arange(len(size_items))
            y_pred, y_last = [], []
            for it in size_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                w = 0.35
                if not all(pd.isna(y_pred)):
                    ax.bar(x - w/2, np.nan_to_num(y_pred, nan=0.0), width=w, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.bar(x + w/2, np.nan_to_num(y_last, nan=0.0), width=w, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(size_items)
                ax.set_title("ê³¼ì‹¤ í¬ê¸°")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)

            def _bar_single(item, title, ylim_top=None):
                p, l = _pick(compare_df, item)
                if pd.isna(p) and pd.isna(l): 
                    return
                xs, ys, cs = [], [], []
                if not pd.isna(p): xs.append("ì˜ˆì¸¡(ì˜¬í•´)"); ys.append(float(p)); cs.append(PRED_COLOR)
                if not pd.isna(l): xs.append("ì „ë…„ë„");     ys.append(float(l)); cs.append(LAST_COLOR)
                fig, ax = plt.subplots(figsize=(2.5, 1.8))
                ax.bar(np.arange(len(xs)), ys, tick_label=xs, color=cs, width=0.35)
                ax.set_title(title); ax.grid(axis="y", linestyle=":", alpha=0.35)
                if ylim_top: ax.set_ylim(top=ylim_top)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                fig.tight_layout(); st.pyplot(fig, use_container_width=False)

            c1, c2, c3 = st.columns(3)
            with c1: _bar_single("ê²½ë„", "ê²½ë„", ylim_top=70)
            with c2: _bar_single("ë‹¹ë„", "ë‹¹ë„")
            with c3: _bar_single("ì‚°ë„", "ì‚°ë„")

            tone_items = ["L", "a", "b"]
            x = np.arange(len(tone_items))
            y_pred, y_last = [], []
            for it in tone_items:
                p, l = _pick(compare_df, it)
                y_pred.append(np.nan if pd.isna(p) else float(p))
                y_last.append(np.nan if pd.isna(l) else float(l))
            if not (all(pd.isna(y_pred)) and all(pd.isna(y_last))):
                fig, ax = plt.subplots(figsize=(3.5, 2.6))
                if not all(pd.isna(y_pred)):
                    ax.plot(x, y_pred, marker="o", linewidth=2, label="ì˜ˆì¸¡(ì˜¬í•´)", color=PRED_COLOR)
                if not all(pd.isna(y_last)):
                    ax.plot(x, y_last, marker="o", linewidth=2, label="ì „ë…„ë„", color=LAST_COLOR)
                ax.set_xticks(x); ax.set_xticklabels(tone_items)
                ax.set_title("ì°©ìƒ‰ë„")
                ax.grid(axis="y", linestyle=":", alpha=0.35)
                ax.spines["top"].set_visible(False); ax.spines["right"].set_visible(False)
                ax.spines["left"].set_linewidth(0.7); ax.spines["bottom"].set_linewidth(0.7)
                ax.legend(); fig.tight_layout()
                st.pyplot(fig, use_container_width=False)
        else:
            st.warning("ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆì—ì„œ êµ°ìœ„ í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”.")

        # ë‹¤ìš´ë¡œë“œë“¤
        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì‹¤ì¸¡ ì›”ë³„ CSV",
                df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_measured.csv",
                mime="text/csv",
                disabled=df.empty
            )
        with c2:
            st.download_button(
                "â¬‡ï¸ ì˜¬í•´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì›”ë³„ CSV",
                filled_this_year.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_monthly_used.csv",
                mime="text/csv"
            )
        with c3:
            st.download_button(
                "â¬‡ï¸ íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ CSV",
                pred_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{region_disp}_{cultivar}_{cur_year}_predictions.csv",
                mime="text/csv"
            )
    else:
        st.info("í’ˆì¢…ì„ ì„ íƒí•˜ê³  â€˜êµ°ìœ„ ìë™ì¡°íšŒ & ì˜ˆì¸¡â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹¤í–‰í•˜ì„¸ìš”.")
