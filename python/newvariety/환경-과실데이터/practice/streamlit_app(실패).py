# -*- coding: utf-8 -*-
# íŒŒì¼: streamlit_app.py
import os, re, json
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime

import numpy as np
import pandas as pd
import requests
import streamlit as st
import matplotlib.pyplot as plt
import statsmodels.api as sm

# =========================
# ê¸°ë³¸ ì„¸íŒ…
# =========================
st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡ (API ìë™ ì¬í•™ìŠµ)", layout="wide")

EQUATIONS_PATH = Path("equations.json")  # ì¬í•™ìŠµí•œ íšŒê·€ì‹ ì˜êµ¬ ì €ì¥ ìœ„ì¹˜

AREA_CODE = {
    "ê²½ê¸°í™”ì„±": "324", "ê²½ë¶ì˜ì£¼": "331", "ê²½ë¶ì²­ì†¡": "332", "ëŒ€êµ¬êµ°ìœ„": "333",
    "ê²½ë‚¨ê±°ì°½": "334", "ì „ë¶ì¥ìˆ˜": "335", "ê²½ê¸°í¬ì²œ": "337", "ì¶©ë¶ì¶©ì£¼": "338",
}
REGION_NAME_MAP = {
    "ê²½ê¸°í™”ì„±": "í™”ì„±", "ê²½ë¶ì˜ì£¼": "ì˜ì£¼", "ê²½ë¶ì²­ì†¡": "ì²­ì†¡", "ëŒ€êµ¬êµ°ìœ„": "êµ°ìœ„",
    "ê²½ë‚¨ê±°ì°½": "ê±°ì°½", "ì „ë¶ì¥ìˆ˜": "ì¥ìˆ˜", "ê²½ê¸°í¬ì²œ": "í¬ì²œ", "ì¶©ë¶ì¶©ì£¼": "ì¶©ì£¼",
}

# ìµœì´ˆ ê¸°ë™ì‹œ ê¸°ë³¸ì‹(ì—†ìœ¼ë©´ ì˜ˆì¸¡ì€ ì¬í•™ìŠµ í›„ ê°€ëŠ¥)
DEFAULT_EQUATIONS = {
    "í™ë¡œ": {},  # ì´ˆê¸°ì—ëŠ” ë¹„ì›Œë‘ê³  ë²„íŠ¼ìœ¼ë¡œ í•™ìŠµ ê¶Œì¥(ì›í•˜ì‹œë©´ ì—¬ê¸° ê¸°ë³¸ì‹ ë„£ìœ¼ì…”ë„ ë©ë‹ˆë‹¤)
    "í›„ì§€": {},
}

# =========================
# í•œê¸€ í°íŠ¸(ê°€ëŠ¥í•  ë•Œë§Œ)
# =========================
import matplotlib
import matplotlib.font_manager as fm

def _set_korean_font():
    preferred = ["Malgun Gothic", "AppleGothic", "NanumGothic",
                 "Noto Sans CJK KR", "Noto Sans KR", "NanumBarunGothic"]
    sys_fonts = set(f.name for f in fm.fontManager.ttflist)
    for name in preferred:
        if name in sys_fonts:
            matplotlib.rcParams["font.family"] = name
            matplotlib.rcParams["axes.unicode_minus"] = False
            return
    matplotlib.rcParams["axes.unicode_minus"] = False

_set_korean_font()
plt.rcParams["font.size"] = 6

def fetch_aws_stat_fallback_html(region_name: str, s_ym: str, e_ym: str) -> pd.DataFrame:
    """
    JSON ì‘ë‹µì´ ì‹¤íŒ¨í•  ë•Œ: ì›”ë³„ í†µê³„ë¥¼ HTMLì—ì„œ ì§ì ‘ íŒŒì‹±í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜.
    - statmethod=D(ì›”ë³„)
    - í•„ìš”í•œ ì»¬ëŸ¼: ì›”, í‰ê· ê¸°ì˜¨/ìµœê³ ê¸°ì˜¨/ìµœì €ê¸°ì˜¨/ìŠµë„/ê°•ìš°ëŸ‰/ì¼ì‚¬ëŸ‰/ê²°ë¡œì‹œê°„/í‰ê· í’ì†/ìµœëŒ€í’ì†
    """
    import io as _io
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do",
    }
    sess = requests.Session()
    # ì²« í˜ì´ì§€ë¡œ ì¿ í‚¤/ì„¸ì…˜ ì·¨ë“
    sess.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", headers=headers, timeout=20)

    params = {
        "pageIndex": "1",
        "searchNum": "0",
        "areaName": region_name,
        "areaCode": AREA_CODE.get(region_name, region_name),
        "statmethod": "D",
        "wetherDtBgn2": s_ym,
        "wetherDtEnd2": e_ym,
        "wetherDtBgn": s_ym,
        "wetherDtEnd": e_ym,
    }
    # ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€(HTML) ìš”ì²­
    r = sess.post("https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
                  data=params, headers=headers, timeout=30)
    r.raise_for_status()

    # í˜ì´ì§€ ë‚´ í…Œì´ë¸”ì„ ì „ë¶€ ì½ê³ , ì›”/ì§€í‘œ ì»¬ëŸ¼ì„ í¬í•¨í•œ í‘œë¥¼ ì„ íƒ
    tables = pd.read_html(_io.StringIO(r.text))
    wanted_cols = {"ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"}
    cand = None
    for t in tables:
        cols = set(map(str, t.columns))
        if "ì›”" in cols and len(wanted_cols & cols) >= 5:
            cand = t.copy()
            break
    if cand is None:
        # ë””ë²„ê·¸: ì¼ë¶€ í˜ì´ì§€ëŠ” ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ ìƒì„¸ ê·¸ë¦¬ë“œë¡œ ë°˜í™˜ë  ìˆ˜ ìˆì–´ ì›ë¬¸ ì¼ë¶€ ì¶œë ¥
        st.error("[í™˜ê²½/HTML] ì›”ë³„ í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ë‹µ ì¼ë¶€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(r.text[:800])
        return pd.DataFrame()

    # ì»¬ëŸ¼ ì •ë¦¬ & ìˆ«ìí™”
    cand = cand.rename(columns=lambda x: str(x).strip())
    cand["ì—°ë„"] = pd.to_numeric(cand["ì›”"].astype(str).str[:4], errors="coerce")
    cand["ì›”"]   = pd.to_numeric(cand["ì›”"].astype(str).str[-2:], errors="coerce")
    numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    for c in numcands:
        if c in cand.columns:
            cand[c] = pd.to_numeric(cand[c], errors="coerce")
    cand = cand.dropna(subset=["ì—°ë„","ì›”"])
    cand = cand.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
    return cand


# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def _clean_str(s: str) -> str:
    s = str(s)
    s = s.replace("\xa0", " ").replace("\n", " ").replace("\r", " ")
    s = re.sub(r"\s+", " ", s).strip()
    s = re.sub(r"\s*\(\s*", " (", s)
    s = re.sub(r"\s*\)\s*", ")", s)
    return s

def normalize_quality_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    if isinstance(out.columns, pd.MultiIndex):
        out.columns = [" ".join([str(x) for x in tup if str(x) != "nan"]).strip()
                       for tup in out.columns.values]
    out.columns = [_clean_str(c) for c in out.columns]
    alias = {
        "ê²½ë„ í‰ê· (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
        "ê²½ë„ í‰ê·  (N/Ã¸11mm)": "ê²½ë„í‰ê· (N/Ã¸11mm)",
        "ì°©ìƒ‰ (Hunter L)": "ì°©ìƒ‰(Hunter L)",
        "ì°©ìƒ‰ (Hunter a)": "ì°©ìƒ‰(Hunter a)",
        "ì°©ìƒ‰ (Hunter b)": "ì°©ìƒ‰(Hunter b)",
    }
    out = out.rename(columns={k: v for k, v in alias.items() if k in out.columns})
    if "ì§€ì—­" in out.columns:
        out["ì§€ì—­"] = out["ì§€ì—­"].map(_clean_str)
    if "ìˆ˜í™•ì¼ì" in out.columns:
        out["ìˆ˜í™•ì¼ì"] = pd.to_datetime(out["ìˆ˜í™•ì¼ì"], errors="coerce")
    return out

def get_first_col_by_pattern(df: pd.DataFrame, pattern: str) -> Optional[str]:
    pat = re.compile(pattern, flags=re.IGNORECASE)
    for c in df.columns:
        if pat.search(str(c)):
            return c
    return None

def cultivar_window(cultivar: str):
    return (4, 8) if cultivar == "í™ë¡œ" else (4, 10)

def get_today_ym():
    now = datetime.now()
    return now.year, now.month

def _ensure_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# =========================
# API: í™˜ê²½ë°ì´í„°(AWS)
# =========================
@st.cache_data(show_spinner=False, ttl=300)
@st.cache_data(show_spinner=False, ttl=300)
def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
    """
    ê³¼ìˆ˜ìƒìœ¡í’ˆì§ˆê´€ë¦¬ì‹œìŠ¤í…œ AWS ì›”ë³„ í†µê³„(JSON/AJAX) í˜¸ì¶œ.
    - í—¤ë” ê°•í™”(ajax/ua/referer), ì„¸ì…˜ ì¿ í‚¤ ì„ ì·¨ë“
    - JSON/JSONP/HTML ì‘ë‹µ ëª¨ë‘ ëŒ€ë¹„
    - ì‹¤íŒ¨ ì‹œ ì§„ë‹¨ ë¡œê·¸ ë°˜í™˜
    """
    import time, json, re
    BASE = "https://fruit.nihhs.go.kr/apple/aws"
    list_url = f"{BASE}/awsStatList.do"
    referer  = f"{BASE}/awsStat.do"

    # 0) íŒŒë¼ë¯¸í„° sanity
    s_ym = str(s_ym)
    e_ym = str(e_ym)
    if not re.match(r"^\d{4}-\d{2}$", s_ym) or not re.match(r"^\d{4}-\d{2}$", e_ym):
        return {"error": f"ì˜ëª»ëœ ë‚ ì§œí˜•ì‹: s_ym={s_ym}, e_ym={e_ym}"}

    # 1) ì„¸ì…˜ê³¼ í—¤ë” ì¤€ë¹„
    session = requests.Session()
    base_headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": "https://fruit.nihhs.go.kr",
        "Referer": referer,
        "X-Requested-With": "XMLHttpRequest",
        "Connection": "keep-alive",
    }

    try:
        # 2) ì¿ í‚¤ ì„ ì·¨ë“
        session.get(referer, headers=base_headers, timeout=20)
    except Exception as e:
        return {"error": f"ì‚¬ì „ ì ‘ì† ì‹¤íŒ¨: {e}"}

    # 3) í¼ ë°ì´í„° êµ¬ì„± (ì›”ë³„: D ê¸°ì¤€)
    form = {
        "pageIndex": "1",
        "searchNum": "0",
        "areaName": region_name,
        "areaCode": AREA_CODE.get(region_name, region_name),
        "statmethod": stat_gb_code,  # "D" = ì›”ë³„
    }
    if stat_gb_code == "A":
        form["wetherDtBgn"] = f"{s_ym}-01"
        form["wetherDtEnd"] = f"{e_ym}-30"
    elif stat_gb_code in ("B", "C"):
        form["wetherDtM"] = s_ym
    elif stat_gb_code == "D":
        # ì¼ë¶€ í™˜ê²½ì—ì„œ _Bgn/_End ë§Œ ìˆì–´ë„ ë™ì‘í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ ë‘˜ ë‹¤ ì „ë‹¬
        form["wetherDtBgn2"] = s_ym
        form["wetherDtEnd2"] = e_ym
        form["wetherDtBgn"] = s_ym
        form["wetherDtEnd"] = e_ym

    # 4) ë¦¬íŠ¸ë¼ì´ ë£¨í”„ (ìµœëŒ€ 3íšŒ)
    last_text = ""
    for attempt in range(3):
        try:
            resp = session.post(list_url, data=form, headers=base_headers, timeout=30)
            last_text = resp.text or ""
            ctype = resp.headers.get("Content-Type", "")

            # 4-1) JSON ë³¸ë¬¸
            if "application/json" in ctype or last_text.strip().startswith("{"):
                try:
                    return resp.json()
                except Exception:
                    # JSON í…ìŠ¤íŠ¸ê°€ ê¹¨ì§„ ê²½ìš°
                    try:
                        return json.loads(last_text)
                    except Exception:
                        pass

            # 4-2) JSONP ê°€ëŠ¥ì„±: callback(...) ë˜í•‘ ì œê±°
            m = re.match(r"^[^(]+\((\s*{.*}\s*)\)\s*;?\s*$", last_text, re.S)
            if m:
                try:
                    return json.loads(m.group(1))
                except Exception:
                    pass

            # 4-3) HTMLë¡œ ë–¨ì–´ì§„ ê²½ìš°: ë””ë²„ê·¸ ì •ë³´ ë°˜í™˜ (ìƒìœ„ì—ì„œ ë³´ì—¬ì¤Œ)
            # ë³´í†µì€ ì„¸ì…˜/í—¤ë” ë¬¸ì œì´ê±°ë‚˜ ì„œë²„ ì¼ì‹œ ì˜¤ë¥˜
            time.sleep(0.8)  # ì§§ê²Œ ëŒ€ê¸° í›„ ì¬ì‹œë„
        except Exception as e:
            last_text = f"[attempt {attempt+1}] ìš”ì²­ ì˜ˆì™¸: {e}"
            time.sleep(0.8)
            continue

    # 5) ìµœì¢… ì‹¤íŒ¨: ì•ë¶€ë¶„ë§Œ ëŒë ¤ ì§„ë‹¨
    snippet = re.sub(r"\s+", " ", last_text)[:800]
    return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": snippet, "debug": {"form": form}}


def json_to_dataframe(payload: dict) -> pd.DataFrame:
    if not payload or "result" not in payload:
        return pd.DataFrame()
    res = payload.get("result", [])
    if len(res) == 0:
        return pd.DataFrame()
    method = payload.get("mainAwsVO", {}).get("statmethod")
    raw = pd.DataFrame(res)

    rename_map = {
        "statsDt": "ì¼ì", "wetherDt": "ì¼ì",
        "dalyWetherAvrgTp": "í‰ê· ê¸°ì˜¨", "wetherAvgTp": "í‰ê· ê¸°ì˜¨",
        "dalyWetherMxmmTp": "ìµœê³ ê¸°ì˜¨", "wetherMaxTp": "ìµœê³ ê¸°ì˜¨",
        "dalyWetherMummTp": "ìµœì €ê¸°ì˜¨", "wetherMinTp": "ìµœì €ê¸°ì˜¨",
        "dalyWetherAvrgHd": "ìŠµë„",     "WetherAvgHd": "ìŠµë„",
        "dalyWetherTtalRainqy": "ê°•ìš°ëŸ‰", "wetherMaxRainqy": "ê°•ìš°ëŸ‰",
        "dalyWetherMxmmSolradqy": "ì¼ì‚¬ëŸ‰",
        "wetherMaxSolradqy": "ì¼ì‚¬ëŸ‰",
        "wetherSumSolradqy": "ì¼ì‚¬ëŸ‰",
        "dalyWetherMxmmCondenstime": "ê²°ë¡œì‹œê°„",
        "wetherMaxCondenstime": "ê²°ë¡œì‹œê°„",
        "wetherSumCondenstime": "ê²°ë¡œì‹œê°„",
        "dalyWetherAvrgWs": "í‰ê· í’ì†", "wetherAvgWs": "í‰ê· í’ì†",
        "dalyWetherMxmmWs": "ìµœëŒ€í’ì†", "wetherMaxWs": "ìµœëŒ€í’ì†",
        "wetherDtMonth": "ì›”", "wetherDt": "ì›”",
    }
    raw = raw.rename(columns=rename_map)

    if method == "D":
        want = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"] \
               if "ì›”" in raw.columns else \
               ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    else:
        want = ["ì¼ì","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]

    use_cols = [c for c in want if c in raw.columns]
    if not use_cols:
        return pd.DataFrame()
    df = raw[use_cols].copy()

    numcands = ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    df = _ensure_numeric(df, [c for c in numcands if c in df.columns])

    if "ì¼ì" in df.columns and df["ì¼ì"].dtype != "int64":
        df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
        if "ì—°ë„" not in df.columns:
            df["ì—°ë„"] = df["ì¼ì"].dt.year
        if "ì›”" not in df.columns:
            df["ì›”"] = df["ì¼ì"].dt.month
    elif "ì›”" in df.columns:
        df["ì—°ë„"] = pd.to_numeric(df["ì›”"].astype(str).str[:4], errors="coerce")
        df["ì›”"] = pd.to_numeric(df["ì›”"].astype(str).str[-2:], errors="coerce")

    if {"ì—°ë„","ì›”"}.issubset(df.columns):
        df = df.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
    return df

def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(df.columns):
        return df.copy()
    agg_map = {
        "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
        "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum","í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
    }
    use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
    out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
    return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
        raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ í•„ìš”")
    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
    mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
    sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()
    wide_mean = None
    for m in range(1, 12+1):
        sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
        wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")
    wide_sum = None
    for m in range(1, 12+1):
        sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
        wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")
    wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
    wide = wide.rename(columns={"ì—°ë„":"year"})
    return wide

def apply_equation_row(row: pd.Series, eq_str: str) -> float:
    rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
    cols = sorted(row.index.tolist(), key=len, reverse=True)
    expr = rhs
    for c in cols:
        expr = expr.replace(c, f"row[{repr(c)}]")
    return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

# =========================
# ê³¼ì‹¤ í’ˆì§ˆ(ë¼ë²¨) ìˆ˜ì§‘
# =========================
@st.cache_data(show_spinner=False, ttl=3600)
def fetch_quality_tables(selyear: int, lastyear: int, cultivar: str) -> dict:
    code = "apple01" if cultivar == "í›„ì§€" else "apple02"
    url = "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do"
    params = {
        "frtgrdCode": "apple",
        "selyear": str(selyear),
        "lastYear": str(lastyear),
        "searchGubun": code,
        "pageIndex": "1",
    }
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://fruit.nihhs.go.kr/apple/qlityInfo_frutQlity.do",
        "Accept": "text/html,application/xhtml+xml",
    }
    r = requests.get(url, params=params, headers=headers, timeout=30)
    r.raise_for_status()

    # ì§„ë‹¨: ì‘ë‹µ ê¸¸ì´/ì—°ë„ ì¶œë ¥
    st.info(f"[í’ˆì§ˆí‘œ GET] year={selyear}, last={lastyear}, cultivar={cultivar}, bytes={len(r.text)}")

    try:
        import io as _io
        tables = pd.read_html(_io.StringIO(r.text), flavor=["lxml","bs4","html5lib"])
    except Exception as e:
        st.warning(f"ì „ë…„ë„ ê³¼ì‹¤í’ˆì§ˆ í‘œ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return {}

    cleaned = []
    for t in tables:
        t2 = normalize_quality_columns(t)
        if set(["ì§€ì—­","ìˆ˜í™•ì¼ì"]).issubset(t2.columns):
            cleaned.append(t2)

    result = {}
    if len(cleaned) >= 1:
        result["this"] = cleaned[0]
    if len(cleaned) >= 2:
        result["last"] = cleaned[1]
    return result


def pick_region_row(qdf: pd.DataFrame, region_disp_name: str) -> Optional[pd.Series]:
    if qdf is None or qdf.empty or "ì§€ì—­" not in qdf.columns:
        return None
    tmp = qdf.copy()
    tmp["ì§€ì—­"] = tmp["ì§€ì—­"].map(_clean_str)
    if "ìˆ˜í™•ì¼ì" in tmp.columns:
        tmp["ìˆ˜í™•ì¼ì"] = pd.to_datetime(tmp["ìˆ˜í™•ì¼ì"], errors="coerce")
    sub = tmp[tmp["ì§€ì—­"] == _clean_str(region_disp_name)]
    if sub.empty: return None
    sub = sub.sort_values("ìˆ˜í™•ì¼ì", ascending=False, na_position="last")
    return sub.iloc[0]

def collect_fruit_labels_from_api(cultivar: str, region_disp: str, start_year: int = 2012, end_year: int = None) -> pd.DataFrame:
    if end_year is None:
        end_year = datetime.now().year - 1
    rows = []
    for y in range(start_year+1, end_year+1):
        try:
            qdict = fetch_quality_tables(y, y-1, cultivar)
            if not qdict or "last" not in qdict or qdict["last"] is None or qdict["last"].empty:
                st.info(f"[ë¼ë²¨] {y}: last í‘œ ì—†ìŒ")
                continue
            q_last = normalize_quality_columns(qdict["last"])
            r = pick_region_row(q_last, region_disp)
            if r is None:
                st.info(f"[ë¼ë²¨] {y}: ì§€ì—­ '{region_disp}' í–‰ ì—†ìŒ")
                continue
            def take(pat):
                c = get_first_col_by_pattern(r.to_frame().T, pat)
                return None if c is None else pd.to_numeric(r[c], errors="coerce")
            rows.append({
                "year": y,
                "ê³¼ì¤‘": take(r"^ê³¼ì¤‘"),
                "ì¢…ê²½": take(r"^ì¢…ê²½"),
                "íš¡ê²½": take(r"^íš¡ê²½"),
                "ê²½ë„": take(r"(ê²½ë„\s*í‰ê· |ê²½ë„í‰ê· |N\s*/?\s*Ã¸?\s*11\s*mm)"),
                "ë‹¹ë„": take(r"^ë‹¹ë„(\s*\((Â°|Ëš)?\s*Brix\))?"),
                "ì‚°ë„": take(r"^ì‚°ë„(\s*\(%\))?"),
                "L":    take(r"ì°©ìƒ‰.*Hunter\s*L\b"),
                "a":    take(r"ì°©ìƒ‰.*Hunter\s*a\b"),
                "b":    take(r"ì°©ìƒ‰.*Hunter\s*b\b"),
            })
        except Exception as e:
            st.info(f"[ë¼ë²¨] {y}: ì˜ˆì™¸ {e}")
            continue

    df = pd.DataFrame(rows)
    if df.empty:
        st.warning("[ë¼ë²¨] ìˆ˜ì§‘ ê²°ê³¼ 0í–‰. ì—°ë„/ì§€ì—­/í’ˆì¢…ì„ ë°”ê¾¸ê±°ë‚˜ ì‹œì‘ ì—°ë„ë¥¼ ë” ê³¼ê±°ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
        return df
    targ = [c for c in ["ê³¼ì¤‘","ì¢…ê²½","íš¡ê²½","ê²½ë„","ë‹¹ë„","ì‚°ë„","L","a","b"] if c in df.columns]
    df = df.dropna(how="all", subset=targ)
    st.success(f"[ë¼ë²¨] ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}í–‰ (ì˜ˆ: ìƒë‹¨ 3í–‰)")
    st.dataframe(df.head(3))
    return df


def collect_env_features_from_api(region: str, start_year: int = 2012, end_year: int = None) -> pd.DataFrame:
    if end_year is None:
        end_year = datetime.now().year
    payload = fetch_aws_stat(region, "D", f"{start_year:04d}-01", f"{end_year:04d}-12")

    # 1) JSON ê²½ë¡œ
    if "error" not in payload:
        df = json_to_dataframe(payload)
    else:
        # 2) HTML ìš°íšŒ ê²½ë¡œ
        st.warning(f"[í™˜ê²½] JSON ì‹¤íŒ¨ â†’ HTML íŒŒì‹± ìš°íšŒ ì‹œë„: {payload.get('error')}")
        raw = payload.get("raw", "")
        if raw:
            st.caption("ì„œë²„ ì‘ë‹µ ìŠ¤ë‹ˆí«(ì°¸ê³ ìš©)")
            st.code(raw)
        df = fetch_aws_stat_fallback_html(region, f"{start_year:04d}-01", f"{end_year:04d}-12")

    if df.empty:
        st.error("[í™˜ê²½] ì›”ë³„ ì›ë³¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # ì›”ë³„ ì§‘ê³„ í›„ wide ë³€í™˜
    env_m = agg_to_monthly(df) if {"ì—°ë„","ì›”"}.issubset(df.columns) else df
    if env_m.empty:
        st.error("[í™˜ê²½] ì›”ë³„ ì§‘ê³„ ê²°ê³¼ 0í–‰")
        return pd.DataFrame()

    wide = build_wide_month_feats(env_m)
    if wide.empty:
        st.error("[í™˜ê²½] wide í”¼ì²˜ 0í–‰")
        return pd.DataFrame()

    st.success(f"[í™˜ê²½] wide í”¼ì²˜ ìˆ˜ì§‘ ì™„ë£Œ: {len(wide)}í–‰, ì»¬ëŸ¼ {len(wide.columns)}ê°œ (ì˜ˆ: ìƒë‹¨ 3í–‰)")
    st.dataframe(wide.head(3))
    return wide



# =========================
# ê°„ë‹¨ ìë™ ì¬í•™ìŠµ(ìƒê´€ Top-20 + OLS)
# =========================
def fit_auto_equations_from_api(cultivar: str, region: str, start_year: int = 2012):
    region_disp = REGION_NAME_MAP.get(region, region)

    st.info(f"[í•™ìŠµ] ìˆ˜ì§‘ ì‹œì‘: í’ˆì¢…={cultivar}, ì§€ì—­={region}({region_disp}), ì‹œì‘ì—°ë„={start_year}")
    labels = collect_fruit_labels_from_api(cultivar, region_disp, start_year=start_year)
    env_wide = collect_env_features_from_api(region, start_year=start_year)

    if labels.empty and env_wide.empty:
        raise RuntimeError("ë¼ë²¨ê³¼ í™˜ê²½ í”¼ì²˜ ëª¨ë‘ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if labels.empty:
        raise RuntimeError("ë¼ë²¨(ì „ë…„ë„ ê³¼ì‹¤í‘œ)ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if env_wide.empty:
        raise RuntimeError("í™˜ê²½ wide í”¼ì²˜ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    data = pd.merge(labels, env_wide, on="year", how="inner").dropna()
    st.info(f"[í•™ìŠµ] ë³‘í•© í›„ ë°ì´í„°: {len(data)}í–‰, ì»¬ëŸ¼ {len(data.columns)}ê°œ")
    st.dataframe(data.head(3))

    if len(data) < 8:
        raise RuntimeError("í•™ìŠµ í‘œë³¸ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤(8í–‰ ë¯¸ë§Œ). ì‹œì‘ ì—°ë„ë¥¼ ë” ê³¼ê±°ë¡œ ì„¤ì •í•´ ë³´ì„¸ìš”.")

    # ì„¤ëª…ë³€ìˆ˜ í’€
    num_cols = [c for c in data.columns if c != "year"]
    env_cols = [c for c in num_cols if re.search("ê¸°ì˜¨|ìŠµë„|ê°•ìš°|ì¼ì‚¬|ê²°ë¡œ|í’ì†", c)]

    targets = [c for c in ["ê³¼ì¤‘","ì¢…ê²½","íš¡ê²½","ê²½ë„","ë‹¹ë„","ì‚°ë„","L","a","b"] if c in data.columns]
    if not targets:
        raise RuntimeError("íƒ€ê¹ƒ ì»¬ëŸ¼(ê³¼ì¤‘/ê²½ë„/ë‹¹ë„ ë“±)ì´ í•œ ê°œë„ ì—†ìŠµë‹ˆë‹¤.")

    new_eq = {}
    info_rows = []

    for tgt in targets:
        corr = data[env_cols + [tgt]].corr(numeric_only=True)[tgt].dropna().abs().sort_values(ascending=False)
        if corr.empty:
            st.warning(f"[í•™ìŠµ] {tgt}: ìœ íš¨í•œ ìƒê´€ ì—†ìŒ â†’ ìŠ¤í‚µ")
            continue
        feats = corr.head(20).index.tolist()
        X = data[feats].astype(float)
        y = data[tgt].astype(float)
        Xc = sm.add_constant(X)
        model = sm.OLS(y, Xc).fit()

        parts = [f"{model.params['const']:.6g}"] + [f"{model.params[f]:+.6g}Â·{f}" for f in feats]
        eq = f"{tgt} = " + " ".join(parts)
        new_eq[tgt] = eq
        info_rows.append([tgt, len(feats), round(model.rsquared, 3), len(data)])

    if not new_eq:
        raise RuntimeError("ëª¨ë“  íƒ€ê¹ƒì—ì„œ ì‹ ìƒì„± ì‹¤íŒ¨(ìƒê´€/í‘œë³¸ ë¶€ì¡±).")

    info_df = pd.DataFrame(info_rows, columns=["target","n_feats","R2_in_sample","n_samples"])
    return new_eq, info_df, data


# =========================
# íšŒê·€ì‹ ì €ì¥/ë¡œë“œ
# =========================
def load_equations() -> Dict[str, Dict[str, str]]:
    if EQUATIONS_PATH.exists():
        with open(EQUATIONS_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return DEFAULT_EQUATIONS.copy()

def save_equations(eqs: Dict[str, Dict[str, str]]):
    with open(EQUATIONS_PATH, "w", encoding="utf-8") as f:
        json.dump(eqs, f, ensure_ascii=False, indent=2)

# =========================
# UI
# =========================
st.markdown("<h1 style='text-align:center;'>ğŸ ì‚¬ê³¼ ê³¼ì‹¤ í’ˆì§ˆ ì˜ˆì¸¡ (API ìë™ ì¬í•™ìŠµ)</h1>", unsafe_allow_html=True)

colA, colB, colC = st.columns([1,1,1])
with colA:
    cultivar = st.radio("í’ˆì¢…", ["í™ë¡œ","í›„ì§€"], horizontal=True)
with colB:
    region = st.selectbox("ì§€ì—­", list(AREA_CODE.keys()), index=1)
with colC:
    start_year = st.number_input("í•™ìŠµ ì‹œì‘ ì—°ë„(ë¼ë²¨/í™˜ê²½ ìˆ˜ì§‘ ì‹œì‘ ì—°ë„)", min_value=2005, max_value=datetime.now().year-2, value=2012, step=1)

eq_store = load_equations()

# ---- ì¬í•™ìŠµ ë²„íŠ¼
st.markdown("### ğŸ” ìë™ ì¬í•™ìŠµ(ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ â†’ íšŒê·€ ì í•© â†’ ì‹ ì €ì¥)")
if st.button("APIë§Œìœ¼ë¡œ ìë™ ì¬í•™ìŠµ ì‹¤í–‰"):
    with st.spinner("ê³¼ê±° ë¼ë²¨/í™˜ê²½ ë°ì´í„°ë¥¼ APIë¡œ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            new_eq, info_df, train_df = fit_auto_equations_from_api(cultivar, region, start_year=int(start_year))
            st.success("ì¬í•™ìŠµ ì™„ë£Œ! ì•„ë˜ ì •ë³´ì™€ ìƒˆ íšŒê·€ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
            st.dataframe(info_df, use_container_width=True)

            # ì €ì¥ì†Œì— ë°˜ì˜
            if cultivar not in eq_store:
                eq_store[cultivar] = {}
            eq_store[cultivar].update(new_eq)
            save_equations(eq_store)

            st.subheader("ê°±ì‹ ëœ íšŒê·€ì‹")
            st.json(new_eq)

        except Exception as e:
            st.error(f"ì¬í•™ìŠµ ì‹¤íŒ¨: {e}")

st.markdown("---")
# ---- ì˜ˆì¸¡ ë²„íŠ¼
st.markdown("### ğŸ” ì˜¬í•´ ì˜ˆì¸¡ ì‹¤í–‰(ì‹¤ì¸¡+ì˜ˆìƒ ì›”ë³„ í™˜ê²½ ì‚¬ìš©)")
run = st.button("ìë™ì¡°íšŒ & ì˜ˆì¸¡")

if run:
    cur_year, cur_month = get_today_ym()
    s_mon, e_mon = cultivar_window(cultivar)
    s_ym = f"{cur_year:04d}-{s_mon:02d}"
    e_ym_real = f"{cur_year:04d}-{min(e_mon, cur_month):02d}"

    with st.spinner("ì˜¬í•´ ì›”ë³„ í™˜ê²½ ì‹¤ì¸¡ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        payload = fetch_aws_stat(region, "D", s_ym, e_ym_real)
    if "error" in payload:
        st.error("API ì‘ë‹µ(JSON) íŒŒì‹± ì‹¤íŒ¨")
        st.code(payload.get("raw","")[:800])
        st.stop()
    df_cur = json_to_dataframe(payload)

    st.subheader("ì˜¬í•´ ì›”ë³„ ì‹¤ì¸¡(í™˜ê²½)")
    if df_cur.empty:
        st.warning("ì˜¬í•´ ì‹¤ì¸¡ ë°ì´í„°ê°€ ì—†ì–´ ê³¼ê±° í‰ê· ìœ¼ë¡œë§Œ ì±„ì›ë‹ˆë‹¤.")
    else:
        st.dataframe(df_cur, use_container_width=True)

    # ê³¼ê±°(ê¸°í›„í‰ë…„) í™•ë³´
    past_payload = fetch_aws_stat(region, "D", f"{max(cur_year-15,2010):04d}-01", f"{cur_year-1:04d}-12")
    past_df = json_to_dataframe(past_payload)
    # ê³¼ì‹¤ë°ì´í„° í•™ìŠµ ì‹œì‘ ì—°ë„ 2019ë…„ìœ¼ë¡œ ê³ ì •
    start_year = 2019
    past_payload = fetch_aws_stat(region, "D", f"{start_year:04d}-01", f"{cur_year-1:04d}-12")
    past_df = json_to_dataframe(past_payload)
    # 2019ë…„ë¶€í„° í˜„ì¬ê¹Œì§€ ë°ì´í„°ë§Œ ì‚¬ìš©
    if not past_df.empty:
        past_df = past_df[past_df["ì—°ë„"] >= start_year]
    env_all = pd.concat([env_m, past_df], ignore_index=True) if not past_df.empty else env_m
    env_all = env_all[env_all["ì—°ë„"] >= start_year]

    filled_this_year = fill_missing_or_future_with_climatology(env_all, cur_year, cultivar, mode=mode)

    # íšŒê·€ì‹ ë¡œë“œ
    eq_by_cultivar = load_equations()
    equations = eq_by_cultivar.get(cultivar, {})

    if not equations:
        st.warning("í˜„ì¬ ì €ì¥ëœ íšŒê·€ì‹ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € [ìë™ ì¬í•™ìŠµ]ì„ ì‹¤í–‰í•´ ì‹ì„ ìƒì„±/ì €ì¥í•˜ì„¸ìš”.")
        st.stop()

    preds = {}
    for tgt, formula in equations.items():
        try:
            preds[tgt] = apply_equation_row(row, formula)
        except Exception as e:
            preds[tgt] = f"ì—ëŸ¬: {e}"

    st.subheader(f"ì˜ˆì¸¡ ê²°ê³¼  |  í’ˆì¢…: {cultivar}  |  ì§€ì—­: {region}  |  ì—°ë„: {cur_year}")
    pred_df = pd.DataFrame([preds]).T.reset_index()
    pred_df.columns = ["í•­ëª©", "ì˜ˆì¸¡ê°’(ì˜¬í•´)"]
    st.dataframe(pred_df.set_index("í•­ëª©").T, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œ
    c1, c2 = st.columns(2)
    with c1:
        st.download_button("â¬‡ï¸ ì˜¬í•´ í™˜ê²½ wide(íŠ¹ì§•) CSV",
            env_wide.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{cultivar}_{cur_year}_env_wide.csv",
            mime="text/csv")
    with c2:
        st.download_button("â¬‡ï¸ ì˜ˆì¸¡ ê²°ê³¼ CSV",
            pred_df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{cultivar}_{cur_year}_preds.csv",
            mime="text/csv")
else:
    st.info("â‘  í’ˆì¢…/ì§€ì—­/í•™ìŠµì‹œì‘ì—°ë„ ì„ íƒ â†’ â‘¡ [APIë§Œìœ¼ë¡œ ìë™ ì¬í•™ìŠµ ì‹¤í–‰] â†’ â‘¢ [ìë™ì¡°íšŒ & ì˜ˆì¸¡] ìˆœì„œë¡œ ì´ìš©í•˜ì„¸ìš”.")
