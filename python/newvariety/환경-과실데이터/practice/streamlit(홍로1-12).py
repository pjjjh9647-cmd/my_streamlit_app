# -*- coding: utf-8 -*-
# íŒŒì¼ëª…: ê¸°ìƒìë™ë¶ˆëŸ¬ì˜¤ê¸°3.py
import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime

# -------------------------------------------------
# ê¸°ë³¸ UI
# -------------------------------------------------
st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ + íšŒê·€ì‹ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ ìˆ˜ì§‘ + íšŒê·€ì‹ ì˜ˆì¸¡ê¸°")

# -------------------------------------------------
# ì§€ì—­ ì½”ë“œ (ì‚¬ì´íŠ¸ì˜ select valueì™€ ë™ì¼)
# -------------------------------------------------
AREA_CODE = {
    "ê²½ê¸°í™”ì„±": "324",
    "ê²½ë¶ì˜ì£¼": "331",
    "ê²½ë¶ì²­ì†¡": "332",
    "ëŒ€êµ¬êµ°ìœ„": "333",
    "ê²½ë‚¨ê±°ì°½": "334",
    "ì „ë¶ì¥ìˆ˜": "335",
    "ê²½ê¸°í¬ì²œ": "337",
    "ì¶©ë¶ì¶©ì£¼": "338",
}

# -------------------------------------------------
# íšŒê·€ì‹ í•˜ë“œì½”ë”© (ì¤‘ê°„ì  'Â·' ëŒ€ì‹  ê³±ì…ˆ '*')
# -------------------------------------------------
EQUATIONS = {
    "ê³¼ì¤‘": "ê³¼ì¤‘ = 780.25 -0.493092*ì¼ì‚¬ëŸ‰_sum_m06 -0.0654782*ì¼ì‚¬ëŸ‰_sum_m12 -11.2556*ìµœê³ ê¸°ì˜¨_mean_m11 +41.8356*í‰ê· í’ì†_mean_m09 -0.397973*ì¼ì‚¬ëŸ‰_sum_m04 +0.0920122*ì¼ì‚¬ëŸ‰_sum_m10 +0.170844*ì¼ì‚¬ëŸ‰_sum_m08 -3.18769*í‰ê· ê¸°ì˜¨_mean_m01 -9.02924*ìµœê³ ê¸°ì˜¨_mean_m02 -28.8609*í‰ê· í’ì†_mean_m06 +8.12358*ìµœì €ê¸°ì˜¨_mean_m06 -28.7406*í‰ê· í’ì†_mean_m01",
    "ì¢…ê²½": "ì¢…ê²½ = 141.837 -0.0273306*ì¼ì‚¬ëŸ‰_sum_m03 +0.00264557*ì¼ì‚¬ëŸ‰_sum_m12 -0.0644849*ì¼ì‚¬ëŸ‰_sum_m04 +0.0675809*ìµœê³ ê¸°ì˜¨_mean_m01 -0.0470187*ì¼ì‚¬ëŸ‰_sum_m06 -0.101279*ìµœì €ê¸°ì˜¨_mean_m11 -0.0221346*ì¼ì‚¬ëŸ‰_sum_m02 -3.97461*í‰ê· í’ì†_mean_m01 +7.36367*í‰ê· í’ì†_mean_m09 +1.67381*í‰ê· í’ì†_mean_m12 -0.814958*ìµœì €ê¸°ì˜¨_mean_m10 +1.07135*ìµœì €ê¸°ì˜¨_mean_m07 +0.36404*ìµœì €ê¸°ì˜¨_mean_m03",
    "íš¡ê²½": "íš¡ê²½ = 131.821 -0.0276458*ì¼ì‚¬ëŸ‰_sum_m12 -0.0413528*ì¼ì‚¬ëŸ‰_sum_m06 -0.04801*ì¼ì‚¬ëŸ‰_sum_m04 -0.384756*í‰ê· ê¸°ì˜¨_mean_m01 +0.0205801*ì¼ì‚¬ëŸ‰_sum_m10 +0.0040987*ì¼ì‚¬ëŸ‰_sum_m08 +0.0159965*ê²°ë¡œì‹œê°„_mean_m12 +1.972*í‰ê· í’ì†_mean_m09 -1.91269*í‰ê· í’ì†_mean_m11 -0.336407*ìµœê³ ê¸°ì˜¨_mean_m12 +0.00843139*ê°•ìš°ëŸ‰_sum_m01",
    "L":   "L = -18.8956 +0.295656*ìŠµë„_mean_m01 +0.201764*ìŠµë„_mean_m07 +2.76035*ìµœì €ê¸°ì˜¨_mean_m06 +0.216754*í‰ê· ê¸°ì˜¨_mean_m08 +0.0233481*ê°•ìš°ëŸ‰_sum_m06 -1.98533*ìµœì €ê¸°ì˜¨_mean_m05 +0.000291997*ê°•ìš°ëŸ‰_sum_m10 -7.85007*í‰ê· í’ì†_mean_m06 -0.0106574*ìµœì €ê¸°ì˜¨_mean_m01 +3.28669*ìµœëŒ€í’ì†_mean_m06 +1.81111*í‰ê· í’ì†_mean_m07 -0.984845*ìµœëŒ€í’ì†_mean_m01 +1.00267*ìµœì €ê¸°ì˜¨_mean_m11 +0.185018*ìµœëŒ€í’ì†_mean_m02",
    "a":   "a = 107.273 -0.60921*ìŠµë„_mean_m07 +0.0211848*ìŠµë„_mean_m01 -0.2095*ê°•ìš°ëŸ‰_sum_m01 +1.04499*ìµœì €ê¸°ì˜¨_mean_m05 -0.0574164*ì¼ì‚¬ëŸ‰_sum_m07 -0.0255798*ê°•ìš°ëŸ‰_sum_m06 +0.353024*ìµœê³ ê¸°ì˜¨_mean_m12 -0.0768866*ì¼ì‚¬ëŸ‰_sum_m01 +5.1832*ìµœëŒ€í’ì†_mean_m01 +0.0847879*ì¼ì‚¬ëŸ‰_sum_m12 -2.542*ìµœì €ê¸°ì˜¨_mean_m11 +0.00246546*ê°•ìš°ëŸ‰_sum_m10 -1.30278*ìµœê³ ê¸°ì˜¨_mean_m06 +0.000167988*ê°•ìš°ëŸ‰_sum_m08",
    "b":   "b = -8.76636 +0.150928*ìŠµë„_mean_m01 +0.2415*ìŠµë„_mean_m07 +0.0140843*ê°•ìš°ëŸ‰_sum_m01 +0.00991179*ê°•ìš°ëŸ‰_sum_m06 -0.0265506*ìµœê³ ê¸°ì˜¨_mean_m11 -0.0665377*ìŠµë„_mean_m05 +0.0115693*ê°•ìš°ëŸ‰_sum_m10 +1.64114*ìµœì €ê¸°ì˜¨_mean_m06 -0.516096*í‰ê· í’ì†_mean_m07 -0.989597*ìµœì €ê¸°ì˜¨_mean_m05 -0.749867*ìµœê³ ê¸°ì˜¨_mean_m05 +0.0279286*ìŠµë„_mean_m12 -0.00214226*ê°•ìš°ëŸ‰_sum_m08 -2.66929*í‰ê· í’ì†_mean_m08 +0.793795*ìµœëŒ€í’ì†_mean_m06",
    "ê²½ë„": "ê²½ë„ = 301.381 -6.50372*ìµœëŒ€í’ì†_mean_m02 -0.0609388*ìŠµë„_mean_m04 +0.0806892*ê°•ìš°ëŸ‰_sum_m12 -0.882603*ìŠµë„_mean_m08 +1.27762*ìµœê³ ê¸°ì˜¨_mean_m12 +0.00699291*ê°•ìš°ëŸ‰_sum_m03 -0.94864*ìµœì €ê¸°ì˜¨_mean_m12 -1.20453*ìŠµë„_mean_m09 +0.00443249*ê²°ë¡œì‹œê°„_mean_m04 -2.59534*í‰ê· ê¸°ì˜¨_mean_m08 +0.183054*ìŠµë„_mean_m02 +2.18242*í‰ê· í’ì†_mean_m09 +0.00175875*ì¼ì‚¬ëŸ‰_sum_m03",
}

# -------------------------------------------------
# ìœ í‹¸
# -------------------------------------------------
def _ensure_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# -------------------------------------------------
# ì‚¬ì´íŠ¸ AJAX â†’ JSON
# -------------------------------------------------
@st.cache_data(show_spinner=False, ttl=300)
def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
    """
    stat_gb_code: "A"(ê¸°ê°„), "B"(ì¼ë³„), "C"(ìˆœë³„), "D"(ì›”ë³„)
    s_ym/e_ym: "YYYY-MM"
    """
    session = requests.Session()
    session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)

    form = {
        "pageIndex": "1",
        "searchNum": "0",
        "areaName": region_name,
        "areaCode": AREA_CODE.get(region_name, region_name),
        "statmethod": stat_gb_code,
    }
    if stat_gb_code == "A":
        form["wetherDtBgn"] = f"{s_ym}-01"
        form["wetherDtEnd"] = f"{e_ym}-30"
    elif stat_gb_code in ("B", "C"):
        form["wetherDtM"] = s_ym
    elif stat_gb_code == "D":
        form["wetherDtBgn2"] = s_ym
        form["wetherDtEnd2"] = e_ym
        form["wetherDtBgn"] = s_ym
        form["wetherDtEnd"] = e_ym

    resp = session.post(
        "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
        data=form, timeout=30,
        headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
    )
    resp.raise_for_status()
    try:
        return resp.json()
    except Exception:
        return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

# -------------------------------------------------
# JSON â†’ í‘œ
# -------------------------------------------------
def json_to_dataframe(payload: dict) -> pd.DataFrame:
    if not payload or "result" not in payload:
        return pd.DataFrame()
    res = payload.get("result", [])
    if len(res) == 0:
        return pd.DataFrame()

    method = payload.get("mainAwsVO", {}).get("statmethod")
    if method == "A":
        df = pd.DataFrame(res)[[
            "statsDt","dalyWetherAvrgTp","dalyWetherMxmmTp","dalyWetherMummTp",
            "dalyWetherAvrgHd","dalyWetherTtalRainqy","dalyWetherMxmmSolradqy",
            "dalyWetherMxmmCondenstime","dalyWetherAvrgWs","dalyWetherMxmmWs"
        ]].rename(columns={
            "statsDt":"ì¼ì","dalyWetherAvrgTp":"í‰ê· ê¸°ì˜¨","dalyWetherMxmmTp":"ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp":"ìµœì €ê¸°ì˜¨","dalyWetherAvrgHd":"ìŠµë„","dalyWetherTtalRainqy":"ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy":"ì¼ì‚¬ëŸ‰","dalyWetherMxmmCondenstime":"ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs":"í‰ê· í’ì†","dalyWetherMxmmWs":"ìµœëŒ€í’ì†"
        })
    elif method == "B":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì¼ì","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    elif method == "C":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ìˆœ","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    else:  # "D"
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherMaxCondenstime","wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì›”","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherMaxCondenstime":"ê²°ë¡œì‹œê°„",
            "wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })

    df = _ensure_numeric(
        df, ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    )

    if "ì¼ì" in df.columns:
        df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
        df["ì—°ë„"] = df["ì¼ì"].dt.year
        df["ì›”"] = df["ì¼ì"].dt.month
    elif "ì›”" in df.columns:
        df["ì—°ë„"] = df["ì›”"].astype(str).str[:4].astype(int)
        df["ì›”"] = df["ì›”"].astype(str).str[5:7].astype(int)

    return df

# -------------------------------------------------
# ì¼/ìˆœ â†’ ì›”ë³„ ì§‘ê³„
# -------------------------------------------------
def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(df.columns):
        return df.copy()

    agg_map = {
        "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
        "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
        "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
    }
    use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
    out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
    return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

# -------------------------------------------------
# ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (_mean_mMM / _sum_mMM)
# -------------------------------------------------
def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
        raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]

    # í‰ê· /í•©ê³„
    mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
    sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()

    wide_mean = None
    for m in range(1, 13):
        sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
        wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")

    wide_sum = None
    for m in range(1, 13):
        sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
        wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")

    wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
    return wide

# -------------------------------------------------
# íšŒê·€ì‹ ì ìš© (í•œ ì—°ë„ rowì— ëŒ€í•´)
# -------------------------------------------------
def apply_equation_row(row: pd.Series, eq_str: str) -> float:
    rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
    # ê¸´ ì—´ ì´ë¦„ë¶€í„° ëŒ€ì¹˜
    cols = sorted(row.index.tolist(), key=len, reverse=True)
    expr = rhs
    for c in cols:
        expr = expr.replace(c, f"row[{repr(c)}]")
    return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

# -------------------------------------------------
# ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°: ìµœê·¼ 3ë…„ í‰ê·  or ì „ì²´ í‰ê· 
# -------------------------------------------------
def fill_missing_months_with_climatology(env_m: pd.DataFrame, target_year: int, mode: str = "last3") -> pd.DataFrame:
    """
    env_m: ì›”ë³„ ìš”ì•½ DF(ì—°ë„, ì›”, ë³€ìˆ˜ë“¤)
    target_year: ì±„ì›Œì•¼ í•  ì—°ë„
    mode: "last3"=ìµœê·¼3ë…„ í‰ê· , "all"=ì „ì²´ ê³¼ê±° í‰ê· 
    """
    req_cols = {"ì—°ë„", "ì›”"}
    if not req_cols.issubset(env_m.columns):
        raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    cur = env_m[env_m["ì—°ë„"] == target_year].copy()
    hist = env_m[env_m["ì—°ë„"] < target_year].copy()
    if hist.empty:
        return cur  # ê³¼ê±° ì—†ìœ¼ë©´ ì±„ìš¸ ìˆ˜ ì—†ìŒ

    if mode == "last3":
        last_years = sorted(hist["ì—°ë„"].unique())[-3:]
        hist = hist[hist["ì—°ë„"].isin(last_years)]

    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
    climo = hist.groupby("ì›”", as_index=False)[num_cols].mean()

    have_months = set(cur["ì›”"].tolist())
    all_months = set(range(1, 13))
    missing = sorted(list(all_months - have_months))

    if missing:
        fill_rows = climo[climo["ì›”"].isin(missing)].copy()
        fill_rows.insert(0, "ì—°ë„", target_year)
        cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)

    cur = cur.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
    for c in num_cols:
        cur[c] = pd.to_numeric(cur[c], errors="coerce")
    return cur

# -------------------------------------------------
# ì‚¬ì´ë“œë°”
# -------------------------------------------------
with st.sidebar:
    st.header("ì¡°íšŒ ì¡°ê±´")
    region = st.selectbox("ì§€ì—­", list(AREA_CODE.keys()), index=1)
    stat_label = st.selectbox("í†µê³„ êµ¬ë¶„", ["ê¸°ê°„(ì¼ìë²”ìœ„)","ì¼ë³„","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)","ì›”ë³„"], index=3)
    stat_map = {"ê¸°ê°„(ì¼ìë²”ìœ„)":"A","ì¼ë³„":"B","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)":"C","ì›”ë³„":"D"}
    stat_gb = stat_map[stat_label]

    col1, col2 = st.columns(2)
    with col1:
        s_year = st.number_input("ì‹œì‘ ì—°ë„", 2010, 2100, 2024, 1)
        s_month = st.number_input("ì‹œì‘ ì›”", 1, 12, 1, 1)
    with col2:
        e_year = st.number_input("ì¢…ë£Œ ì—°ë„", 2010, 2100, 2025, 1)
        e_month = st.number_input("ì¢…ë£Œ ì›”", 1, 12, 8, 1)

    s_ym = f"{int(s_year):04d}-{int(s_month):02d}"
    e_ym = f"{int(e_year):04d}-{int(e_month):02d}"

    fill_strategy = st.selectbox(
        "ë¯¸í™•ë³´ ì›” ì±„ì›€ ë°©ë²•",
        ["ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)", "ìµœê·¼ 3ë…„ ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°", "ì „ì²´ ê³¼ê±° ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°"],
        index=1
    )

    run = st.button("ğŸ” ì¡°íšŒ & ì˜ˆì¸¡")

# -------------------------------------------------
# ì‹¤í–‰
# -------------------------------------------------
if run:
    with st.spinner("ì„œë²„ì—ì„œ ê¸°ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        payload = fetch_aws_stat(region, stat_gb, s_ym, e_ym)

    if "error" in payload:
        st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.code(payload.get("raw","")[:1000])
        st.stop()

    df = json_to_dataframe(payload)
    if df.empty:
        st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„(íŠ¹íˆ 'ê¸°ê°„'ì€ 1ë…„ ì´ë‚´)ê³¼ ì§€ì—­ì„ ì¡°ì •í•˜ì„¸ìš”.")
        st.stop()

    st.subheader("ì›ìë£Œ")
    st.dataframe(df, use_container_width=True)

    # ì›”ë³„ ì§‘ê³„
    if stat_gb in ("A","B","C"):
        env_m = agg_to_monthly(df)
        st.subheader("ì›”ë³„ ìš”ì•½(ì§‘ê³„)")
    else:
        env_m = df.copy()
        if "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"] = env_m["ì›”"].astype(str).str[5:7].astype(int)
        st.subheader("ì›”ë³„ ì‘ë‹µ")

    st.dataframe(env_m, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œ
    c1, c2 = st.columns(2)
    with c1:
        st.download_button(
            "â¬‡ï¸ ì›ìë£Œ CSV",
            df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_raw.csv",
            mime="text/csv",
        )
    with c2:
        st.download_button(
            "â¬‡ï¸ ì›”ë³„ìš”ì•½ CSV",
            env_m.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_monthly.csv",
            mime="text/csv",
        )

    # ì˜ˆì¸¡ ì—°ë„ ì„ íƒ (env_m ê¸°ì¤€)
    years = sorted(env_m["ì—°ë„"].dropna().astype(int).unique())
    if not years:
        st.warning("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_year = st.selectbox("ì˜ˆì¸¡ ì—°ë„ ì„ íƒ", years, index=len(years)-1)

    # ì„ íƒ ì—°ë„ì˜ ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸° ì ìš©
    env_m_filled = env_m.copy()
    if fill_strategy != "ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)":
        mode = "last3" if "ìµœê·¼ 3ë…„" in fill_strategy else "all"
        filled_rowset = fill_missing_months_with_climatology(env_m, sel_year, mode=mode)
        env_m_filled = pd.concat(
            [env_m_filled[env_m_filled["ì—°ë„"] != sel_year], filled_rowset],
            ignore_index=True
        ).sort_values(["ì—°ë„","ì›”"])

        st.info(f"{sel_year}ë…„ì˜ ë¹„ì–´ ìˆëŠ” ì›”ì„ '{fill_strategy}'ë¡œ ì±„ì› ìŠµë‹ˆë‹¤.")
        st.dataframe(env_m_filled[env_m_filled["ì—°ë„"] == sel_year], use_container_width=True)

    # ê°€ë¡œ í™•ì¥ í”¼ì²˜ ìƒì„± (ì±„ì›€ ë°˜ì˜)
    try:
        wide = build_wide_month_feats(env_m_filled)
    except Exception as e:
        st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
        st.stop()

    st.subheader("ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (ì„ íƒ ì—°ë„)")
    st.dataframe(wide[wide["ì—°ë„"] == sel_year], use_container_width=True)

    # ì„ íƒ ì—°ë„ í–‰
    row = wide[wide["ì—°ë„"] == sel_year].iloc[0]

    # íšŒê·€ì‹ ì „ë¶€ ì ìš©
    preds = {}
    for tgt, formula in EQUATIONS.items():
        try:
            preds[tgt] = apply_equation_row(row, formula)
        except Exception as e:
            preds[tgt] = f"ì—ëŸ¬: {e}"

    st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼ (ì—°ë„: {sel_year})")
    st.write(preds)

else:
    st.info("ì¢Œì¸¡ì—ì„œ ì¡°ê±´ì„ ê³ ë¥´ê³  **ğŸ” ì¡°íšŒ & ì˜ˆì¸¡** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
