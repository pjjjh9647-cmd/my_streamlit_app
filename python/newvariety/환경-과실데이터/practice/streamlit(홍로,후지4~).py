# -*- coding: utf-8 -*-
# íŒŒì¼ëª…: ê¸°ìƒìë™ë¶ˆëŸ¬ì˜¤ê¸°3.py
import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime

# -------------------------------------------------
# ê¸°ë³¸ UI
# -------------------------------------------------
st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ + íšŒê·€ì‹ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ ìˆ˜ì§‘ + íšŒê·€ì‹ ì˜ˆì¸¡ê¸°")

# -------------------------------------------------
# ì§€ì—­ ì½”ë“œ (ì‚¬ì´íŠ¸ì˜ select valueì™€ ë™ì¼)
# -------------------------------------------------
AREA_CODE = {
    "ê²½ê¸°í™”ì„±": "324",
    "ê²½ë¶ì˜ì£¼": "331",
    "ê²½ë¶ì²­ì†¡": "332",
    "ëŒ€êµ¬êµ°ìœ„": "333",
    "ê²½ë‚¨ê±°ì°½": "334",
    "ì „ë¶ì¥ìˆ˜": "335",
    "ê²½ê¸°í¬ì²œ": "337",
    "ì¶©ë¶ì¶©ì£¼": "338",
}

# -------------------------------------------------
# íšŒê·€ì‹ í•˜ë“œì½”ë”©: í’ˆì¢…ë³„
#   ì¤‘ê°„ì  'Â·'ì€ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ '*'ë¡œ ì¹˜í™˜
# -------------------------------------------------
EQUATIONS_BY_CULTIVAR = {
    "í™ë¡œ": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 667.243 -0.597465Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.376337Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.0756442Â·ì¼ì‚¬ëŸ‰_sum_m08 +24.5342Â·í‰ê· í’ì†_mean_m06 +5.05212Â·ìµœì €ê¸°ì˜¨_mean_m06",
        "ì¢…ê²½": "ì¢…ê²½ = 124.046 -0.0439843Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.0673823Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.397906Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.559339Â·í‰ê· í’ì†_mean_m06 +7.43416Â·í‰ê· í’ì†_mean_m05 +0.00854761Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.15116Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.05474Â·ìµœì €ê¸°ì˜¨_mean_m05 -2.574Â·ìµœëŒ€í’ì†_mean_m04",
        "íš¡ê²½": "íš¡ê²½ = 141.358 -0.0531011Â·ì¼ì‚¬ëŸ‰_sum_m06 -0.0459844Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.00297393Â·ì¼ì‚¬ëŸ‰_sum_m08",
        "L":   "L = -68.3528 +2.1686e-05Â·ê°•ìš°ëŸ‰_sum_m07 +0.653086Â·ìŠµë„_mean_m07 +2.72693Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.14857Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.00918464Â·ê°•ìš°ëŸ‰_sum_m06 -1.52125Â·ìµœì €ê¸°ì˜¨_mean_m05 -6.00147Â·í‰ê· í’ì†_mean_m06 +3.14509Â·ìµœëŒ€í’ì†_mean_m06 +4.16545Â·í‰ê· í’ì†_mean_m07",
        "a":   "a = 226.087 -1.71711Â·ìŠµë„_mean_m07 +0.00830904Â·ê°•ìš°ëŸ‰_sum_m07 -4.51272Â·ìµœì €ê¸°ì˜¨_mean_m06 +1.51756Â·ìµœì €ê¸°ì˜¨_mean_m05 -1.94971Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.040713Â·ì¼ì‚¬ëŸ‰_sum_m07 -0.0185248Â·ê°•ìš°ëŸ‰_sum_m06 +0.00975096Â·ê°•ìš°ëŸ‰_sum_m08 +1.93026Â·ìµœê³ ê¸°ì˜¨_mean_m07 -0.192988Â·í‰ê· í’ì†_mean_m06",
        "b":   "b = -23.7933 +0.381237Â·ìŠµë„_mean_m07 +0.0052134Â·ê°•ìš°ëŸ‰_sum_m06 +0.0606139Â·ìŠµë„_mean_m05 +1.14817Â·ìµœì €ê¸°ì˜¨_mean_m06 +0.682908Â·í‰ê· í’ì†_mean_m07 -0.523353Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.350293Â·ìµœê³ ê¸°ì˜¨_mean_m05 -0.00264168Â·ê°•ìš°ëŸ‰_sum_m08 -1.23413Â·í‰ê· í’ì†_mean_m08 +0.652516Â·ìµœëŒ€í’ì†_mean_m06",
        "ê²½ë„": "ê²½ë„ = 54.6658 +0.2039Â·ìŠµë„_mean_m04 +0.0144323Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.194462Â·ìŠµë„_mean_m08 -0.0140798Â·ì¼ì‚¬ëŸ‰_sum_m04 +0.00218425Â·ê²°ë¡œì‹œê°„_mean_m04 +0.364872Â·í‰ê· ê¸°ì˜¨_mean_m08",
        "ë‹¹ë„": "ë‹¹ë„ = 1.14467 -0.425354Â·ìµœëŒ€í’ì†_mean_m06 -1.03279Â·í‰ê· í’ì†_mean_m07 -0.0754722Â·í‰ê· í’ì†_mean_m08 +0.781233Â·í‰ê· í’ì†_mean_m04 -0.0277847Â·ìµœê³ ê¸°ì˜¨_mean_m08 -0.0127413Â·ìŠµë„_mean_m05 +0.0022906Â·ê²°ë¡œì‹œê°„_mean_m05 +0.259103Â·ìµœê³ ê¸°ì˜¨_mean_m06 +0.0923847Â·ìŠµë„_mean_m04 +0.410232Â·ìµœëŒ€í’ì†_mean_m04 -0.00215038Â·ê°•ìš°ëŸ‰_sum_m06",
        "ì‚°ë„": "ì‚°ë„ = 0.262689 +0.0555189Â·ìµœëŒ€í’ì†_mean_m06 +0.0451885Â·í‰ê· í’ì†_mean_m08 -0.0549304Â·í‰ê· í’ì†_mean_m04 -0.00534754Â·ìµœê³ ê¸°ì˜¨_mean_m06 -0.0236952Â·í‰ê· í’ì†_mean_m07 -0.00264247Â·ìŠµë„_mean_m04 +0.00413186Â·ìŠµë„_mean_m08 -0.00334177Â·í‰ê· ê¸°ì˜¨_mean_m07 +0.000124634Â·ê°•ìš°ëŸ‰_sum_m06 -0.001393Â·ìŠµë„_mean_m05",
    },
    "í›„ì§€": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 399.484 -0.229845Â·ì¼ì‚¬ëŸ‰_sum_m04 +6.76485Â·ìµœì €ê¸°ì˜¨_mean_m05 -17.8404Â·ìµœëŒ€í’ì†_mean_m07",
        "ì¢…ê²½": "ì¢…ê²½ = 183.553 -0.0439139Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.626045Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0145561Â·ì¼ì‚¬ëŸ‰_sum_m10 +0.955631Â·ìµœì €ê¸°ì˜¨_mean_m05 -0.0373121Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.656449Â·ìŠµë„_mean_m08 -0.0131851Â·ìŠµë„_mean_m06 +1.16239Â·í‰ê· ê¸°ì˜¨_mean_m07 -1.16892Â·ìµœì €ê¸°ì˜¨_mean_m09 -0.420997Â·ìŠµë„_mean_m09",
        "íš¡ê²½": "íš¡ê²½ = 79.6808 -1.82161Â·ìµœëŒ€í’ì†_mean_m07 +0.796471Â·í‰ê· ê¸°ì˜¨_mean_m05",
        "L":   "L = 75.7441 -0.134414Â·ìŠµë„_mean_m08 -0.400198Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0159958Â·ê°•ìš°ëŸ‰_sum_m10 +0.0240315Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.812706Â·ìµœì €ê¸°ì˜¨_mean_m04 -0.0812023Â·ìŠµë„_mean_m04 -0.206954Â·ìŠµë„_mean_m06 +0.116267Â·ìŠµë„_mean_m10 -0.0069829Â·ì¼ì‚¬ëŸ‰_sum_m04 -2.452Â·í‰ê· í’ì†_mean_m04 -0.0989298Â·í‰ê· ê¸°ì˜¨_mean_m08 -0.384125Â·í‰ê· ê¸°ì˜¨_mean_m07",
        "a":   "a = 4.0922 -0.0203282Â·ê°•ìš°ëŸ‰_sum_m10 -2.85393Â·ìµœëŒ€í’ì†_mean_m05 -0.00910066Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.0392451Â·í‰ê· ê¸°ì˜¨_mean_m06 +0.307386Â·ìŠµë„_mean_m08 +0.000860505Â·ê°•ìš°ëŸ‰_sum_m08 -0.688696Â·ìµœëŒ€í’ì†_mean_m08 -0.00144964Â·ì¼ì‚¬ëŸ‰_sum_m05 +0.758309Â·ìµœëŒ€í’ì†_mean_m07",
        "b":   "b = 12.841 -0.0308293Â·ìŠµë„_mean_m08 +0.0145751Â·ì¼ì‚¬ëŸ‰_sum_m08 -0.00322966Â·ê°•ìš°ëŸ‰_sum_m08 +0.035395Â·í‰ê· ê¸°ì˜¨_mean_m10 +0.0796701Â·ìŠµë„_mean_m10 -0.000543608Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00337387Â·ê°•ìš°ëŸ‰_sum_m10 -0.00372859Â·ì¼ì‚¬ëŸ‰_sum_m04 -0.14243Â·ìŠµë„_mean_m06 +0.0641568Â·í‰ê· ê¸°ì˜¨_mean_m08 +0.14721Â·ìµœì €ê¸°ì˜¨_mean_m07 +0.53868Â·í‰ê· í’ì†_mean_m04",
        "ê²½ë„": "ê²½ë„ = 8.39888 +0.0529999Â·ì¼ì‚¬ëŸ‰_sum_m09 +6.94666Â·í‰ê· í’ì†_mean_m07 +3.98929Â·ìµœëŒ€í’ì†_mean_m08 -0.0451264Â·ì¼ì‚¬ëŸ‰_sum_m08 +0.406065Â·ìŠµë„_mean_m04 -3.47701Â·í‰ê· í’ì†_mean_m06 -0.00806023Â·ê²°ë¡œì‹œê°„_mean_m10 +0.0392251Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00773583Â·ê²°ë¡œì‹œê°„_mean_m09 -2.0759Â·ìµœëŒ€í’ì†_mean_m10 +0.000289527Â·ê²°ë¡œì‹œê°„_mean_m06 -2.8229Â·ìµœëŒ€í’ì†_mean_m05 +0.000106158Â·ê²°ë¡œì‹œê°„_mean_m05 +0.270037Â·ìµœê³ ê¸°ì˜¨_mean_m09",
        "ë‹¹ë„": "ë‹¹ë„ = 10.492 +0.00486017Â·ì¼ì‚¬ëŸ‰_sum_m06 +0.00146432Â·ê²°ë¡œì‹œê°„_mean_m10 +0.00262004Â·ê²°ë¡œì‹œê°„_mean_m07 -0.00156465Â·ê²°ë¡œì‹œê°„_mean_m09 -1.20735Â·í‰ê· í’ì†_mean_m10 -0.000317261Â·ê²°ë¡œì‹œê°„_mean_m05",
        "ì‚°ë„": "ì‚°ë„ = 0.766184 -0.0175941Â·í‰ê· ê¸°ì˜¨_mean_m10 -0.00379855Â·ìŠµë„_mean_m04 -0.00807644Â·ìµœê³ ê¸°ì˜¨_mean_m04 -4.6679e-05Â·ê°•ìš°ëŸ‰_sum_m08 +0.00318949Â·ìµœê³ ê¸°ì˜¨_mean_m08 -8.77968e-05Â·ê°•ìš°ëŸ‰_sum_m10 -0.00456198Â·í‰ê· í’ì†_mean_m04 +0.00411344Â·ìµœê³ ê¸°ì˜¨_mean_m07",
    },
}

# -------------------------------------------------
# ìœ í‹¸
# -------------------------------------------------
def _ensure_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# -------------------------------------------------
# ì‚¬ì´íŠ¸ AJAX â†’ JSON
# -------------------------------------------------
@st.cache_data(show_spinner=False, ttl=300)
def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
    """
    stat_gb_code: "A"(ê¸°ê°„), "B"(ì¼ë³„), "C"(ìˆœë³„), "D"(ì›”ë³„)
    s_ym/e_ym: "YYYY-MM"
    """
    session = requests.Session()
    session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)

    form = {
        "pageIndex": "1",
        "searchNum": "0",
        "areaName": region_name,
        "areaCode": AREA_CODE.get(region_name, region_name),
        "statmethod": stat_gb_code,
    }
    if stat_gb_code == "A":
        form["wetherDtBgn"] = f"{s_ym}-01"
        form["wetherDtEnd"] = f"{e_ym}-30"
    elif stat_gb_code in ("B", "C"):
        form["wetherDtM"] = s_ym
    elif stat_gb_code == "D":
        form["wetherDtBgn2"] = s_ym
        form["wetherDtEnd2"] = e_ym
        form["wetherDtBgn"] = s_ym
        form["wetherDtEnd"] = e_ym

    resp = session.post(
        "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
        data=form, timeout=30,
        headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
    )
    resp.raise_for_status()
    try:
        return resp.json()
    except Exception:
        return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

# -------------------------------------------------
# JSON â†’ í‘œ
# -------------------------------------------------
def json_to_dataframe(payload: dict) -> pd.DataFrame:
    if not payload or "result" not in payload:
        return pd.DataFrame()
    res = payload.get("result", [])
    if len(res) == 0:
        return pd.DataFrame()

    method = payload.get("mainAwsVO", {}).get("statmethod")
    if method == "A":
        df = pd.DataFrame(res)[[
            "statsDt","dalyWetherAvrgTp","dalyWetherMxmmTp","dalyWetherMummTp",
            "dalyWetherAvrgHd","dalyWetherTtalRainqy","dalyWetherMxmmSolradqy",
            "dalyWetherMxmmCondenstime","dalyWetherAvrgWs","dalyWetherMxmmWs"
        ]].rename(columns={
            "statsDt":"ì¼ì","dalyWetherAvrgTp":"í‰ê· ê¸°ì˜¨","dalyWetherMxmmTp":"ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp":"ìµœì €ê¸°ì˜¨","dalyWetherAvrgHd":"ìŠµë„","dalyWetherTtalRainqy":"ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy":"ì¼ì‚¬ëŸ‰","dalyWetherMxmmCondenstime":"ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs":"í‰ê· í’ì†","dalyWetherMxmmWs":"ìµœëŒ€í’ì†"
        })
    elif method == "B":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì¼ì","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    elif method == "C":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ìˆœ","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    else:  # "D"
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherMaxCondenstime","wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì›”","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherMaxCondenstime":"ê²°ë¡œì‹œê°„",
            "wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })

    df = _ensure_numeric(
        df, ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    )

    if "ì¼ì" in df.columns:
        df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
        df["ì—°ë„"] = df["ì¼ì"].dt.year
        df["ì›”"] = df["ì¼ì"].dt.month
    elif "ì›”" in df.columns:
        df["ì—°ë„"] = df["ì›”"].astype(str).str[:4].astype(int)
        df["ì›”"] = df["ì›”"].astype(str).str[5:7].astype(int)

    return df

# -------------------------------------------------
# ì¼/ìˆœ â†’ ì›”ë³„ ì§‘ê³„
# -------------------------------------------------
def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(df.columns):
        return df.copy()

    agg_map = {
        "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
        "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
        "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
    }
    use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
    out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
    return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

# -------------------------------------------------
# ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (_mean_mMM / _sum_mMM)
# -------------------------------------------------
def build_wide_month_feats(env_m: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(env_m.columns):
        raise ValueError("env_mì— 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]

    mean_agg = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].mean()
    sum_agg  = env_m.groupby(["ì—°ë„","ì›”"], as_index=False)[num_cols].sum()

    wide_mean = None
    for m in range(1, 13):
        sub = mean_agg[mean_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_mean_m{m:02d}" for c in num_cols})
        wide_mean = sub if wide_mean is None else pd.merge(wide_mean, sub, on="ì—°ë„", how="outer")

    wide_sum = None
    for m in range(1, 13):
        sub = sum_agg[sum_agg["ì›”"] == m].drop(columns=["ì›”"]).copy()
        sub = sub.rename(columns={c: f"{c}_sum_m{m:02d}" for c in num_cols})
        wide_sum = sub if wide_sum is None else pd.merge(wide_sum, sub, on="ì—°ë„", how="outer")

    wide = pd.merge(wide_mean, wide_sum, on="ì—°ë„", how="outer").fillna(0)
    return wide

# -------------------------------------------------
# íšŒê·€ì‹ ì ìš© (í•œ ì—°ë„ rowì— ëŒ€í•´)
# -------------------------------------------------
def apply_equation_row(row: pd.Series, eq_str: str) -> float:
    rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
    cols = sorted(row.index.tolist(), key=len, reverse=True)
    expr = rhs
    for c in cols:
        expr = expr.replace(c, f"row[{repr(c)}]")
    return float(eval(expr, {"__builtins__": {}}, {"row": row, "np": np}))

# -------------------------------------------------
# ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°: ìµœê·¼ 3ë…„ í‰ê·  or ì „ì²´ í‰ê· 
# -------------------------------------------------
def fill_missing_months_with_climatology(env_m: pd.DataFrame, target_year: int, mode: str = "last3") -> pd.DataFrame:
    req_cols = {"ì—°ë„", "ì›”"}
    if not req_cols.issubset(env_m.columns):
        raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    cur = env_m[env_m["ì—°ë„"] == target_year].copy()
    hist = env_m[env_m["ì—°ë„"] < target_year].copy()
    if hist.empty:
        return cur

    if mode == "last3":
        last_years = sorted(hist["ì—°ë„"].unique())[-3:]
        hist = hist[hist["ì—°ë„"].isin(last_years)]

    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
    climo = hist.groupby("ì›”", as_index=False)[num_cols].mean()

    have_months = set(cur["ì›”"].tolist())
    all_months = set(range(1, 13))
    missing = sorted(list(all_months - have_months))

    if missing:
        fill_rows = climo[climo["ì›”"].isin(missing)].copy()
        fill_rows.insert(0, "ì—°ë„", target_year)
        cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)

    cur = cur.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
    for c in num_cols:
        cur[c] = pd.to_numeric(cur[c], errors="coerce")
    return cur

# -------------------------------------------------
# ì‚¬ì´ë“œë°”
# -------------------------------------------------
with st.sidebar:
    st.header("ì¡°íšŒ ì¡°ê±´")
    region = st.selectbox("ì§€ì—­", list(AREA_CODE.keys()), index=1)
    stat_label = st.selectbox("í†µê³„ êµ¬ë¶„", ["ê¸°ê°„(ì¼ìë²”ìœ„)","ì¼ë³„","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)","ì›”ë³„"], index=3)
    stat_map = {"ê¸°ê°„(ì¼ìë²”ìœ„)":"A","ì¼ë³„":"B","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)":"C","ì›”ë³„":"D"}
    stat_gb = stat_map[stat_label]

    col1, col2 = st.columns(2)
    with col1:
        s_year = st.number_input("ì‹œì‘ ì—°ë„", 2010, 2100, 2024, 1)
        s_month = st.number_input("ì‹œì‘ ì›”", 1, 12, 1, 1)
    with col2:
        e_year = st.number_input("ì¢…ë£Œ ì—°ë„", 2010, 2100, 2025, 1)
        e_month = st.number_input("ì¢…ë£Œ ì›”", 1, 12, 8, 1)

    s_ym = f"{int(s_year):04d}-{int(s_month):02d}"
    e_ym = f"{int(e_year):04d}-{int(e_month):02d}"

    cultivar = st.selectbox("í’ˆì¢…", ["í™ë¡œ", "í›„ì§€"], index=0)

    fill_strategy = st.selectbox(
        "ë¯¸í™•ë³´ ì›” ì±„ì›€ ë°©ë²•",
        ["ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)", "ìµœê·¼ 3ë…„ ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°", "ì „ì²´ ê³¼ê±° ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°"],
        index=1
    )

    run = st.button("ğŸ” ì¡°íšŒ & ì˜ˆì¸¡")

# -------------------------------------------------
# ì‹¤í–‰
# -------------------------------------------------
if run:
    with st.spinner("ì„œë²„ì—ì„œ ê¸°ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        payload = fetch_aws_stat(region, stat_gb, s_ym, e_ym)

    if "error" in payload:
        st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.code(payload.get("raw","")[:1000])
        st.stop()

    df = json_to_dataframe(payload)
    if df.empty:
        st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„(íŠ¹íˆ 'ê¸°ê°„'ì€ 1ë…„ ì´ë‚´)ê³¼ ì§€ì—­ì„ ì¡°ì •í•˜ì„¸ìš”.")
        st.stop()

    st.subheader("ì›ìë£Œ")
    st.dataframe(df, use_container_width=True)

    # ì›”ë³„ ì§‘ê³„
    if stat_gb in ("A","B","C"):
        env_m = agg_to_monthly(df)
        st.subheader("ì›”ë³„ ìš”ì•½(ì§‘ê³„)")
    else:
        env_m = df.copy()
        if "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"] = env_m["ì›”"].astype(str).str[5:7].astype(int)
        st.subheader("ì›”ë³„ ì‘ë‹µ")

    st.dataframe(env_m, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œ
    c1, c2 = st.columns(2)
    with c1:
        st.download_button(
            "â¬‡ï¸ ì›ìë£Œ CSV",
            df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_raw.csv",
            mime="text/csv",
        )
    with c2:
        st.download_button(
            "â¬‡ï¸ ì›”ë³„ìš”ì•½ CSV",
            env_m.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_monthly.csv",
            mime="text/csv",
        )

    # ì˜ˆì¸¡ ì—°ë„ ì„ íƒ
    years = sorted(env_m["ì—°ë„"].dropna().astype(int).unique())
    if not years:
        st.warning("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_year = st.selectbox("ì˜ˆì¸¡ ì—°ë„ ì„ íƒ", years, index=len(years)-1)

    # ì„ íƒ ì—°ë„ì˜ ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°
    env_m_filled = env_m.copy()
    if fill_strategy != "ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)":
        mode = "last3" if "ìµœê·¼ 3ë…„" in fill_strategy else "all"
        filled_rowset = fill_missing_months_with_climatology(env_m, sel_year, mode=mode)
        env_m_filled = pd.concat(
            [env_m_filled[env_m_filled["ì—°ë„"] != sel_year], filled_rowset],
            ignore_index=True
        ).sort_values(["ì—°ë„","ì›”"])

        st.info(f"{sel_year}ë…„ì˜ ë¹„ì–´ ìˆëŠ” ì›”ì„ '{fill_strategy}'ë¡œ ì±„ì› ìŠµë‹ˆë‹¤.")
        st.dataframe(env_m_filled[env_m_filled["ì—°ë„"] == sel_year], use_container_width=True)

    # ê°€ë¡œ í™•ì¥ í”¼ì²˜
    try:
        wide = build_wide_month_feats(env_m_filled)
    except Exception as e:
        st.error(f"ì›”ë³„ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
        st.stop()

    st.subheader("ì›”ë³„ ê°€ë¡œ í™•ì¥ í”¼ì²˜ (ì„ íƒ ì—°ë„)")
    st.dataframe(wide[wide["ì—°ë„"] == sel_year], use_container_width=True)

    # ì„ íƒ ì—°ë„ í–‰
    row = wide[wide["ì—°ë„"] == sel_year].iloc[0]

    # í’ˆì¢…ë³„ íšŒê·€ì‹ ì ìš©
    EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
    preds = {}
    for tgt, formula in EQUATIONS.items():
        try:
            preds[tgt] = apply_equation_row(row, formula)
        except Exception as e:
            preds[tgt] = f"ì—ëŸ¬: {e}"

    st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  í’ˆì¢…: {cultivar}  ì—°ë„: {sel_year}")
    st.write(preds)

else:
    st.info("ì¢Œì¸¡ì—ì„œ ì¡°ê±´ì„ ê³ ë¥´ê³  í’ˆì¢…ì„ ì„ íƒí•œ ë’¤ ì¡°íšŒ & ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
