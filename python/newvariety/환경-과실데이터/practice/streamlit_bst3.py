# -*- coding: utf-8 -*-
# íŒŒì¼ëª…: ê¸°ìƒìë™ë¶ˆëŸ¬ì˜¤ê¸°3.py
import streamlit as st
import pandas as pd
import numpy as np
import requests

# -------------------------------------------------
# ê¸°ë³¸ UI
# -------------------------------------------------
st.set_page_config(page_title="ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ + íšŒê·€ì‹ ì˜ˆì¸¡", layout="wide")
st.title("ğŸ ì‚¬ê³¼ ê¸°ìƒ í†µê³„ ìˆ˜ì§‘ + íšŒê·€ì‹ ì˜ˆì¸¡ê¸°")

# -------------------------------------------------
# ì§€ì—­ ì½”ë“œ (ì‚¬ì´íŠ¸ì˜ select valueì™€ ë™ì¼)
# -------------------------------------------------
AREA_CODE = {
    "ê²½ê¸°í™”ì„±": "324",
    "ê²½ë¶ì˜ì£¼": "331",
    "ê²½ë¶ì²­ì†¡": "332",
    "ëŒ€êµ¬êµ°ìœ„": "333",
    "ê²½ë‚¨ê±°ì°½": "334",
    "ì „ë¶ì¥ìˆ˜": "335",
    "ê²½ê¸°í¬ì²œ": "337",
    "ì¶©ë¶ì¶©ì£¼": "338",
}

# -------------------------------------------------
# íšŒê·€ì‹ í•˜ë“œì½”ë”©: í’ˆì¢…ë³„ [RF Surrogate (Top7)]
#   ë³€ìˆ˜ëª…ì€ compute_surrogate_featuresê°€ ìƒì„±í•˜ëŠ” í‚¤ì™€ ì¼ì¹˜
# -------------------------------------------------
EQUATIONS_BY_CULTIVAR = {
    "í™ë¡œ": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 12.056147*tmin_min + -9.629374*rad_mean + -7.557363*BIO1 + -7.113372*BIO3 + 6.300282*BIO2 + 0.230161*BIO4 + 0.083789*BIO17 + 342.610104",
        "ì¢…ê²½": "ì¢…ê²½ = -1.660309*BIO3 + 1.573977*BIO1 + -0.881396*BIO9 + 0.195462*BIO6 + -0.075146*BIO15 + -0.066353*BIO17 + 0.035802*BIO19 + 123.548826",
        "íš¡ê²½": "íš¡ê²½ = 1.82377*BIO2 + -1.51124*rad_mean + -1.11108*BIO3 + 0.86551*tmin_min + -0.633304*BIO1 + 0.030822*BIO17 + 0.024086*BIO4 + 100.305645",
        "L":   "L = 2.170257*rad_mean + 0.948709*tmin_min + 0.247605*BIO7 + -0.190922*BIO5 + 0.130094*BIO15 + 0.01155*BIO13 + -0.001625*BIO18 + -11.667927",
        "a":   "a = -2.131537*BIO1 + -1.02557*rad_mean + 0.362407*BIO8 + -0.262204*BIO15 + 0.10297*BIO7 + -0.003475*BIO13 + -0.001415*BIO12 + 73.912057",
        "b":   "b = -0.964736*BIO2 + 0.751818*rad_mean + 0.65202*BIO7 + -0.638487*BIO10 + 0.235709*tmin_min + 0.047874*BIO15 + 0.001465*prcp_sum + -0.446419",
        "ê²½ë„": "ê²½ë„ = 0.860667*BIO2 + -0.656111*BIO9 + 0.604804*BIO11 + 0.408686*BIO7 + 0.220572*BIO6 + 0.057338*BIO19 + -0.015364*BIO17 + 32.087843",
        "ë‹¹ë„": "ë‹¹ë„ = 0.477546*BIO7 + -0.343928*rad_mean + 0.209582*tmin_min + 0.131251*BIO3 + -0.082806*BIO1 + 0.029396*BIO17 + -0.00716*BIO19 + -5.352908",
        "ì‚°ë„": "ì‚°ë„ = -0.016915*BIO7 + -0.014232*BIO11 + -0.009266*BIO1 + 5.6e-05*BIO15 + -5.3e-05*tmax_max + -5.3e-05*BIO5 + -3.8e-05*BIO17 + 1.019211",
    },
    "í›„ì§€": {
        "ê³¼ì¤‘": "ê³¼ì¤‘ = 27.986436*tmean_mean + -19.500409*BIO1 + -12.874489*BIO2 + -9.750718*rad_mean + 3.757523*BIO3 + -3.028252*BIO14 + 0.116994*tmin_min + 161.589562",
        "ì¢…ê²½": "ì¢…ê²½ = 2.412665*tmean_mean + -1.671756*BIO2 + 0.471648*BIO8 + -0.380966*BIO9 + -0.268923*BIO14 + 0.125479*BIO3 + -0.035734*BIO4 + 68.775581",
        "íš¡ê²½": "íš¡ê²½ = 1.176866*tmean_mean + -0.748493*rad_mean + 0.593462*BIO2 + -0.384283*BIO3 + -0.325304*BIO14 + -0.293261*tmin_min + -0.015595*BIO4 + 98.009556",
        "L":   "L = 1.028479*tmean_mean + 0.920429*rad_mean + 0.775709*tmin_min + 0.553947*BIO6 + 0.090418*BIO5 + 0.090418*tmax_max + -0.045502*BIO15 + 7.803875",
        "a":   "a = 4.590789*BIO2 + -1.63216*BIO3 + -0.872113*rad_mean + -0.766842*BIO7 + -0.522951*BIO6 + 0.13017*BIO8 + 0.09858*BIO15 + 37.248344",
        "b":   "b = 0.50634*tmax_max + 0.50634*BIO5 + 0.457942*rad_mean + -0.317073*BIO7 + -0.212172*BIO2 + -0.049509*BIO15 + 0.01981*BIO17 + -4.395964",
        "ê²½ë„": "ê²½ë„ = 2.616906*rad_mean + -0.544131*BIO3 + 0.145794*BIO14 + 0.112602*BIO15 + 0.04379*BIO17 + -0.002874*BIO19 + -0.000805*BIO18 + 22.750648",
        "ë‹¹ë„": "ë‹¹ë„ = 0.166642*BIO7 + 0.071367*BIO3 + -0.054104*BIO9 + -0.015806*BIO8 + 0.007976*BIO15 + 0.006492*BIO19 + 0.000995*BIO4 + 2.756779",
        "ì‚°ë„": "ì‚°ë„ = -0.010443*BIO1 + 0.004683*rad_mean + -0.003907*BIO5 + -0.003907*tmax_max + -0.000605*BIO14 + -0.000405*BIO17 + 5.5e-05*BIO18 + 0.622858",
    },
}

# -------------------------------------------------
# ìœ í‹¸
# -------------------------------------------------
def _ensure_numeric(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# -------------------------------------------------
# ì‚¬ì´íŠ¸ AJAX â†’ JSON
# -------------------------------------------------
@st.cache_data(show_spinner=False, ttl=300)
def fetch_aws_stat(region_name: str, stat_gb_code: str, s_ym: str, e_ym: str) -> dict:
    """
    stat_gb_code: "A"(ê¸°ê°„), "B"(ì¼ë³„), "C"(ìˆœë³„), "D"(ì›”ë³„)
    s_ym/e_ym: "YYYY-MM"
    """
    session = requests.Session()
    session.get("https://fruit.nihhs.go.kr/apple/aws/awsStat.do", timeout=20)

    form = {
        "pageIndex": "1",
        "searchNum": "0",
        "areaName": region_name,
        "areaCode": AREA_CODE.get(region_name, region_name),
        "statmethod": stat_gb_code,
    }
    if stat_gb_code == "A":
        form["wetherDtBgn"] = f"{s_ym}-01"
        form["wetherDtEnd"] = f"{e_ym}-30"
    elif stat_gb_code in ("B", "C"):
        form["wetherDtM"] = s_ym
    elif stat_gb_code == "D":
        form["wetherDtBgn2"] = s_ym
        form["wetherDtEnd2"] = e_ym
        form["wetherDtBgn"] = s_ym
        form["wetherDtEnd"] = e_ym

    resp = session.post(
        "https://fruit.nihhs.go.kr/apple/aws/awsStatList.do",
        data=form, timeout=30,
        headers={"Referer": "https://fruit.nihhs.go.kr/apple/aws/awsStat.do"}
    )
    resp.raise_for_status()
    try:
        return resp.json()
    except Exception:
        return {"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "raw": resp.text[:4000]}

# -------------------------------------------------
# JSON â†’ í‘œ
# -------------------------------------------------
def json_to_dataframe(payload: dict) -> pd.DataFrame:
    if not payload or "result" not in payload:
        return pd.DataFrame()
    res = payload.get("result", [])
    if len(res) == 0:
        return pd.DataFrame()

    method = payload.get("mainAwsVO", {}).get("statmethod")
    if method == "A":
        df = pd.DataFrame(res)[[
            "statsDt","dalyWetherAvrgTp","dalyWetherMxmmTp","dalyWetherMummTp",
            "dalyWetherAvrgHd","dalyWetherTtalRainqy","dalyWetherMxmmSolradqy",
            "dalyWetherMxmmCondenstime","dalyWetherAvrgWs","dalyWetherMxmmWs"
        ]].rename(columns={
            "statsDt":"ì¼ì","dalyWetherAvrgTp":"í‰ê· ê¸°ì˜¨","dalyWetherMxmmTp":"ìµœê³ ê¸°ì˜¨",
            "dalyWetherMummTp":"ìµœì €ê¸°ì˜¨","dalyWetherAvrgHd":"ìŠµë„","dalyWetherTtalRainqy":"ê°•ìš°ëŸ‰",
            "dalyWetherMxmmSolradqy":"ì¼ì‚¬ëŸ‰","dalyWetherMxmmCondenstime":"ê²°ë¡œì‹œê°„",
            "dalyWetherAvrgWs":"í‰ê· í’ì†","dalyWetherMxmmWs":"ìµœëŒ€í’ì†"
        })
    elif method == "B":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì¼ì","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    elif method == "C":
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ìˆœ","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })
    else:  # "D"
        df = pd.DataFrame(res)[[
            "wetherDt","wetherAvgTp","wetherMaxTp","wetherMinTp",
            "WetherAvgHd","wetherMaxRainqy","wetherMaxSolradqy",
            "wetherMaxCondenstime","wetherAvgWs","wetherMaxWs"
        ]].rename(columns={
            "wetherDt":"ì›”","wetherAvgTp":"í‰ê· ê¸°ì˜¨","wetherMaxTp":"ìµœê³ ê¸°ì˜¨",
            "wetherMinTp":"ìµœì €ê¸°ì˜¨","WetherAvgHd":"ìŠµë„","wetherMaxRainqy":"ê°•ìš°ëŸ‰",
            "wetherMaxSolradqy":"ì¼ì‚¬ëŸ‰","wetherMaxCondenstime":"ê²°ë¡œì‹œê°„",
            "wetherAvgWs":"í‰ê· í’ì†","wetherMaxWs":"ìµœëŒ€í’ì†"
        })

    df = _ensure_numeric(
        df, ["í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ìŠµë„","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰","ê²°ë¡œì‹œê°„","í‰ê· í’ì†","ìµœëŒ€í’ì†"]
    )

    if "ì¼ì" in df.columns:
        df["ì¼ì"] = pd.to_datetime(df["ì¼ì"], errors="coerce")
        df["ì—°ë„"] = df["ì¼ì"].dt.year
        df["ì›”"] = df["ì¼ì"].dt.month
    elif "ì›”" in df.columns:
        df["ì—°ë„"] = df["ì›”"].astype(str).str[:4].astype(int)
        df["ì›”"] = df["ì›”"].astype(str).str[5:7].astype(int)

    return df

# -------------------------------------------------
# ì¼/ìˆœ â†’ ì›”ë³„ ì§‘ê³„
# -------------------------------------------------
def agg_to_monthly(df: pd.DataFrame) -> pd.DataFrame:
    if not {"ì—°ë„","ì›”"}.issubset(df.columns):
        return df.copy()

    agg_map = {
        "í‰ê· ê¸°ì˜¨":"mean","ìµœê³ ê¸°ì˜¨":"mean","ìµœì €ê¸°ì˜¨":"mean","ìŠµë„":"mean",
        "ê°•ìš°ëŸ‰":"sum","ì¼ì‚¬ëŸ‰":"sum","ê²°ë¡œì‹œê°„":"sum",
        "í‰ê· í’ì†":"mean","ìµœëŒ€í’ì†":"mean"
    }
    use_cols = {k:v for k,v in agg_map.items() if k in df.columns}
    out = df.groupby(["ì—°ë„","ì›”"], as_index=False).agg(use_cols)
    return out.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)

# -------------------------------------------------
# ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°: ìµœê·¼ 3ë…„ í‰ê·  or ì „ì²´ í‰ê· 
# -------------------------------------------------
def fill_missing_months_with_climatology(env_m: pd.DataFrame, target_year: int, mode: str = "last3") -> pd.DataFrame:
    req_cols = {"ì—°ë„", "ì›”"}
    if not req_cols.issubset(env_m.columns):
        raise ValueError("env_mì—ëŠ” 'ì—°ë„','ì›”' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")

    cur = env_m[env_m["ì—°ë„"] == target_year].copy()
    hist = env_m[env_m["ì—°ë„"] < target_year].copy()
    if hist.empty:
        return cur

    if mode == "last3":
        last_years = sorted(hist["ì—°ë„"].unique())[-3:]
        hist = hist[hist["ì—°ë„"].isin(last_years)]

    num_cols = [c for c in env_m.columns if c not in ("ì—°ë„","ì›”") and pd.api.types.is_numeric_dtype(env_m[c])]
    climo = hist.groupby("ì›”", as_index=False)[num_cols].mean()

    have_months = set(cur["ì›”"].tolist())
    all_months = set(range(1, 13))
    missing = sorted(list(all_months - have_months))

    if missing:
        fill_rows = climo[climo["ì›”"].isin(missing)].copy()
        fill_rows.insert(0, "ì—°ë„", target_year)
        cur = pd.concat([cur, fill_rows], ignore_index=True, axis=0)

    cur = cur.sort_values(["ì—°ë„","ì›”"]).reset_index(drop=True)
    for c in num_cols:
        cur[c] = pd.to_numeric(cur[c], errors="coerce")
    return cur

# -------------------------------------------------
# ì—°ê°„ íŒŒìƒì§€í‘œ + BIO ì§€í‘œ ê³„ì‚°
#   ì…ë ¥: íŠ¹ì • ì—°ë„ì˜ ì›”ë³„ ë°ì´í„°(ì—´: ì›”/í‰ê· ê¸°ì˜¨/ìµœê³ ê¸°ì˜¨/ìµœì €ê¸°ì˜¨/ê°•ìš°ëŸ‰/ì¼ì‚¬ëŸ‰)
#   ì¶œë ¥: dict (ìˆ˜ì‹ì— ë“¤ì–´ê°ˆ í”¼ì²˜ë“¤)
# -------------------------------------------------
def _rolling3_with_wrap(arr):
    # ê¸¸ì´ 12 ê°€ì •, 3ê°œì›” ì´ë™í•©/í‰ê· ì„ ì›” ê²½ê³„ ë„˜ì–´ ìˆœí™˜ ê³„ì‚°
    n = len(arr)
    ext = np.concatenate([arr, arr[:2]])
    sums = np.array([ext[i:i+3].sum() for i in range(n)])
    means = sums / 3.0
    return sums, means

def compute_surrogate_features(env_m_year: pd.DataFrame) -> dict:
    needed = ["ì›”","í‰ê· ê¸°ì˜¨","ìµœê³ ê¸°ì˜¨","ìµœì €ê¸°ì˜¨","ê°•ìš°ëŸ‰","ì¼ì‚¬ëŸ‰"]
    for c in needed:
        if c not in env_m_year.columns:
            raise ValueError(f"ì„ íƒ ì—°ë„ ë°ì´í„°ì— '{c}' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    df = env_m_year.sort_values("ì›”").reset_index(drop=True).copy()

    # ë°°ì—´ ì¤€ë¹„
    tmean = df["í‰ê· ê¸°ì˜¨"].to_numpy(float)
    tmax  = df["ìµœê³ ê¸°ì˜¨"].to_numpy(float)
    tmin  = df["ìµœì €ê¸°ì˜¨"].to_numpy(float)
    prcp  = df["ê°•ìš°ëŸ‰"].to_numpy(float)
    rad   = df["ì¼ì‚¬ëŸ‰"].to_numpy(float)

    # ê¸°ë³¸ íŒŒìƒ
    tmin_min   = float(np.nanmin(tmin))
    tmax_max   = float(np.nanmax(tmax))
    tmean_mean = float(np.nanmean(tmean))
    # rad_mean: ì›” ì¼ì‚¬ëŸ‰(ì›”í•©)ì˜ í‰ê· (=ì—°í‰ê·  ì›” ì¼ì‚¬ëŸ‰)
    rad_mean   = float(np.nanmean(rad))
    prcp_sum   = float(np.nansum(prcp))

    # BIO ì§€í‘œ (ì›”ê°’ ê¸°ë°˜ ê·¼ì‚¬)
    BIO1 = float(tmean_mean)                 # Annual Mean Temp
    diurnal = tmax - tmin
    BIO2 = float(np.nanmean(diurnal))        # Mean Diurnal Range
    BIO5 = float(np.nanmax(tmax))            # Max Temp of Warmest Month
    BIO6 = float(np.nanmin(tmin))            # Min Temp of Coldest Month
    BIO7 = float(BIO5 - BIO6)                # Temp Annual Range
    BIO3 = float((BIO2 / BIO7) * 100) if BIO7 not in (0, np.nan) else np.nan  # Isothermality (%)
    BIO4 = float(np.nanstd(tmean, ddof=0) * 100.0)                             # Temp Seasonality

    # 3ê°œì›” ì°½(ë¶„ê¸°) - ìˆœí™˜
    prcp_3sum_vals, _ = _rolling3_with_wrap(prcp)
    _, tmean_3mean_vals = _rolling3_with_wrap(tmean)

    wettest_q_idx  = int(np.nanargmax(prcp_3sum_vals))
    driest_q_idx   = int(np.nanargmin(prcp_3sum_vals))
    warmest_q_idx  = int(np.nanargmax(tmean_3mean_vals))
    coldest_q_idx  = int(np.nanargmin(tmean_3mean_vals))

    BIO8  = float(tmean_3mean_vals[wettest_q_idx])   # Mean Temp of Wettest Quarter
    BIO9  = float(tmean_3mean_vals[driest_q_idx])    # Mean Temp of Driest Quarter
    BIO10 = float(tmean_3mean_vals[warmest_q_idx])   # Mean Temp of Warmest Quarter
    BIO11 = float(tmean_3mean_vals[coldest_q_idx])   # Mean Temp of Coldest Quarter
    BIO12 = float(prcp_sum)                          # Annual Precipitation
    BIO13 = float(np.nanmax(prcp))                   # Precipitation of Wettest Month
    BIO14 = float(np.nanmin(prcp))                   # Precipitation of Driest Month
    BIO15 = float((np.nanstd(prcp, ddof=0) / np.nanmean(prcp)) * 100.0) if np.nanmean(prcp) not in (0, np.nan) else np.nan  # Precip Seasonality
    BIO17 = float(prcp_3sum_vals[driest_q_idx])      # Precip of Driest Quarter
    BIO18 = float(prcp_3sum_vals[warmest_q_idx])     # Precip of Warmest Quarter
    BIO19 = float(prcp_3sum_vals[coldest_q_idx])     # Precip of Coldest Quarter

    feats = {
        "tmin_min": tmin_min,
        "tmax_max": tmax_max,
        "tmean_mean": tmean_mean,
        "rad_mean": rad_mean,
        "prcp_sum": prcp_sum,

        "BIO1": BIO1, "BIO2": BIO2, "BIO3": BIO3, "BIO4": BIO4, "BIO5": BIO5, "BIO6": BIO6, "BIO7": BIO7,
        "BIO8": BIO8, "BIO9": BIO9, "BIO10": BIO10, "BIO11": BIO11, "BIO12": BIO12, "BIO13": BIO13,
        "BIO14": BIO14, "BIO15": BIO15, "BIO17": BIO17, "BIO18": BIO18, "BIO19": BIO19,
    }
    return feats

# -------------------------------------------------
# ìˆ˜ì‹ ì ìš© (ì¹˜í™˜ ì—†ì´ localsë¡œ í‰ê°€)
# -------------------------------------------------
def apply_equation_series(series: pd.Series, eq_str: str) -> float:
    """
    ìˆ˜ì‹ì„ ê·¸ëŒ€ë¡œ í‰ê°€í•˜ë˜, ë³€ìˆ˜ëŠ” localsë¡œ ì „ë‹¬í•œë‹¤.
    ì˜ˆ: "ê³¼ì¤‘ = 1.2*tmin_min + 0.3*BIO3 + 10"
    """
    rhs = eq_str.split("=", 1)[1].strip().replace("Â·", "*")
    ns = {k: (float(v) if pd.notna(v) else float("nan")) for k, v in series.items()}
    val = eval(rhs, {"__builtins__": {}}, ns)  # ì•ˆì „ ëª¨ë“œ
    return float(val)

# -------------------------------------------------
# ì‚¬ì´ë“œë°”
# -------------------------------------------------
with st.sidebar:
    st.header("ì¡°íšŒ ì¡°ê±´")
    region = st.selectbox("ì§€ì—­", list(AREA_CODE.keys()), index=1)
    stat_label = st.selectbox("í†µê³„ êµ¬ë¶„", ["ê¸°ê°„(ì¼ìë²”ìœ„)","ì¼ë³„","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)","ì›”ë³„"], index=3)
    stat_map = {"ê¸°ê°„(ì¼ìë²”ìœ„)":"A","ì¼ë³„":"B","ìˆœë³„(ìƒÂ·ì¤‘Â·í•˜ìˆœ)":"C","ì›”ë³„":"D"}
    stat_gb = st.radio("í†µê³„ ì½”ë“œ", options=list(stat_map.values()), index=list(stat_map.values()).index(stat_map[stat_label]), horizontal=True, help="ë³€ê²½ ì‹œ ìœ„ ì…€ë ‰íŠ¸ì™€ ë™ì¼í•˜ê²Œ ë™ì‘")
    # ìœ„ ë¼ë””ì˜¤ëŠ” ì„ íƒì§€ ë™ê¸°í™”ë¥¼ ìœ„í•œ ë³´ì¡°(ì„ íƒ). ì‹«ìœ¼ë©´ ì œê±°í•´ë„ ë™ì‘í•¨.

    col1, col2 = st.columns(2)
    with col1:
        s_year = st.number_input("ì‹œì‘ ì—°ë„", 2010, 2100, 2024, 1)
        s_month = st.number_input("ì‹œì‘ ì›”", 1, 12, 1, 1)
    with col2:
        e_year = st.number_input("ì¢…ë£Œ ì—°ë„", 2010, 2100, 2025, 1)
        e_month = st.number_input("ì¢…ë£Œ ì›”", 1, 12, 8, 1)

    s_ym = f"{int(s_year):04d}-{int(s_month):02d}"
    e_ym = f"{int(e_year):04d}-{int(e_month):02d}"

    cultivar = st.selectbox("í’ˆì¢…", ["í™ë¡œ", "í›„ì§€"], index=0)

    fill_strategy = st.selectbox(
        "ë¯¸í™•ë³´ ì›” ì±„ì›€ ë°©ë²•",
        ["ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)", "ìµœê·¼ 3ë…„ ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°", "ì „ì²´ ê³¼ê±° ì›”í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°"],
        index=1
    )

    run = st.button("ğŸ” ì¡°íšŒ & ì˜ˆì¸¡")

# -------------------------------------------------
# ì‹¤í–‰
# -------------------------------------------------
if run:
    with st.spinner("ì„œë²„ì—ì„œ ê¸°ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        payload = fetch_aws_stat(region, stat_gb, s_ym, e_ym)

    if "error" in payload:
        st.error("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        st.code(payload.get("raw","")[:1000])
        st.stop()

    df = json_to_dataframe(payload)
    if df.empty:
        st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„(íŠ¹íˆ 'ê¸°ê°„'ì€ 1ë…„ ì´ë‚´)ê³¼ ì§€ì—­ì„ ì¡°ì •í•˜ì„¸ìš”.")
        st.stop()

    st.subheader("ì›ìë£Œ")
    st.dataframe(df, use_container_width=True)

    # ì›”ë³„ ì§‘ê³„
    if stat_gb in ("A","B","C"):
        env_m = agg_to_monthly(df)
        st.subheader("ì›”ë³„ ìš”ì•½(ì§‘ê³„)")
    else:
        env_m = df.copy()
        if "ì—°ë„" not in env_m.columns and "ì›”" in env_m.columns:
            env_m["ì—°ë„"] = env_m["ì›”"].astype(str).str[:4].astype(int)
            env_m["ì›”"] = env_m["ì›”"].astype(str).str[5:7].astype(int)
        st.subheader("ì›”ë³„ ì‘ë‹µ")

    st.dataframe(env_m, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œ
    c1, c2 = st.columns(2)
    with c1:
        st.download_button(
            "â¬‡ï¸ ì›ìë£Œ CSV",
            df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_raw.csv",
            mime="text/csv",
        )
    with c2:
        st.download_button(
            "â¬‡ï¸ ì›”ë³„ìš”ì•½ CSV",
            env_m.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{region}_{stat_gb}_{s_ym}_{e_ym}_monthly.csv",
            mime="text/csv",
        )

    # ì˜ˆì¸¡ ì—°ë„ ì„ íƒ
    years = sorted(env_m["ì—°ë„"].dropna().astype(int).unique())
    if not years:
        st.warning("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    sel_year = st.selectbox("ì˜ˆì¸¡ ì—°ë„ ì„ íƒ", years, index=len(years)-1)

    # ì„ íƒ ì—°ë„ì˜ ë¯¸í™•ë³´ ì›” ì±„ìš°ê¸°
    env_m_filled = env_m.copy()
    if fill_strategy != "ì±„ìš°ì§€ ì•ŠìŒ(ì˜ˆì¸¡ ë¶ˆê°€)":
        mode = "last3" if "ìµœê·¼ 3ë…„" in fill_strategy else "all"
        filled_rowset = fill_missing_months_with_climatology(env_m, sel_year, mode=mode)
        env_m_filled = pd.concat(
            [env_m_filled[env_m_filled["ì—°ë„"] != sel_year], filled_rowset],
            ignore_index=True
        ).sort_values(["ì—°ë„","ì›”"])

        st.info(f"{sel_year}ë…„ì˜ ë¹„ì–´ ìˆëŠ” ì›”ì„ '{fill_strategy}'ë¡œ ì±„ì› ìŠµë‹ˆë‹¤.")
        st.dataframe(env_m_filled[env_m_filled["ì—°ë„"] == sel_year], use_container_width=True)

    # ì„ íƒ ì—°ë„ ë°ì´í„°ë§Œ ì¶”ì¶œ
    env_year = env_m_filled[env_m_filled["ì—°ë„"] == sel_year].copy()

    # íŒŒìƒì§€í‘œ ê³„ì‚°
    try:
        feats_dict = compute_surrogate_features(env_year)
    except Exception as e:
        st.error(f"íŒŒìƒì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        st.stop()

    feats_series = pd.Series(feats_dict)
    st.subheader("ì—°ê°„ íŒŒìƒì§€í‘œ / BIO ì§€í‘œ")
    st.dataframe(pd.DataFrame([feats_dict]), use_container_width=True)

    # í’ˆì¢…ë³„ íšŒê·€ì‹ ì ìš©  (<= ë°˜ë“œì‹œ if run: ë¸”ë¡ ë‚´ë¶€)
    EQUATIONS = EQUATIONS_BY_CULTIVAR.get(cultivar, {})
    preds = {}
    for tgt, formula in EQUATIONS.items():
        try:
            v = apply_equation_series(feats_series, formula)
            preds[tgt] = None if (pd.isna(v) or np.isinf(v)) else float(v)
        except Exception as e:
            preds[tgt] = f"ì—ëŸ¬: {e}"

    st.subheader(f"íšŒê·€ì‹ ì˜ˆì¸¡ ê²°ê³¼  í’ˆì¢…: {cultivar}  ì—°ë„: {sel_year}")
    st.write(preds)

else:
    st.info("ì¢Œì¸¡ì—ì„œ ì¡°ê±´ì„ ê³ ë¥´ê³  í’ˆì¢…ì„ ì„ íƒí•œ ë’¤ ì¡°íšŒ & ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
